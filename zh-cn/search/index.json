[{"content":"redis通信 源码分析 系统初始化 \u0026amp; eventloop事件循环总线构建 从main函数说起（原300+行，精简部分非核心内容后包含注释100+行） 网络通信相关主要为：在main函数中启动epoll监听，io多路复用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 int main(int argc, char **argv) { struct timeval tv; int j; char config_from_stdin = 0; /* 系统基础依赖初始化： 1. 时区设置 2. 内存oom处理方法 3. 随机数/哈希种子生成 4. crc64校验码初始化 */ char *exec_name = strrchr(argv[0], \u0026#39;/\u0026#39;); if (exec_name == NULL) exec_name = argv[0]; server.sentinel_mode = checkForSentinelMode(argc,argv, exec_name); initServerConfig(); ACLInit(); /* 初始化 ACL（访问控制列表）系统，网络连接时需要根据ACL控制权限，此时未加载实际配置 */ moduleInitModulesSystem(); connTypeInitialize(); /* 存储可执行文件路径和启动参数，用于以后重启服务器 */ server.executable = getAbsolutePath(argv[0]); server.exec_argv = zmalloc(sizeof(char*)*(argc+1)); server.exec_argv[argc] = NULL; for (j = 0; j \u0026lt; argc; j++) server.exec_argv[j] = zstrdup(argv[j]); /* 初始化 Sentinel 相关配置（如果是 Sentinel 模式） */ if (server.sentinel_mode) { initSentinelConfig(); initSentinel(); } /* 检查是否需要启动 redis-check-rdb 或 redis-check-aof 模式 */ if (strstr(exec_name,\u0026#34;redis-check-rdb\u0026#34;) != NULL) redis_check_rdb_main(argc,argv,NULL); else if (strstr(exec_name,\u0026#34;redis-check-aof\u0026#34;) != NULL) redis_check_aof_main(argc,argv); /* 参数解析 */ if (argc \u0026gt;= 2) { j = 1; sds options = sdsempty(); // 使用内部定义的sds字符串结构 /* 解析特殊参数 --version，--help */ if (strcmp(argv[1], \u0026#34;-v\u0026#34;) == 0 || strcmp(argv[1], \u0026#34;--version\u0026#34;) == 0) { sds version = getVersion(); printf(\u0026#34;Redis server %s\\n\u0026#34;, version); sdsfree(version); exit(0); } if (strcmp(argv[1], \u0026#34;--help\u0026#34;) == 0 || strcmp(argv[1], \u0026#34;-h\u0026#34;) == 0) usage(); sds *argv_tmp; int argc_tmp; int handled_last_config_arg = 1; while(j \u0026lt; argc) { /* 遍历解析参数 */ j++; } /* 根据参数完成必要文件配置的加载 */ loadServerConfig(server.configfile, config_from_stdin, options); if (server.sentinel_mode) loadSentinelConfigFromQueue(); sdsfree(options); } if (server.sentinel_mode) sentinelCheckConfigFile(); /* 核心：启动服务 */ initServer(); // 核心中的核心：载入server对象相关的核心组件：signal信号处理器，thread线程管理器，eventloop事件处理总线等 if (background || server.pidfile) createPidFile(); if (server.set_proc_title) redisSetProcTitle(NULL); redisAsciiArt(); // 打印启动redis的ASCII文字 checkTcpBacklogSettings(); if (server.cluster_enabled) { clusterInit(); } if (!server.sentinel_mode) { moduleInitModulesSystemLast(); moduleLoadFromQueue(); } // acl读取实际配置 ACLLoadUsersAtStartup(); initListeners(); if (server.cluster_enabled) { clusterInitLast(); } InitServerLast(); if (!server.sentinel_mode) { // 非sentinel模式 serverLog(LL_NOTICE,\u0026#34;Server initialized\u0026#34;); aofLoadManifestFromDisk(); loadDataFromDisk(); aofOpenIfNeededOnServerStart(); aofDelHistoryFiles(); applyAppendOnlyConfig(); // 集群模式校验 if (server.cluster_enabled) { serverAssert(verifyClusterConfigWithData() == C_OK); } // 打印所有监听器的状态 for (j = 0; j \u0026lt; CONN_TYPE_MAX; j++) { connListener *listener = \u0026amp;server.listeners[j]; if (listener-\u0026gt;ct == NULL) continue; serverLog(LL_NOTICE,\u0026#34;Ready to accept connections %s\u0026#34;, listener-\u0026gt;ct-\u0026gt;get_type(NULL)); } if (server.supervised_mode == SUPERVISED_SYSTEMD) { // 如果是由 systemd 监督运行的 Redis 实例，通知 systemd Redis 状态 } } else { sentinelIsRunning(); if (server.supervised_mode == SUPERVISED_SYSTEMD) { // 如果是由 systemd 监督运行的 sentinel 实例，通知 systemd sentinel 状态 } } /* 内存分配过小（1MB）警告 */ if (server.maxmemory \u0026gt; 0 \u0026amp;\u0026amp; server.maxmemory \u0026lt; 1024*1024) { serverLog(LL_WARNING,\u0026#34;WARNING: You specified a maxmemory value that is less than 1MB (current value is %llu bytes). Are you sure this is what you really want?\u0026#34;, server.maxmemory); } redisSetCpuAffinity(server.server_cpulist); setOOMScoreAdj(-1); // epoll监听，io多路复用，死循环 aeMain(server.el); aeDeleteEventLoop(server.el); return 0; } 核心中的核心：initServer方法，载入server对象相关的核心组件：signal信号处理器，thread线程管理器，eventloop事件处理总线等。（原200+行，精简部分非核心内容后包含注释60+行） 网络通信相关主要为：在初始化函数中创建thread线程管理器，eventloop事件处理总线 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 void initServer(void) { // 信号处理器，例如ctrl+c发送SIGKILL信号，此时需要关闭服务 setupSignalHandlers(); // 线程管理器初始化 ThreadsManager_init(); makeThreadKillable(); /* 在从配置系统设置默认值后进行初始化 */ server.aof_state = server.aof_enabled ? AOF_ON : AOF_OFF; server.fsynced_reploff = server.aof_enabled ? 0 : -1; server.hz = server.config_hz; // 心跳频率 server.pid = getpid(); // 创建eventloop事件处理总线，基于epoll机制（linux） server.el = aeCreateEventLoop(server.maxclients+CONFIG_FDSET_INCR); if (server.el == NULL) { serverLog(LL_WARNING, \u0026#34;Failed creating the event loop. Error message: \u0026#39;%s\u0026#39;\u0026#34;, strerror(errno)); exit(1); } /* 创建定时器回调，这是我们处理许多后台操作的方式， 比如客户端超时、未访问的过期键的淘汰等 */ if (aeCreateTimeEvent(server.el, 1, serverCron, NULL, NULL) == AE_ERR) { serverPanic(\u0026#34;Can\u0026#39;t create event loop timers.\u0026#34;); exit(1); } /* 为用于唤醒事件循环的管道注册一个可读事件， 用于模块线程间的通信 */ if (aeCreateFileEvent(server.el, server.module_pipe[0], AE_READABLE, modulePipeReadable,NULL) == AE_ERR) { serverPanic( \u0026#34;Error registering the readable event for the module pipe.\u0026#34;); } /* 注册epoll阻塞前后的回调函数（需在加载持久化之前完成，因为它会被 processEventsWhileBlocked 使用） */ aeSetBeforeSleepProc(server.el,beforeSleep); aeSetAfterSleepProc(server.el,afterSleep); /* 32位老系统受限于寻址上限32bit，最多访问2^32个字节，也就是4294967296B -\u0026gt; 4GB，redis会默认限制3GB上限 */ if (server.arch_bits == 32 \u0026amp;\u0026amp; server.maxmemory == 0) { serverLog(LL_WARNING,\u0026#34;Warning: 32 bit instance detected but no memory limit set. Setting 3 GB maxmemory limit with \u0026#39;noeviction\u0026#39; policy now.\u0026#34;); server.maxmemory = 3072LL*(1024*1024); /* 3 GB */ server.maxmemory_policy = MAXMEMORY_NO_EVICTION; } // 脚本系统初始化 luaEnvInit(); scriptingInit(1); if (functionsInit() == C_ERR) { serverPanic(\u0026#34;Functions initialization failed, check the server logs.\u0026#34;); exit(1); } // 基本监控初始化：提供慢查询告警/延迟监控等功能 slowlogInit(); latencyMonitorInit(); // 参照配置初始化密码，一般不启用 ACLUpdateDefaultUserPassword(server.requirepass); // 定时器功能初始化 applyWatchdogPeriod(); if (server.maxmemory_clients != 0) initServerClientMemUsageBuckets(); } aeCreateEventLoop方法：创建事件循环总线 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 aeEventLoop *aeCreateEventLoop(int setsize) { aeEventLoop *eventLoop; monotonicInit(); /* just in case the calling app didn\u0026#39;t initialize */ // 分配内存：最大感兴趣的fd为setsize if ((eventLoop = zmalloc(sizeof(*eventLoop))) == NULL) goto err; eventLoop-\u0026gt;events = zmalloc(sizeof(aeFileEvent)*setsize); eventLoop-\u0026gt;fired = zmalloc(sizeof(aeFiredEvent)*setsize); if (eventLoop-\u0026gt;events == NULL || eventLoop-\u0026gt;fired == NULL) goto err; eventLoop-\u0026gt;setsize = setsize; eventLoop-\u0026gt;timeEventHead = NULL; eventLoop-\u0026gt;timeEventNextId = 0; eventLoop-\u0026gt;stop = 0; eventLoop-\u0026gt;maxfd = -1; eventLoop-\u0026gt;beforesleep = NULL; eventLoop-\u0026gt;aftersleep = NULL; eventLoop-\u0026gt;flags = 0; if (aeApiCreate(eventLoop) == -1) goto err; // 核心：调用封装的函数aeApiCreate /* Events的关注事件默认置为0（不关注任何事件）*/ for (int i = 0; i \u0026lt; setsize; i++) eventLoop-\u0026gt;events[i].mask = AE_NONE; return eventLoop; err: // 失败则释放内存 if (eventLoop) { zfree(eventLoop-\u0026gt;events); zfree(eventLoop-\u0026gt;fired); zfree(eventLoop); } return NULL; } /* ae_epoll.c，仅在上面代码中调用，创建事件总线\t这里依赖系统内置库函数：epoll_create，其中size参数仅为参考值，对较新的linux版本来说无实际作用 */ static int aeApiCreate(aeEventLoop *eventLoop) { aeApiState *state = zmalloc(sizeof(aeApiState)); if (!state) return -1; state-\u0026gt;events = zmalloc(sizeof(struct epoll_event)*eventLoop-\u0026gt;setsize); if (!state-\u0026gt;events) { zfree(state); return -1; } state-\u0026gt;epfd = epoll_create(1024); /* 1024 is just a hint for the kernel */ if (state-\u0026gt;epfd == -1) { zfree(state-\u0026gt;events); zfree(state); return -1; } anetCloexec(state-\u0026gt;epfd); eventLoop-\u0026gt;apidata = state; return 0; } ae_epoll.c封装系统库函数（无精简） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 #include \u0026lt;sys/epoll.h\u0026gt; typedef struct aeApiState { int epfd; struct epoll_event *events; } aeApiState; /* 仅在aeCreateEventLoop代码中调用，创建事件总线\t依赖系统内置库函数：epoll_create，其中： size参数仅为参考值，对较新的linux版本来说无实际作用 */ static int aeApiCreate(aeEventLoop *eventLoop) { aeApiState *state = zmalloc(sizeof(aeApiState)); if (!state) return -1; state-\u0026gt;events = zmalloc(sizeof(struct epoll_event)*eventLoop-\u0026gt;setsize); if (!state-\u0026gt;events) { zfree(state); return -1; } state-\u0026gt;epfd = epoll_create(1024); /* 1024 is just a hint for the kernel */ if (state-\u0026gt;epfd == -1) { zfree(state-\u0026gt;events); zfree(state); return -1; } anetCloexec(state-\u0026gt;epfd); eventLoop-\u0026gt;apidata = state; return 0; } // resize event数组，类似vector(c)/list(java)/slice(golang/python)动态扩容 static int aeApiResize(aeEventLoop *eventLoop, int setsize) { aeApiState *state = eventLoop-\u0026gt;apidata; state-\u0026gt;events = zrealloc(state-\u0026gt;events, sizeof(struct epoll_event)*setsize); return 0; } // 释放资源 static void aeApiFree(aeEventLoop *eventLoop) { aeApiState *state = eventLoop-\u0026gt;apidata; close(state-\u0026gt;epfd); zfree(state-\u0026gt;events); zfree(state); } /* 在eventloop中注册新的fd，mask为感兴趣的事件 依赖系统内置库函数epoll_ctl，其中： epfd为事件总线fd， op为注册操作，枚举EPOLL_CTL_ADD, EPOLL_CTL_ADD, EPOLL_CTL_DEL， fd为注册的新fd， ee为新建的epoll_event结构体实例 */ static int aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask) { aeApiState *state = eventLoop-\u0026gt;apidata; struct epoll_event ee = {0}; /* avoid valgrind warning */ /* If the fd was already monitored for some event, we need a MOD * operation. Otherwise we need an ADD operation. */ int op = eventLoop-\u0026gt;events[fd].mask == AE_NONE ? EPOLL_CTL_ADD : EPOLL_CTL_MOD; ee.events = 0; mask |= eventLoop-\u0026gt;events[fd].mask; /* Merge old events */ if (mask \u0026amp; AE_READABLE) ee.events |= EPOLLIN; if (mask \u0026amp; AE_WRITABLE) ee.events |= EPOLLOUT; ee.data.fd = fd; if (epoll_ctl(state-\u0026gt;epfd,op,fd,\u0026amp;ee) == -1) return -1; return 0; } /* 在eventloop中注册新的fd，mask为感兴趣的事件 依赖系统内置库函数epoll_ctl，其中： epfd为事件总线fd， op为注册操作，枚举EPOLL_CTL_ADD, EPOLL_CTL_ADD, EPOLL_CTL_DEL， fd为注册的新fd， ee为新建的epoll_event结构体实例，关注的mask写在这个结构体中 */ static void aeApiDelEvent(aeEventLoop *eventLoop, int fd, int delmask) { aeApiState *state = eventLoop-\u0026gt;apidata; struct epoll_event ee = {0}; /* avoid valgrind warning */ int mask = eventLoop-\u0026gt;events[fd].mask \u0026amp; (~delmask); ee.events = 0; if (mask \u0026amp; AE_READABLE) ee.events |= EPOLLIN; if (mask \u0026amp; AE_WRITABLE) ee.events |= EPOLLOUT; ee.data.fd = fd; if (mask != AE_NONE) { epoll_ctl(state-\u0026gt;epfd,EPOLL_CTL_MOD,fd,\u0026amp;ee); } else { /* Note, Kernel \u0026lt; 2.6.9 requires a non null event pointer even for * EPOLL_CTL_DEL. */ epoll_ctl(state-\u0026gt;epfd,EPOLL_CTL_DEL,fd,\u0026amp;ee); } } /* 在eventloop中注册新的fd，mask为感兴趣的事件 依赖系统内置库函数epoll_wait，其中： epfd为事件总线fd， events为已注册的全部感兴趣事件， tvp相关为等待时间，-1为一直阻塞，直到有注册的感兴趣事件发生 */ static int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp) { aeApiState *state = eventLoop-\u0026gt;apidata; int retval, numevents = 0; retval = epoll_wait(state-\u0026gt;epfd,state-\u0026gt;events,eventLoop-\u0026gt;setsize, tvp ? (tvp-\u0026gt;tv_sec*1000 + (tvp-\u0026gt;tv_usec + 999)/1000) : -1); if (retval \u0026gt; 0) { int j; numevents = retval; for (j = 0; j \u0026lt; numevents; j++) { int mask = 0; struct epoll_event *e = state-\u0026gt;events+j; if (e-\u0026gt;events \u0026amp; EPOLLIN) mask |= AE_READABLE; if (e-\u0026gt;events \u0026amp; EPOLLOUT) mask |= AE_WRITABLE; if (e-\u0026gt;events \u0026amp; EPOLLERR) mask |= AE_WRITABLE|AE_READABLE; if (e-\u0026gt;events \u0026amp; EPOLLHUP) mask |= AE_WRITABLE|AE_READABLE; eventLoop-\u0026gt;fired[j].fd = e-\u0026gt;data.fd; eventLoop-\u0026gt;fired[j].mask = mask; } } else if (retval == -1 \u0026amp;\u0026amp; errno != EINTR) { panic(\u0026#34;aeApiPoll: epoll_wait, %s\u0026#34;, strerror(errno)); } return numevents; } static char *aeApiName(void) { return \u0026#34;epoll\u0026#34;; } 哪些地方调用了注册事件 server启动过程中：initListeners -\u0026gt; createSocketAcceptHandler （accept） connSocketAcceptHandler 创建客户端连接时：ConnectionType -\u0026gt; connSocketConnect（connect） ae_handler -\u0026gt; connSocketSetReadHandler 建立client通信时：createClient -\u0026gt; readQueryFromClient ae_handler -\u0026gt; connSocketSetWriteHandler 初始化服务端时：initServer -\u0026gt; aeSetBeforeSleepProc -\u0026gt; beforeSleep -\u0026gt; handleClientsWithPendingWritesUsingThreads -\u0026gt; sendReplyToClient 同步rdb数据：initServer -\u0026gt; aeCreateTimeEvent(server.el, 1, serverCron, NULL, NULL) -\u0026gt; serverCron -\u0026gt; checkChildrenDone -\u0026gt; replicationStartPendingFork -\u0026gt; rdbSaveToSlavesSockets rdbPipeReadHandler sentinel通信：initServer -\u0026gt; aeCreateTimeEvent(server.el, 1, serverCron, NULL, NULL) -\u0026gt; serverCron -\u0026gt; sentinelTimer -\u0026gt; sentinelHandleDictOfRedisInstances -\u0026gt; sentinelHandleRedisInstance -\u0026gt; sentinelReconnectInstance -\u0026gt; redisAeAttach -\u0026gt; redisAeAddWrite pipeline管道的bio通信：initServer -\u0026gt; InitServerLast -\u0026gt; bioInit 注册事件处理：main -\u0026gt; aeMain -\u0026gt; aeApiPoll -\u0026gt; epoll_wait 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 // 死循环处理事件 void aeMain(aeEventLoop *eventLoop) { eventLoop-\u0026gt;stop = 0; while (!eventLoop-\u0026gt;stop) { aeProcessEvents(eventLoop, AE_ALL_EVENTS| AE_CALL_BEFORE_SLEEP| AE_CALL_AFTER_SLEEP); } } typedef struct aeEventLoop { int maxfd; /* highest file descriptor currently registered */ int setsize; /* max number of file descriptors tracked */ long long timeEventNextId; aeFileEvent *events; /* Registered events */ aeFiredEvent *fired; /* Fired events */ aeTimeEvent *timeEventHead; int stop; void *apidata; /* This is used for polling API specific data */ aeBeforeSleepProc *beforesleep; aeBeforeSleepProc *aftersleep; int flags; } aeEventLoop; typedef struct aeFileEvent { int mask; /* one of AE_(READABLE|WRITABLE|BARRIER) */ aeFileProc *rfileProc; aeFileProc *wfileProc; void *clientData; } aeFileEvent; int aeProcessEvents(aeEventLoop *eventLoop, int flags) { int processed = 0, numevents; /* 如果没有文件事件和时间事件需要处理，直接返回 */ if (!(flags \u0026amp; AE_TIME_EVENTS) \u0026amp;\u0026amp; !(flags \u0026amp; AE_FILE_EVENTS)) return 0; /* 即使没有文件事件，如果有时间事件，也需要调用 aeApiPoll 来等待下一次时间事件的触发 */ if (eventLoop-\u0026gt;maxfd != -1 || ((flags \u0026amp; AE_TIME_EVENTS) \u0026amp;\u0026amp; !(flags \u0026amp; AE_DONT_WAIT))) { int j; struct timeval tv, *tvp = NULL; /* NULL means infinite wait. */ int64_t usUntilTimer; if (eventLoop-\u0026gt;beforesleep != NULL \u0026amp;\u0026amp; (flags \u0026amp; AE_CALL_BEFORE_SLEEP)) /* Before sleep callback. */ eventLoop-\u0026gt;beforesleep(eventLoop); /* eventLoop-\u0026gt;flags 可能会在 beforeSleep 中发生改变，所以需要在调用 beforeSleep 后重新检查 同时，flags 参数优先级更高，特别是 AE_DONT_WAIT 设置时，应忽略 eventLoop-\u0026gt;flags 中的值 */ if ((flags \u0026amp; AE_DONT_WAIT) || (eventLoop-\u0026gt;flags \u0026amp; AE_DONT_WAIT)) { tv.tv_sec = tv.tv_usec = 0; tvp = \u0026amp;tv; } else if (flags \u0026amp; AE_TIME_EVENTS) { usUntilTimer = usUntilEarliestTimer(eventLoop); if (usUntilTimer \u0026gt;= 0) { tv.tv_sec = usUntilTimer / 1000000; tv.tv_usec = usUntilTimer % 1000000; tvp = \u0026amp;tv; } } /* 调用aeApiPoll多路复用方法，Call the multiplexing API, will return only on timeout or when some event fires. */ numevents = aeApiPoll(eventLoop, tvp); /* 如果没有请求处理文件事件，就跳过文件事件的处理 */ if (!(flags \u0026amp; AE_FILE_EVENTS)) { numevents = 0; } /* After sleep callback. */ if (eventLoop-\u0026gt;aftersleep != NULL \u0026amp;\u0026amp; flags \u0026amp; AE_CALL_AFTER_SLEEP) eventLoop-\u0026gt;aftersleep(eventLoop); for (j = 0; j \u0026lt; numevents; j++) { int fd = eventLoop-\u0026gt;fired[j].fd; aeFileEvent *fe = \u0026amp;eventLoop-\u0026gt;events[fd]; int mask = eventLoop-\u0026gt;fired[j].mask; int fired = 0; /* Number of events fired for current fd. */ /* 默认情况下，先执行可读事件，再执行可写事件。这个顺序可以确保有可读数据时，优先处理读取请求。 * 如果设置了 AE_BARRIER 标志，则表示我们希望反转执行顺序，先执行可写事件。 */ int invert = fe-\u0026gt;mask \u0026amp; AE_BARRIER; /* 检查事件是否仍然有效：可能已经处理过的事件在当前回合中已经被移除 */ if (!invert \u0026amp;\u0026amp; fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_READABLE) { fe-\u0026gt;rfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); fired++; fe = \u0026amp;eventLoop-\u0026gt;events[fd]; /* Refresh in case of resize. */ } /* 执行可写事件 */ if (fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_WRITABLE) { if (!fired || fe-\u0026gt;wfileProc != fe-\u0026gt;rfileProc) { fe-\u0026gt;wfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); fired++; } } /* 如果需要反转执行顺序，在可写事件后执行可读事件 */ if (invert) { fe = \u0026amp;eventLoop-\u0026gt;events[fd]; /* Refresh in case of resize. */ if ((fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_READABLE) \u0026amp;\u0026amp; (!fired || fe-\u0026gt;wfileProc != fe-\u0026gt;rfileProc)) { fe-\u0026gt;rfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); fired++; } } processed++; } } /* 如果需要处理时间事件，则继续处理时间事件 */ if (flags \u0026amp; AE_TIME_EVENTS) processed += processTimeEvents(eventLoop); return processed; } 多路复用处理方法（类似netty中的handler实现） 协议解析：createClient -\u0026gt; readQueryFromClient -\u0026gt; processInputBuffer -\u0026gt; processXXXBuffer -\u0026gt; processCommandAndResetClient inline：processInlineBuffer multi：processMultibulkBuffer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 void readQueryFromClient(connection *conn) { client *c = connGetPrivateData(conn); int nread, big_arg = 0; size_t qblen, readlen; /* 如果启用了线程化 I/O，并且需要在退出事件循环时稍后读取客户端数据 */ if (postponeClientRead(c)) return; /* 更新服务器的总读取次数 */ atomicIncr(server.stat_total_reads_processed, 1); readlen = PROTO_IOBUF_LEN; /* 如果这是一个多批量请求，并且正在处理一个较大的批量回复，尽量确保查询缓冲区 * 精确包含表示对象的 SDS 字符串，即使这可能会导致更多的 read(2) 调用。 * 这样，函数 processMultiBulkBuffer() 可以避免复制缓冲区来创建 Redis 对象。 */ if (c-\u0026gt;reqtype == PROTO_REQ_MULTIBULK \u0026amp;\u0026amp; c-\u0026gt;multibulklen \u0026amp;\u0026amp; c-\u0026gt;bulklen != -1 \u0026amp;\u0026amp; c-\u0026gt;bulklen \u0026gt;= PROTO_MBULK_BIG_ARG) { /* 对于大的参数，客户端总是使用其私有的查询缓冲区。 * 使用可重用的查询缓冲区可能会导致其超出 32k，最终让客户端接管这个缓冲区。 */ if (!c-\u0026gt;querybuf) c-\u0026gt;querybuf = sdsempty(); ssize_t remaining = (size_t)(c-\u0026gt;bulklen+2)-(sdslen(c-\u0026gt;querybuf)-c-\u0026gt;qb_pos); big_arg = 1; /* 注意：\u0026#39;remaining\u0026#39; 变量在某些边缘情况下可能为零，例如当在 CLIENT PAUSE 后恢复被阻塞的客户端时 */ if (remaining \u0026gt; 0) readlen = remaining; /* 如果是主客户端，在遇到大参数时需要扩大读取长度，但不需要对齐到下一个参数，可以读取更多数据 */ if (c-\u0026gt;flags \u0026amp; CLIENT_MASTER \u0026amp;\u0026amp; readlen \u0026lt; PROTO_IOBUF_LEN) readlen = PROTO_IOBUF_LEN; } else if (c-\u0026gt;querybuf == NULL) { if (unlikely(thread_reusable_qb_used)) { /* 如果可重用的查询缓冲区已被其他客户端使用，切换到使用客户端的私有查询缓冲区。 * 这种情况仅在通过 processEventsWhileBlocked() 执行嵌套命令时发生。 */ c-\u0026gt;querybuf = sdsnewlen(NULL, PROTO_IOBUF_LEN); sdsclear(c-\u0026gt;querybuf); } else { /* 如果查询缓冲区不存在，则创建可重用的查询缓冲区 */ if (!thread_reusable_qb) { thread_reusable_qb = sdsnewlen(NULL, PROTO_IOBUF_LEN); sdsclear(thread_reusable_qb); } /* 将可重用的查询缓冲区分配给客户端，并标记为正在使用 */ serverAssert(sdslen(thread_reusable_qb) == 0); c-\u0026gt;querybuf = thread_reusable_qb; c-\u0026gt;flags |= CLIENT_REUSABLE_QUERYBUFFER; thread_reusable_qb_used = 1; } } qblen = sdslen(c-\u0026gt;querybuf); if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; // 主客户端的查询缓冲区可以贪婪扩展 (big_arg || sdsalloc(c-\u0026gt;querybuf) \u0026lt; PROTO_IOBUF_LEN)) { /* 在读取大参数时，我们不会读取超过一个参数的内容到查询缓冲区， * 所以不需要预分配多于所需的空间，因此使用非贪婪扩展。 */ c-\u0026gt;querybuf = sdsMakeRoomForNonGreedy(c-\u0026gt;querybuf, readlen); /* 稍后将峰值设置为已使用的部分，但这里我们过度分配，因为我们知道需要的空间，确保在使用前不会被缩小。 */ if (c-\u0026gt;querybuf_peak \u0026lt; qblen + readlen) c-\u0026gt;querybuf_peak = qblen + readlen; } else { c-\u0026gt;querybuf = sdsMakeRoomFor(c-\u0026gt;querybuf, readlen); /* 从套接字中尽可能多地读取数据，以节省 read(2) 系统调用次数。 */ readlen = sdsavail(c-\u0026gt;querybuf); } nread = connRead(c-\u0026gt;conn, c-\u0026gt;querybuf+qblen, readlen); if (nread == -1) { if (connGetState(conn) == CONN_STATE_CONNECTED) { goto done; } else { serverLog(LL_VERBOSE, \u0026#34;从客户端读取数据时出错: %s\u0026#34;, connGetLastError(c-\u0026gt;conn)); freeClientAsync(c); goto done; } } else if (nread == 0) { if (server.verbosity \u0026lt;= LL_VERBOSE) { sds info = catClientInfoString(sdsempty(), c); serverLog(LL_VERBOSE, \u0026#34;客户端关闭了连接 %s\u0026#34;, info); sdsfree(info); } freeClientAsync(c); goto done; } /* 更新查询缓冲区的长度 */ sdsIncrLen(c-\u0026gt;querybuf, nread); qblen = sdslen(c-\u0026gt;querybuf); if (c-\u0026gt;querybuf_peak \u0026lt; qblen) c-\u0026gt;querybuf_peak = qblen; /* 更新最后交互时间 */ c-\u0026gt;lastinteraction = server.unixtime; if (c-\u0026gt;flags \u0026amp; CLIENT_MASTER) { c-\u0026gt;read_reploff += nread; atomicIncr(server.stat_net_repl_input_bytes, nread); } else { atomicIncr(server.stat_net_input_bytes, nread); } /* 对于普通客户端，如果查询缓冲区的大小超过限制或需要身份验证，则关闭客户端连接 */ if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; /* MULTI/EXEC 队列中的命令尚未执行，因此它们也算作查询缓冲区的一部分 */ (c-\u0026gt;mstate.argv_len_sums + sdslen(c-\u0026gt;querybuf) \u0026gt; server.client_max_querybuf_len || (c-\u0026gt;mstate.argv_len_sums + sdslen(c-\u0026gt;querybuf) \u0026gt; 1024*1024 \u0026amp;\u0026amp; authRequired(c)))) { sds ci = catClientInfoString(sdsempty(),c), bytes = sdsempty(); bytes = sdscatrepr(bytes,c-\u0026gt;querybuf,64); serverLog(LL_WARNING,\u0026#34;关闭客户端，查询缓冲区超过最大限制: %s (查询缓冲区初始字节: %s)\u0026#34;, ci, bytes); sdsfree(ci); sdsfree(bytes); freeClientAsync(c); atomicIncr(server.stat_client_qbuf_limit_disconnections, 1); goto done; } /* 如果客户端输入缓冲区还有数据，继续解析并检查是否有完整的命令需要执行 */ if (processInputBuffer(c) == C_ERR) c = NULL; done: if (c \u0026amp;\u0026amp; (c-\u0026gt;flags \u0026amp; CLIENT_REUSABLE_QUERYBUFFER)) { serverAssert(c-\u0026gt;qb_pos == 0); /* 确保客户端的查询缓冲区在 processInputBuffer 中被修剪 */ resetReusableQueryBuf(c); } beforeNextClient(c); } processInputBuffer读取client请求信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 /* 该函数在每次客户端结构体 \u0026#39;c\u0026#39; 中有更多查询缓冲区需要处理时被调用， * 可能是因为我们从套接字读取了更多的数据，或者客户端被阻塞并在之后重新激活， * 所以可能存在待处理的查询缓冲区，这些缓冲区可能已经代表一个完整的命令需要处理。 * 如果在处理过程中客户端已经被释放，则返回 C_ERR */ int processInputBuffer(client *c) { /* 当输入缓冲区有内容时，继续处理 */ while(c-\u0026gt;qb_pos \u0026lt; sdslen(c-\u0026gt;querybuf)) { /* 如果客户端当前被阻塞，立即中止 */ if (c-\u0026gt;flags \u0026amp; CLIENT_BLOCKED) break; /* 如果客户端有待处理的命令，不要继续处理更多的缓冲区 */ if (c-\u0026gt;flags \u0026amp; CLIENT_PENDING_COMMAND) break; /* 如果客户端是主客户端，并且当前有忙碌脚本，暂停处理输入 */ if (isInsideYieldingLongCommand() \u0026amp;\u0026amp; c-\u0026gt;flags \u0026amp; CLIENT_MASTER) break; /* 如果设置了 CLIENT_CLOSE_AFTER_REPLY 标志，处理完回复后就关闭连接， * 不允许继续处理更多的命令 */ if (c-\u0026gt;flags \u0026amp; (CLIENT_CLOSE_AFTER_REPLY|CLIENT_CLOSE_ASAP)) break; /* 如果请求类型未知，判断请求类型 */ if (!c-\u0026gt;reqtype) { if (c-\u0026gt;querybuf[c-\u0026gt;qb_pos] == \u0026#39;*\u0026#39;) { c-\u0026gt;reqtype = PROTO_REQ_MULTIBULK; // 多批量请求 } else { c-\u0026gt;reqtype = PROTO_REQ_INLINE; // 单行命令 } } /* 根据请求类型处理缓冲区 */ if (c-\u0026gt;reqtype == PROTO_REQ_INLINE) { if (processInlineBuffer(c) != C_OK) break; // 处理单行命令 } else if (c-\u0026gt;reqtype == PROTO_REQ_MULTIBULK) { if (processMultibulkBuffer(c) != C_OK) break; // 处理多批量命令 } else { serverPanic(\u0026#34;Unknown request type\u0026#34;); // 未知的请求类型，程序崩溃 } /* 多批量请求处理可能导致 argc \u0026lt;= 0 */ if (c-\u0026gt;argc == 0) { resetClientInternal(c, 0); // 如果没有有效的参数，重置客户端 } else { /* 如果是 I/O 线程上下文，不能在此执行命令，只能标记客户端需要处理命令 */ if (io_threads_op != IO_THREADS_OP_IDLE) { serverAssert(io_threads_op == IO_THREADS_OP_READ); c-\u0026gt;flags |= CLIENT_PENDING_COMMAND; // 设置为待处理命令状态 break; } /* 准备好执行命令了 */ if (processCommandAndResetClient(c) == C_ERR) { /* 如果客户端已经不再有效，避免继续执行，直接返回 */ return C_ERR; } } } /* 如果客户端是主客户端，需要裁剪查询缓冲区 */ if (c-\u0026gt;flags \u0026amp; CLIENT_MASTER) { /* 如果客户端是主客户端，裁剪查询缓冲区到 repl_applied 指定的位置， * 因为主客户端的查询缓冲区不仅用于解析命令，还用于代理给子复制实例。 * * 需要裁剪查询缓冲区的场景： * 1. 没有接收到完整的命令 * 2. 主客户端因为客户端暂停而被阻塞 * 3. I/O 线程操作读取，主客户端被标记为 CLIENT_PENDING_COMMAND * * 在这些场景下，qb_pos 指向当前命令的一部分或下一个命令的开始位置， * 当前命令尚未应用，因此 repl_applied 不等于 qb_pos。*/ if (c-\u0026gt;repl_applied) { sdsrange(c-\u0026gt;querybuf, c-\u0026gt;repl_applied, -1); // 剩余的命令数据 c-\u0026gt;qb_pos -= c-\u0026gt;repl_applied; c-\u0026gt;repl_applied = 0; } } else if (c-\u0026gt;qb_pos) { /* 如果客户端不是主客户端，裁剪查询缓冲区 */ sdsrange(c-\u0026gt;querybuf, c-\u0026gt;qb_pos, -1); // 将查询缓冲区裁剪到当前位置 c-\u0026gt;qb_pos = 0; // 重置查询缓冲区位置 } /* 在处理查询缓冲区后更新客户端的内存使用情况， * 这对查询缓冲区比较大且没有在上述循环中被完全处理的客户端很重要（ * 例如部分发送的大命令）。*/ if (io_threads_op == IO_THREADS_OP_IDLE) updateClientMemUsageAndBucket(c); return C_OK; // 返回处理成功 } 协议解析 processInlineBuffer：set a b这样的简单命令 processMultibulkBuffer：mset a b c d这样的复合命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 /* 类似于 processMultibulkBuffer()，但是用于处理 inline 协议，而不是 RESP 协议。 * 该函数消耗客户端的查询缓冲区，并在客户端结构体中创建一个准备执行的命令。 * 如果命令已经准备好执行，则返回 C_OK；如果仍然需要读取更多协议数据才能形成一个有效的命令，则返回 C_ERR。 * 当出现协议错误时，返回 C_ERR；在这种情况下，客户端结构体会被设置为回复错误并关闭连接。 */ int processInlineBuffer(client *c) { char *newline; int argc, j, linefeed_chars = 1; sds *argv, aux; size_t querylen; /* 查找换行符的位置 */ newline = strchr(c-\u0026gt;querybuf + c-\u0026gt;qb_pos, \u0026#39;\\n\u0026#39;); /* 如果没有找到 \\r\\n 则返回，不做处理 */ if (newline == NULL) { if (sdslen(c-\u0026gt;querybuf) - c-\u0026gt;qb_pos \u0026gt; PROTO_INLINE_MAX_SIZE) { addReplyError(c, \u0026#34;Protocol error: too big inline request\u0026#34;); setProtocolError(\u0026#34;too big inline request\u0026#34;, c); } return C_ERR; } /* 处理 \\r\\n 的情况 */ if (newline != c-\u0026gt;querybuf + c-\u0026gt;qb_pos \u0026amp;\u0026amp; *(newline - 1) == \u0026#39;\\r\u0026#39;) { newline--; // 将 newline 指向 \\r 的前一个字符 linefeed_chars++; // 计算换行符的字符数 } /* 截取从当前指针到 \\r\\n 之间的内容 */ querylen = newline - (c-\u0026gt;querybuf + c-\u0026gt;qb_pos); aux = sdsnewlen(c-\u0026gt;querybuf + c-\u0026gt;qb_pos, querylen); // 创建一个新的 sds 字符串 argv = sdssplitargs(aux, \u0026amp;argc); // 分割命令行参数 sdsfree(aux); // 释放临时变量 aux if (argv == NULL) { addReplyError(c, \u0026#34;Protocol error: unbalanced quotes in request\u0026#34;); setProtocolError(\u0026#34;unbalanced quotes in inline request\u0026#34;, c); return C_ERR; } /* 如果查询长度为 0 且客户端是从属节点， * 则表示通过换行符刷新最后的 ACK 时间。 * 这是为了让从属节点在加载大型 RDB 文件时能够持续保持连接 */ if (querylen == 0 \u0026amp;\u0026amp; clientTypeIsSlave(c)) { c-\u0026gt;repl_ack_time = server.unixtime; } /* 主节点不应该发送 inline 协议来执行实际的命令。 * 如果发生这种情况，可能是 Redis 协议出现了同步问题， * 比如由于 PSYNC 出错导致的协议不一致。 * * 但是有一个例外：主节点可能只会发送一个换行符来保持连接活动。 */ if (querylen != 0 \u0026amp;\u0026amp; c-\u0026gt;flags \u0026amp; CLIENT_MASTER) { sdsfreesplitres(argv, argc); // 释放参数数组 serverLog(LL_WARNING, \u0026#34;WARNING: Receiving inline protocol from master, master stream corruption? Closing the master connection and discarding the cached master.\u0026#34;); setProtocolError(\u0026#34;Master using the inline protocol. Desync?\u0026#34;, c); return C_ERR; } /* 移动查询缓冲区位置，指向下一个查询命令 */ c-\u0026gt;qb_pos += querylen + linefeed_chars; /* 在客户端结构体中设置 argv 数组 */ if (argc) { /* 如果参数数量超过当前分配的空间，重新分配内存 */ if (unlikely(argc \u0026gt; c-\u0026gt;argv_len)) { zfree(c-\u0026gt;argv); // 释放旧的 argv c-\u0026gt;argv = zmalloc(sizeof(robj*) * argc); // 分配新的 argv 数组 c-\u0026gt;argv_len = argc; } c-\u0026gt;argv_len_sum = 0; // 重置参数长度总和 } /* 为所有的参数创建 Redis 对象 */ for (c-\u0026gt;argc = 0, j = 0; j \u0026lt; argc; j++) { c-\u0026gt;argv[c-\u0026gt;argc] = createObject(OBJ_STRING, argv[j]); // 创建字符串类型的 Redis 对象 c-\u0026gt;argc++; // 增加参数计数 c-\u0026gt;argv_len_sum += sdslen(argv[j]); // 更新参数总长度 } zfree(argv); // 释放临时分割后的参数数组 return C_OK; // 返回命令已准备好执行 } /* 处理客户端 \u0026#39;c\u0026#39; 的查询缓冲区，并为命令执行设置客户端的参数向量。 * 如果客户端有一个格式正确、准备执行的命令，返回 C_OK， * 否则，如果还需要更多的数据才能获得完整的命令，返回 C_ERR。 * 如果出现协议错误，返回 C_ERR；在这种情况下，客户端结构会被设置为回复错误并关闭连接。 * * 当 processInputBuffer() 检测到下一个命令是 RESP 格式时会调用此函数， * 因为命令的第一个字节是 \u0026#39;*\u0026#39;。否则，对于 inline 命令会调用 processInlineBuffer()。*/ int processMultibulkBuffer(client *c) { char *newline = NULL; int ok; long long ll; if (c-\u0026gt;multibulklen == 0) { /* 客户端应该已经被重置 */ serverAssertWithInfo(c, NULL, c-\u0026gt;argc == 0); /* 多重批量长度不能在没有 \\r\\n 的情况下读取 */ newline = strchr(c-\u0026gt;querybuf + c-\u0026gt;qb_pos, \u0026#39;\\r\u0026#39;); if (newline == NULL) { if (sdslen(c-\u0026gt;querybuf) - c-\u0026gt;qb_pos \u0026gt; PROTO_INLINE_MAX_SIZE) { addReplyError(c, \u0026#34;Protocol error: too big mbulk count string\u0026#34;); setProtocolError(\u0026#34;too big mbulk count string\u0026#34;, c); } return C_ERR; } /* 缓冲区中应也包含 \\n */ if (newline - (c-\u0026gt;querybuf + c-\u0026gt;qb_pos) \u0026gt; (ssize_t)(sdslen(c-\u0026gt;querybuf) - c-\u0026gt;qb_pos - 2)) return C_ERR; /* 确定这是一整行，因为 newline != NULL， * 所以可以继续解析多重批量长度 */ serverAssertWithInfo(c, NULL, c-\u0026gt;querybuf[c-\u0026gt;qb_pos] == \u0026#39;*\u0026#39;); ok = string2ll(c-\u0026gt;querybuf + 1 + c-\u0026gt;qb_pos, newline - (c-\u0026gt;querybuf + 1 + c-\u0026gt;qb_pos), \u0026amp;ll); if (!ok || ll \u0026gt; INT_MAX) { addReplyError(c, \u0026#34;Protocol error: invalid multibulk length\u0026#34;); setProtocolError(\u0026#34;invalid mbulk count\u0026#34;, c); return C_ERR; } else if (ll \u0026gt; 10 \u0026amp;\u0026amp; authRequired(c)) { addReplyError(c, \u0026#34;Protocol error: unauthenticated multibulk length\u0026#34;); setProtocolError(\u0026#34;unauth mbulk count\u0026#34;, c); return C_ERR; } c-\u0026gt;qb_pos = (newline - c-\u0026gt;querybuf) + 2; if (ll \u0026lt;= 0) return C_OK; c-\u0026gt;multibulklen = ll; /* 在客户端结构体中设置 argv 数组。 * 如果空间不足或者需要逐步分配空间，创建新的 argv */ if (unlikely(c-\u0026gt;multibulklen \u0026gt; c-\u0026gt;argv_len || c-\u0026gt;multibulklen \u0026gt; 1024)) { zfree(c-\u0026gt;argv); c-\u0026gt;argv_len = min(c-\u0026gt;multibulklen, 1024); c-\u0026gt;argv = zmalloc(sizeof(robj*) * c-\u0026gt;argv_len); } c-\u0026gt;argv_len_sum = 0; } serverAssertWithInfo(c, NULL, c-\u0026gt;multibulklen \u0026gt; 0); while (c-\u0026gt;multibulklen) { /* 如果未知，读取批量长度 */ if (c-\u0026gt;bulklen == -1) { newline = strchr(c-\u0026gt;querybuf + c-\u0026gt;qb_pos, \u0026#39;\\r\u0026#39;); if (newline == NULL) { if (sdslen(c-\u0026gt;querybuf) - c-\u0026gt;qb_pos \u0026gt; PROTO_INLINE_MAX_SIZE) { addReplyError(c, \u0026#34;Protocol error: too big bulk count string\u0026#34;); setProtocolError(\u0026#34;too big bulk count string\u0026#34;, c); return C_ERR; } break; } /* 缓冲区中也应该包含 \\n */ if (newline - (c-\u0026gt;querybuf + c-\u0026gt;qb_pos) \u0026gt; (ssize_t)(sdslen(c-\u0026gt;querybuf) - c-\u0026gt;qb_pos - 2)) break; if (c-\u0026gt;querybuf[c-\u0026gt;qb_pos] != \u0026#39;$\u0026#39;) { addReplyErrorFormat(c, \u0026#34;Protocol error: expected \u0026#39;$\u0026#39;, got \u0026#39;%c\u0026#39;\u0026#34;, c-\u0026gt;querybuf[c-\u0026gt;qb_pos]); setProtocolError(\u0026#34;expected $ but got something else\u0026#34;, c); return C_ERR; } ok = string2ll(c-\u0026gt;querybuf + c-\u0026gt;qb_pos + 1, newline - (c-\u0026gt;querybuf + c-\u0026gt;qb_pos + 1), \u0026amp;ll); if (!ok || ll \u0026lt; 0 || (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; ll \u0026gt; server.proto_max_bulk_len)) { addReplyError(c, \u0026#34;Protocol error: invalid bulk length\u0026#34;); setProtocolError(\u0026#34;invalid bulk length\u0026#34;, c); return C_ERR; } else if (ll \u0026gt; 16384 \u0026amp;\u0026amp; authRequired(c)) { addReplyError(c, \u0026#34;Protocol error: unauthenticated bulk length\u0026#34;); setProtocolError(\u0026#34;unauth bulk length\u0026#34;, c); return C_ERR; } c-\u0026gt;qb_pos = newline - c-\u0026gt;querybuf + 2; if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; ll \u0026gt;= PROTO_MBULK_BIG_ARG) { /* 如果客户端不是主节点（因为主节点的查询缓冲区只能在数据应用并发送给从节点后修剪）。 * * 如果我们将从网络读取一个较大的对象，尝试使其从 c-\u0026gt;querybuf 边界开始，这样可以优化对象创建， * 避免对数据进行大量复制。 * * 但是只有当未解析的数据长度小于或等于 ll+2 时才这样做。否则，修剪查询缓冲区就是浪费时间， * 因为此时查询缓冲区不仅仅包含我们的大批量数据。 */ if (sdslen(c-\u0026gt;querybuf) - c-\u0026gt;qb_pos \u0026lt;= (size_t)ll + 2) { sdsrange(c-\u0026gt;querybuf, c-\u0026gt;qb_pos, -1); c-\u0026gt;qb_pos = 0; /* 提示 sds 库有关字符串长度的预期 */ c-\u0026gt;querybuf = sdsMakeRoomForNonGreedy(c-\u0026gt;querybuf, ll + 2 - sdslen(c-\u0026gt;querybuf)); /* 我们后续会设置峰值为使用的部分，但此时超额分配是为了确保不会在使用前被缩小 */ if (c-\u0026gt;querybuf_peak \u0026lt; (size_t)ll + 2) c-\u0026gt;querybuf_peak = ll + 2; } } c-\u0026gt;bulklen = ll; } /* 读取批量参数 */ if (sdslen(c-\u0026gt;querybuf) - c-\u0026gt;qb_pos \u0026lt; (size_t)(c-\u0026gt;bulklen + 2)) { /* 数据不足（+2 是指尾部的 \\r\\n） */ break; } else { /* 检查是否有足够的空间存储参数，如果没有则进行扩展 */ if (c-\u0026gt;argc \u0026gt;= c-\u0026gt;argv_len) { c-\u0026gt;argv_len = min(c-\u0026gt;argv_len \u0026lt; INT_MAX / 2 ? c-\u0026gt;argv_len * 2 : INT_MAX, c-\u0026gt;argc + c-\u0026gt;multibulklen); c-\u0026gt;argv = zrealloc(c-\u0026gt;argv, sizeof(robj*) * c-\u0026gt;argv_len); } /* 优化：如果非主节点客户端的缓冲区仅包含我们的批量元素， * 那么直接使用当前的 sds 字符串而不是通过复制创建一个新的对象 */ if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; c-\u0026gt;qb_pos == 0 \u0026amp;\u0026amp; c-\u0026gt;bulklen \u0026gt;= PROTO_MBULK_BIG_ARG \u0026amp;\u0026amp; sdslen(c-\u0026gt;querybuf) == (size_t)(c-\u0026gt;bulklen + 2)) { c-\u0026gt;argv[c-\u0026gt;argc++] = createObject(OBJ_STRING, c-\u0026gt;querybuf); c-\u0026gt;argv_len_sum += c-\u0026gt;bulklen; sdsIncrLen(c-\u0026gt;querybuf, -2); /* 去除 CRLF */ /* 假设如果我们看到一个大的参数，接下来可能会看到另一个类似的 */ c-\u0026gt;querybuf = sdsnewlen(SDS_NOINIT, c-\u0026gt;bulklen + 2); sdsclear(c-\u0026gt;querybuf); } else { c-\u0026gt;argv[c-\u0026gt;argc++] = createStringObject(c-\u0026gt;querybuf + c-\u0026gt;qb_pos, c-\u0026gt;bulklen); c-\u0026gt;argv_len_sum += c-\u0026gt;bulklen; c-\u0026gt;qb_pos += c-\u0026gt;bulklen + 2; } c-\u0026gt;bulklen = -1; c-\u0026gt;multibulklen--; } } /* 当 c-\u0026gt;multibulklen 为 0 时，表示命令处理完成 */ if (c-\u0026gt;multibulklen == 0) return C_OK; /* 仍然没有准备好处理命令 */ return C_ERR; } processCommand处理命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 /* 这个函数调用 processCommand()，同时执行一些对于客户端来说有用的额外任务： * * 1. 将当前客户端设置为 \u0026#39;c\u0026#39;。 * 2. 如果命令已处理，则调用 commandProcessed()。 * * 如果处理命令过程中客户端被释放，则返回 C_ERR，否则返回 C_OK。 */ int processCommandAndResetClient(client *c) { int deadclient = 0; client *old_client = server.current_client; // 设置当前处理的客户端为 \u0026#39;c\u0026#39; server.current_client = c; // 处理命令 if (processCommand(c) == C_OK) { // 如果命令成功处理，调用 commandProcessed() commandProcessed(c); // 更新客户端的内存使用情况，考虑到命令执行后可能导致输出缓冲区的增长 if (c-\u0026gt;conn) updateClientMemUsageAndBucket(c); } // 检查当前客户端是否为空，如果为空表示客户端已经被释放 if (server.current_client == NULL) deadclient = 1; /* * 恢复之前的客户端设置。这个恢复是必要的，因为在脚本超时的情况下， * 我们会从 processEventsWhileBlocked 中进入该代码，这会导致设置 server.current_client。 * 如果不恢复，可能会错误地返回 1，表示客户端已经死掉，并停止从客户端缓冲区读取数据。 */ server.current_client = old_client; // performEvictions 可能会刷新从节点的输出缓冲区，这可能导致 // 从节点（可能是当前活动的客户端）被释放。 return deadclient ? C_ERR : C_OK; } 返回写入的resp给client：initServer -\u0026gt; aeSetBeforeSleepProc -\u0026gt; beforeSleep -\u0026gt; handleClientsWithPendingWritesUsingThreads -\u0026gt; sendReplyToClient 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 /* 将数据写入客户端的输出缓冲区。如果客户端在调用后仍然有效，返回 C_OK， * 如果因错误而被释放，返回 C_ERR。如果设置了 handler_installed，则会尝试清除写事件。 * * 该函数由线程调用，但总是将 handler_installed 设置为 0。因此，当 handler_installed 设置为 0 时， * 该函数必须是线程安全的。*/ int writeToClient(client *c, int handler_installed) { /* 更新服务器的总写入次数 */ atomicIncr(server.stat_total_writes_processed, 1); ssize_t nwritten = 0, totwritten = 0; /* 循环写入客户端的待处理回复 */ while(clientHasPendingReplies(c)) { int ret = _writeToClient(c, \u0026amp;nwritten); if (ret == C_ERR) break; totwritten += nwritten; /* 注意：我们避免一次写入超过 NET_MAX_WRITES_PER_EVENT 字节。 * 在单线程服务器中，即使来自超高速链接的大请求总是能接受数据， * 也应该服务其他客户端（在实际场景中可以考虑 \u0026#39;KEYS *\u0026#39; 命令通过回环接口）。 * * 然而，如果超出了最大内存限制，我们会忽略此限制，尽可能地发送数据。 * * 此外，如果客户端是从节点或监视器，我们会尽可能多地发送数据， * 否则，在高速流量下，复制/输出缓冲区可能会无限增长。*/ if (totwritten \u0026gt; NET_MAX_WRITES_PER_EVENT \u0026amp;\u0026amp; (server.maxmemory == 0 || zmalloc_used_memory() \u0026lt; server.maxmemory) \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_SLAVE)) break; } /* 更新统计信息，记录已经发送的字节数 */ if (unlikely(clientTypeIsSlave(c))) { atomicIncr(server.stat_net_repl_output_bytes, totwritten); } else { atomicIncr(server.stat_net_output_bytes, totwritten); } /* 检查写入是否成功 */ if (nwritten == -1) { if (connGetState(c-\u0026gt;conn) != CONN_STATE_CONNECTED) { serverLog(LL_VERBOSE, \u0026#34;Error writing to client: %s\u0026#34;, connGetLastError(c-\u0026gt;conn)); freeClientAsync(c); return C_ERR; } } /* 如果有数据写入，更新客户端的最后交互时间 */ if (totwritten \u0026gt; 0) { /* 对于表示主节点的客户端，不计算发送数据作为一次交互， * 因为我们总是发送 REPLCONF ACK 命令，这些命令只占用一些时间来填充套接字输出缓冲区。 * 我们仅依赖接收到的数据或 ping 命令来检测超时。 */ if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER)) c-\u0026gt;lastinteraction = server.unixtime; } /* 如果客户端没有待处理的回复 */ if (!clientHasPendingReplies(c)) { c-\u0026gt;sentlen = 0; /* 请注意，writeToClient() 是在线程中调用的，但 aeDeleteFileEvent() 不是线程安全的： * 然而，由于 writeToClient() 总是在线程中将 handler_installed 设置为 0， * 所以我们可以放心。*/ if (handler_installed) { serverAssert(io_threads_op == IO_THREADS_OP_IDLE); connSetWriteHandler(c-\u0026gt;conn, NULL); } /* 在发送完整回复后关闭连接。 */ if (c-\u0026gt;flags \u0026amp; CLIENT_CLOSE_AFTER_REPLY) { freeClientAsync(c); return C_ERR; } } /* 在写入数据后更新客户端的内存使用情况。 * 由于这不是线程安全的，所以我们会有条件地执行此操作。 * 如果是多线程写入，则将在 handleClientsWithPendingWritesUsingThreads() 中处理。*/ if (io_threads_op == IO_THREADS_OP_IDLE) updateClientMemUsageAndBucket(c); return C_OK; } 内核函数分析 doc：https://man7.org/linux/man-pages/man7/epoll.7.html\nepoll_create int epoll_create(int size);\n参数介绍 size：这个参数是建议值，用于指定内部事件数组的大小。实际应用中，这个值一般可以传入一个合适的值，epoll 内部会根据操作系统的能力来分配内存。此参数已经在 Linux 2.6.8 中被废弃，并且没有实际意义，但为了兼容，依然存在。\n返回值 fd文件描述符id。\nepoll_ctl int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);\n参数介绍 epfd：通过 epoll_create 创建的 epoll 文件描述符。\nop：操作类型，EPOLL_CTL_ADD、EPOLL_CTL_MOD 和 EPOLL_CTL_DEL 分别表示添加、修改和删除文件描述符的操作。\nfd：要监控的文件描述符。\nevent：指定需要监控的事件，类型为 struct epoll_event，它定义了感兴趣的事件类型（如 EPOLLIN、EPOLLOUT、EPOLLRDHUP 等）以及一个用户自定义数据字段。\n返回值 0：成功\n-1：失败\nepoll_wait int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);\n参数介绍 epfd：通过 epoll_create 创建的 epoll 文件描述符。\nevents：一个数组，用于存放返回的事件。\nmaxevents：指定返回的最大事件数。如果有更多的事件发生，则需要调用多次 epoll_wait。\ntimeout：等待时间（毫秒）。如果设置为 -1，则会无限期阻塞，直到有事件发生。如果设置为 0，则立刻返回，不会阻塞。\n返回值 0：成功\n-1：失败\n边缘触发 \u0026amp; 水平触发 边缘触发et：状态发生变更才通知 水平触发lt：可读/写则通知 特性 水平触发（LT） 边缘触发（ET） 事件通知 一旦满足条件就会持续通知，直到事件被处理完 只在状态变化时通知一次，后续不再通知，直到状态再次变化 事件类型 当文件描述符的状态符合条件时（例如，有数据可读），会持续触发事件，直到条件被处理 只会在文件描述符的状态从“未就绪”变为“就绪”时触发一次事件 处理要求 处理一次事件后，可能会有更多的事件继续被通知 处理完事件后，必须尽可能多地处理数据，否则会错过后续事件 适用场景 适合简单场景，容易处理 适合高并发和高性能要求的场景，减少事件通知的次数 控制 由epoll_ctl注册的event.events控制，event：指定需要监控的事件，类型为 struct epoll_event，它定义了感兴趣的事件类型（如 EPOLLIN、EPOLLOUT、EPOLLRDHUP 等）以及一个用户自定义数据字段。\n当传入事件类型EPOLLET时，该fd为边缘触发。\n默认情况为水平触发。\n对于redis而言，使用的均为水平触发 nginx中存在边缘触发的使用 epoll_wait如何实现等待 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 static int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, struct timespec64 *timeout) { int res, eavail, timed_out = 0; u64 slack = 0; wait_queue_entry_t wait; ktime_t expires, *to = NULL; lockdep_assert_irqs_enabled(); // 如果有超时时间，并且不为零，则转换超时时间为ktime格式 if (timeout \u0026amp;\u0026amp; (timeout-\u0026gt;tv_sec | timeout-\u0026gt;tv_nsec)) { slack = select_estimate_accuracy(timeout); to = \u0026amp;expires; *to = timespec64_to_ktime(*timeout); } else if (timeout) { // 如果超时时间为零，表示非阻塞操作 timed_out = 1; } // 检查是否有可用的事件 eavail = ep_events_available(ep); while (1) { // 如果有事件，则将事件发送到用户空间 if (eavail) { res = ep_send_events(ep, events, maxevents); if (res) { // 如果发送成功，挂起 NAPI 中断 if (res \u0026gt; 0) ep_suspend_napi_irqs(ep); return res; } } // 如果超时标志为真，直接返回 if (timed_out) return 0; // 如果没有事件，执行忙等待 eavail = ep_busy_loop(ep, timed_out); if (eavail) continue; // 检查是否有信号中断 if (signal_pending(current)) return -EINTR; // 初始化等待队列 init_wait(\u0026amp;wait); wait.func = ep_autoremove_wake_function; // 加锁，检查事件是否可用 write_lock_irq(\u0026amp;ep-\u0026gt;lock); __set_current_state(TASK_INTERRUPTIBLE); // 再次检查是否有可用事件 eavail = ep_events_available(ep); if (!eavail) // 如果没有事件，加入到等待队列 __add_wait_queue_exclusive(\u0026amp;ep-\u0026gt;wq, \u0026amp;wait); write_unlock_irq(\u0026amp;ep-\u0026gt;lock); // 如果没有事件，调用高精度定时器进行等待 if (!eavail) timed_out = !schedule_hrtimeout_range(to, slack, HRTIMER_MODE_ABS); // 设置当前任务为运行状态 __set_current_state(TASK_RUNNING); // 被唤醒后检查是否有事件 eavail = 1; // 如果等待队列不为空，移除当前等待条目 if (!list_empty_careful(\u0026amp;wait.entry)) { write_lock_irq(\u0026amp;ep-\u0026gt;lock); if (timed_out) // 如果超时，则再次检查等待队列是否为空 eavail = list_empty(\u0026amp;wait.entry); // 从等待队列中移除当前条目 __remove_wait_queue(\u0026amp;ep-\u0026gt;wq, \u0026amp;wait); write_unlock_irq(\u0026amp;ep-\u0026gt;lock); } } } 总结 阻塞实现：当没有事件发生且超时条件为 -1 时，ep_poll 会通过将当前进程加入到等待队列中来实现阻塞，直到事件发生或者超时。\n忙等待的作用：忙等待是在没有事件的情况下不断轮询检查事件队列，如果有事件，则立即处理。如果没有事件，则避免过早地阻塞。\n等待队列的加入：在忙等待检查之后，ep_poll 会在确认没有事件且没有超时时，将进程加入等待队列。等待队列保证了进程可以被挂起，直到有事件发生或者超时。\n一直没有事件发生的例子 没有事件的情况下，eavail 会持续为 0。\nep_events_available，返回0，当 eavail == 0 时，代码会先进入忙等待阶段，并尝试重新检查是否有事件。 避免直接进入阻塞，提高执行效率（类似jvm中先轻量级cas锁，满足一定条件后再升级为依赖os的重锁） 如果经过忙等待仍然没有事件，ep_busy_loop返回0，此时 eavail == 0 ，epoll 会进入等待队列并阻塞当前线程，直到事件发生。 当进程被唤醒后，eavail 被强制设置为 1，表示进入下一轮事件的处理。 ","date":"2024-11-20T03:44:33+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BD-reids-%E9%80%9A%E4%BF%A1/","title":"高性能 reids-通信"},{"content":"","date":"2024-09-15T00:59:34+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BDmysql-%E4%BA%8B%E5%8A%A1%E4%B8%8Exlog/","title":"高性能MySql-事务与xlog"},{"content":"","date":"2024-09-15T00:58:54+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BDmysql-%E7%B4%A2%E5%BC%95/","title":"高性能MySql-索引"},{"content":"","date":"2024-09-15T00:58:40+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BDmysql-%E9%80%9A%E4%BF%A1/","title":"高性能MySql-通信"},{"content":"MySQL概览 关系型（行存储） 持久化（硬盘/外存） 事务支持（ACID） OLTP（on-line transaction processing） 通常用于主业务侧场景，例如电商购物、旅游购票、外卖下单等场景。\n区分于非主业务侧，会存在诸如商业分析、ai训练数据、用户画像等B端应用场景。此时MySQL也会被用作Data Lake数据湖的数据源，通过一些同步方式，例如binlog订阅、kafka-connector + 流式计算组件 flink/spark 传输至Elastic Search、Cassandra、Hbase等这样的OLAP（on-line analysis processing）大数据存储组件，而后B端工作人员基于这些OLAP组件进行后续的操作。\n架构 client/server\nbinlog\n源码结构（核心） client：客户端实现 sql：服务端实现 auth binlog optimizer parser key lock mysqld sql-command sql-connect storage：存储引擎实现 innobase myisam vio：virtual io，系统io的抽象层 省略include、share、route、test、script等非核心内容。\n流程 client端发起通信请求，通过tcp建立连接connection。 server端进行user/password鉴权（auth）。 数据库mysql的user表中进行验证。 验证通过后，通过mysql 的权限表（mysql中的 user、db、columns_privilege、Host 表，分别存储的是全局级别、数据库级别、表级别、列级别）查询当前用户的权限。 client端通过connection发送执行的sql脚本语句。 server端收到sql后对查询操作进行缓存判定（cache）。 在 MYSQL5.6以后默认关闭缓存，并且在 8.0 后功能置为Deprecated废弃，不推荐使用。原因是：在大多数使用场景下cache命中率过低（必须是两个完全一致的查询语句才能命中缓存）。 server端缓存未命中则进行sql解析（parser）。 from -\u0026gt; on -\u0026gt; join -\u0026gt; where -\u0026gt; group by -\u0026gt; having+聚合函数 -\u0026gt; select -\u0026gt; order by -\u0026gt; limit server端解析成功后优化器会根据索引信息选择相对最佳方案（optimizer）。 优化器会根据扫描行数、是否使用临时表、是否排序等来判断是否使用某个索引，其中扫描行数的计算可以通过统计信息来估算得出。 统计信息可以看作是索引唯一数的数量，mysql内部通过部分采样来估算：具体就是选择 N 个数据页，统计这些页上数据的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了。 由于索引数据会变化，所以索引的统计信息也会变化。当变更的数据行数超过 1/M 的时候，就会重新计算一次统计信息。也可以通过 \u0026ldquo;analyze table 表名\u0026rdquo; 来重新计算索引的统计信息。 统计信息是否持久化：通过innodb_stats_persistent，设置为 on 的时候，表示统计信息会持久化存储。持久化存储开启时，默认的 N 是 20，M 是 10。设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。 server端将优化器选择的索引方案交由存储引擎执行器进行数据查询（executor）。 server端将查询结果写入缓存 \u0026amp; 返回给client端。 client端接收到返回结果，完成sql操作。 如果client端是通过sdk（编程语言connector）进行连接，后续则可以通过一些orm框架进行table - model映射。 优化器 - 实操理解 建表 \u0026amp; 查询该表的统计信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 create table t_user( id bigint auto_increment comment \u0026#39;pk id\u0026#39; primary key, username varchar(256) not null, real_name varchar(32) default \u0026#39;\u0026#39; not null, nick_name varchar(32) default \u0026#39;\u0026#39; not null, password varchar(256) not null, phone_number varchar(16) default \u0026#39;\u0026#39; not null, locale varchar(8) default \u0026#39;\u0026#39; not null, country varchar(2) default \u0026#39;\u0026#39; not null ) comment \u0026#39;user table\u0026#39;; create index idx_country_locale_user on t_user (country, locale, username); create index idx_locale_user on t_user (locale, username); create index idx_real_name on t_user (real_name); select * from mysql.innodb_index_stats where table_name = \u0026#39;t_user\u0026#39;; 返回结果：\n# database_name table_name index_name last_update stat_name stat_value sample_size stat_description 1 db_rag_application t_user PRIMARY 2024/9/21 15:27 n_diff_pfx01 0 1 id 2 db_rag_application t_user PRIMARY 2024/9/21 15:27 n_leaf_pages 1 Number of leaf pages in the index 3 db_rag_application t_user PRIMARY 2024/9/21 15:27 size 1 Number of pages in the index 4 db_rag_application t_user idx_country_locale_user 2024/9/21 15:27 n_diff_pfx01 0 1 country 5 db_rag_application t_user idx_country_locale_user 2024/9/21 15:27 n_diff_pfx02 0 1 country,locale 6 db_rag_application t_user idx_country_locale_user 2024/9/21 15:27 n_diff_pfx03 0 1 country,locale,username 7 db_rag_application t_user idx_country_locale_user 2024/9/21 15:27 n_diff_pfx04 0 1 country,locale,username,id 8 db_rag_application t_user idx_country_locale_user 2024/9/21 15:27 n_leaf_pages 1 Number of leaf pages in the index 9 db_rag_application t_user idx_country_locale_user 2024/9/21 15:27 size 1 Number of pages in the index 10 db_rag_application t_user idx_locale_user 2024/9/21 15:27 n_diff_pfx01 0 1 locale 11 db_rag_application t_user idx_locale_user 2024/9/21 15:27 n_diff_pfx02 0 1 locale,username 12 db_rag_application t_user idx_locale_user 2024/9/21 15:27 n_diff_pfx03 0 1 locale,username,id 13 db_rag_application t_user idx_locale_user 2024/9/21 15:27 n_leaf_pages 1 Number of leaf pages in the index 14 db_rag_application t_user idx_locale_user 2024/9/21 15:27 size 1 Number of pages in the index 15 db_rag_application t_user idx_real_name 2024/9/21 15:27 n_diff_pfx01 0 1 real_name 16 db_rag_application t_user idx_real_name 2024/9/21 15:27 n_diff_pfx02 0 1 real_name,id 17 db_rag_application t_user idx_real_name 2024/9/21 15:27 n_leaf_pages 1 Number of leaf pages in the index 18 db_rag_application t_user idx_real_name 2024/9/21 15:27 size 1 Number of pages in the index 总结 MySQL会对表中的每个索引建立统计数据，存放在mysql.innodb_index_stats 表中，表字段相对清晰，不赘述。 普通索引（secondary/covering）含有n个字段时，会保存n+1条不同组合（额外增加id统计）的统计数据。 例如user表中key (country, locale, user)，产生4个统计数据记录 country, locale, user country, locale country country, locale, user, id 根据以上索引的统计数据，优化器可以找到相对最优的索引，而后进行execute查询数据。 MySQL优化经典操作 \u0026amp; 实现源码 mysql-server大部分操作源码位于sql目录下：https://github.com/mysql/mysql-server/tree/8.4/sql\nexplain 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 // ignore head include class Item; class Query_block; class Query_expression; class Query_term; class String; class THD; struct AccessPath; struct TABLE; template \u0026lt;class T\u0026gt; class mem_root_deque; extern const char *join_type_str[]; /** Table modification plan for JOIN-less statements (update/delete) */ class Modification_plan { public: THD *const thd; ///\u0026lt; Owning thread const enum_mod_type mod_type; ///\u0026lt; Modification type - MT_INSERT/MT_UPDATE/etc TABLE *table; ///\u0026lt; Table to modify enum join_type type = JT_UNKNOWN; AccessPath *range_scan{nullptr}; Item *condition{nullptr}; uint key; ///\u0026lt; Key to use ha_rows limit; ///\u0026lt; Limit bool need_tmp_table; ///\u0026lt; Whether tmp table needs to be used bool need_sort; ///\u0026lt; Whether to use filesort bool used_key_is_modified; ///\u0026lt; Whether the key used to scan is modified const char *message; ///\u0026lt; Arbitrary message bool zero_result; ///\u0026lt; true \u0026lt;=\u0026gt; plan will not be executed ha_rows examined_rows; ///\u0026lt; # of rows expected to be examined in the table Modification_plan(THD *thd_arg, enum_mod_type mt, TABLE *table_arg, enum join_type type_arg, AccessPath *quick_arg, Item *condition_arg, uint key_arg, ha_rows limit_arg, bool need_tmp_table_arg, bool need_sort_arg, bool used_key_is_modified_arg, ha_rows rows); Modification_plan(THD *thd_arg, enum_mod_type mt, TABLE *table_arg, const char *message_arg, bool zero_result_arg, ha_rows rows); ~Modification_plan(); private: void register_in_thd(); }; /** 这个类用于实现对 INSERT、REPLACE 和多表 UPDATE/DELETE 的 EXPLAIN 功能。它会在执行过程中取消对数据的实际修改。 通过重写 prepare()、start_execution() 和 cleanup() 方法，保证在准备和执行时调用底层的拦截器，但不会进行实际的数据修改。 原文（部分）：it suppresses table data modification by the underlying interceptor object. Thus, we can use Query_result_explain object in the context of EXPLAIN INSERT/ REPLACE/UPDATE/DELETE query like we use Query_result_send in the context of EXPLAIN SELECT command */ class Query_result_explain : public Query_result_send { protected: /** Pointer to underlying Query_result_insert, Query_result_update or Query_result_delete object. */ Query_result *interceptor; public: Query_result_explain(Query_expression *unit_arg, Query_result *interceptor_arg) : Query_result_send(), interceptor(interceptor_arg) { unit = unit_arg; } bool use_protocol_adapter() const override { return false; } protected: bool prepare(THD *thd, const mem_root_deque\u0026lt;Item *\u0026gt; \u0026amp;list, Query_expression *u) override { return Query_result_send::prepare(thd, list, u) || interceptor-\u0026gt;prepare(thd, list, u); } bool start_execution(THD *thd) override { return Query_result_send::start_execution(thd) || interceptor-\u0026gt;start_execution(thd); } void cleanup() override { Query_result_send::cleanup(); interceptor-\u0026gt;cleanup(); } }; /** * Wrapper class for writing EXPLAIN output to a user variable. * * This class overrides Query_result_send::send_data() to write the output of * the EXPLAIN query to the user variable specified by m_variable_name. */ class Query_result_explain_into_var final : public Query_result_explain { public: Query_result_explain_into_var(Query_expression *expr, Query_result *child, std::string_view variable_name) : Query_result_explain(expr, child), m_variable_name(variable_name) {} bool send_result_set_metadata(THD *, const mem_root_deque\u0026lt;Item *\u0026gt; \u0026amp;, uint) override { return false; } bool send_data(THD *thd, const mem_root_deque\u0026lt;Item *\u0026gt; \u0026amp;items) override; bool send_eof(THD *thd) override; private: std::string_view m_variable_name; }; // explain单表CUD写操作函数 bool explain_single_table_modification(THD *explain_thd, const THD *query_thd, const Modification_plan *plan, Query_block *select); // explain复杂CRUD操作函数 bool explain_query(THD *explain_thd, const THD *query_thd, Query_expression *unit); // 多个query block查询块（子查询，细节可查询query_term.h内容）时，会调用这个函数，相当于explain_query的进阶函数，可能会被explain_query多次调用 bool explain_query_specification(THD *explain_thd, const THD *query_thd, Query_term *query_term, enum_parsing_context ctx); class Sql_cmd_explain_other_thread final : public Sql_cmd { public: explicit Sql_cmd_explain_other_thread(my_thread_id thread_id) : m_thread_id(thread_id) {} enum_sql_command sql_command_code() const override { return SQLCOM_EXPLAIN_OTHER; } bool execute(THD *thd) override; private: /// connection_id in EXPLAIN FOR CONNECTION \\\u0026lt;connection_id\\\u0026gt; my_thread_id m_thread_id; }; // Used to generate the \u0026#34;query\u0026#34; field in JSON explain object. void print_query_for_explain(const THD *query_thd, Query_expression *unit, String *str); #endif /* OPT_EXPLAIN_INCLUDED */ 这里实现源码过多，感兴趣自行阅读。\nstatistic 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 struct TABLE; typedef float rec_per_key_t; class KEY; /** 这里内容较少且命名清晰，直接参考原文 Guesstimate for \u0026#34;records per key\u0026#34; when index statistics is not available. @param table the table @param key the index @param used_keyparts the number of key part that should be included in the estimate @return estimated records per key value */ rec_per_key_t guess_rec_per_key(const TABLE *const table, const KEY *const key, uint used_keyparts); #endif /* OPT_STATISTICS_INCLUDED */ // 实现：opt_statistic.cc rec_per_key_t guess_rec_per_key(const TABLE *const table, const KEY *const key, uint used_keyparts) { // 参数校验 assert(used_keyparts \u0026gt;= 1); assert(used_keyparts \u0026lt;= key-\u0026gt;actual_key_parts); assert(!key-\u0026gt;has_records_per_key(used_keyparts - 1)); // 从 table 对象中获取总记录数 const ha_rows table_rows = table-\u0026gt;file-\u0026gt;stats.records; /* 预估key匹配records： 如果统计信息中有key匹配的records记录就直接使用 没有的话唯一索引默认匹配一个，普通索引默认匹配10个 */ rec_per_key_t rec_per_key_all; if (key-\u0026gt;has_records_per_key(key-\u0026gt;user_defined_key_parts - 1)) rec_per_key_all = key-\u0026gt;records_per_key(key-\u0026gt;user_defined_key_parts - 1); else { if (key-\u0026gt;actual_flags \u0026amp; HA_NOSAME) rec_per_key_all = 1.0f; // Unique index else { rec_per_key_all = 10.0f; // Non-unique index /* 之前假设普通索引匹配10条，如果是很小的这里需要调整实际匹配量 */ rec_per_key_all = std::min(rec_per_key_all, max(rec_per_key_t(table_rows) / 10, 1.0f)); } } rec_per_key_t rec_per_key; // 假设第一个键部分匹配1%的记录，总体记录数的1%作为估算 const rec_per_key_t rec_per_key_first = table_rows * 0.01f; if (rec_per_key_first \u0026lt; rec_per_key_all) { // 第一部分的估算小于完整键的估算，直接使用完整键的估算。 rec_per_key = rec_per_key_all; } else { if (key-\u0026gt;user_defined_key_parts \u0026gt; 1) { // See formula above：随着使用的键部分数量的增加，记录的匹配数量将相应调整 rec_per_key = rec_per_key_first - (rec_per_key_t(used_keyparts - 1) / (key-\u0026gt;user_defined_key_parts - 1)) * (rec_per_key_first - rec_per_key_all); } else { // 对于单列索引，依据索引的唯一性直接返回相应的估算值。 if (key-\u0026gt;actual_flags \u0026amp; HA_NOSAME) rec_per_key = 1.0f; // Unique index else rec_per_key = rec_per_key_first; // Non-unique index } assert(rec_per_key \u0026gt;= rec_per_key_all); } return rec_per_key; } 其中存在部分外部函数：均来自于key.h\nhas_records_per_key records_per_key 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 // 内存中的索引数据结构 class KEY { public: /** Tot length of key */ uint key_length{0}; /** dupp key and pack flags */ ulong flags{0}; /** dupp key and pack flags for actual key parts */ ulong actual_flags{0}; /** How many key_parts */ uint user_defined_key_parts{0}; /** How many key_parts including hidden parts */ uint actual_key_parts{0}; /** Key parts allocated for primary key parts extension but not used due to some reasons(no primary key, duplicated key parts) */ uint unused_key_parts{0}; /** Should normally be = actual_key_parts */ uint usable_key_parts{0}; uint block_size{0}; /// @cond Doxygen_is_confused enum ha_key_alg algorithm { HA_KEY_ALG_SE_SPECIFIC }; /// @endcond /** A flag which indicates that index algorithm for this key was explicitly specified by user. So, for example, it should be mentioned in SHOW CREATE TABLE output. */ bool is_algorithm_explicit{false}; /** Note that parser is used when the table is opened for use, and parser_name is used when the table is being created. */ /** Fulltext [pre]parser */ plugin_ref parser{nullptr}; /** Fulltext [pre]parser name */ LEX_CSTRING parser_name{nullptr, 0}; KEY_PART_INFO *key_part{nullptr}; /** Name of key */ const char *name{nullptr}; /** Array of AVG(number of records with the same field value) for 1st ... Nth key part. 0 means \u0026#39;not known\u0026#39;. For internally created temporary tables, this member can be nullptr. */ ulong *rec_per_key{nullptr}; /** @retval true if this is a functional index (at least one of the key parts is a functional key part). @retval false if this isn\u0026#39;t a functional index. */ bool is_functional_index() const; // Can\u0026#39;t use in-class initialization as long as we memset-initialize // the struct LEX_CSTRING engine_attribute{nullptr, 0}; LEX_CSTRING secondary_engine_attribute{nullptr, 0}; private: /** Estimate for how much of the index data that is currently available in a memory buffer. Valid range is [0..1]. This will be initialized to a IN_MEMORY_ESTIMATE_UNKNOWN. If it still has this value when used, it means that the storage engine has not supplied a value. */ double m_in_memory_estimate{0.0}; /** 这里就是每一个索引匹配的records数量数据结构，通过指针存了一个float数组 Array of AVG(number of records with the same field value) for 1st ... Nth key part. For internally created temporary tables, this member can be nullptr. This is the same information as stored in the above rec_per_key array but using float values instead of integer values. If the storage engine has supplied values in this array, these will be used. Otherwise the value in rec_per_key will be used. @todo In the next release the rec_per_key array above should be removed and only this should be used. */ rec_per_key_t *rec_per_key_float{nullptr}; public: /** True if this index is visible to the query optimizer. The optimizer may only use visible indexes. */ bool is_visible{false}; TABLE *table{nullptr}; LEX_CSTRING comment{nullptr, 0}; /** Check if records per key estimate is available for given key part. @param key_part_no key part number, must be in [0, KEY::actual_key_parts) @return true if records per key estimate is available, false otherwise */ bool has_records_per_key(uint key_part_no) const { assert(key_part_no \u0026lt; actual_key_parts); return ((rec_per_key_float \u0026amp;\u0026amp; rec_per_key_float[key_part_no] != REC_PER_KEY_UNKNOWN) || (rec_per_key \u0026amp;\u0026amp; rec_per_key[key_part_no] != 0)); } /** Retrieve an estimate for the average number of records per distinct value, when looking only at the first key_part_no+1 columns. If no record per key estimate is available for this key part, REC_PER_KEY_UNKNOWN is returned. @param key_part_no key part number, must be in [0, KEY::actual_key_parts) @return Number of records having the same key value @retval REC_PER_KEY_UNKNOWN no records per key estimate available @retval != REC_PER_KEY_UNKNOWN record per key estimate */ rec_per_key_t records_per_key(uint key_part_no) const { assert(key_part_no \u0026lt; actual_key_parts); /* If the storage engine has provided rec per key estimates as float then use this. If not, use the integer version. */ if (rec_per_key_float[key_part_no] != REC_PER_KEY_UNKNOWN) return rec_per_key_float[key_part_no]; return (rec_per_key[key_part_no] != 0) ? static_cast\u0026lt;rec_per_key_t\u0026gt;(rec_per_key[key_part_no]) : REC_PER_KEY_UNKNOWN; } } 这里代码量较少，可以比较直观的理解mysql优化器统计索引效率的流程。\n存储引擎（索引） innoDB 事务支持 mvcc 行锁 redolog \u0026amp; undolog .ibd文件存索引+数据 InnoDB的文件结构可以划分为多个段（segment）、区（extent）、页（page）等层级。每个索引都存储在特定的段中，而每个段又由多个区组成，每个区包含多个页。在InnoDB中，页是磁盘和内存之间交换数据的最小单位，通常是16KB大小。 Feature Support B-tree indexes Yes Clustered indexes Yes Compressed data Yes Data caches Yes Foreign key support Yes Full-text search indexes Yes Geospatial data type support Yes Geospatial indexing support Yes Hash indexes No Index caches Yes Locking granularity Row MVCC Yes Storage limits 64TB T-tree indexes No Transactions Yes Update statistics for data dictionary Yes 架构 MyISAM 表锁 读多写少 .MYI文件存储索引信息，.MYD文件存储数据（查索引后需要回表） Feature Support B-tree indexes Yes Clustered indexes No Compressed data Yes (Compressed MyISAM tables are supported only when using the compressed row format. Tables using the compressed row format with MyISAM are read only.) Data caches No Foreign key support No Full-text search indexes Yes Geospatial data type support Yes Geospatial indexing support Yes Hash indexes No Index caches Yes Locking granularity Table MVCC No Storage limits 256TB T-tree indexes No Transactions No Update statistics for data dictionary Yes MEMORY 内存 hash Feature Support B-tree indexes Yes Clustered indexes No Compressed data No Data caches No Foreign key support No Full-text search indexes No Geospatial data type support No Geospatial indexing support No Hash indexes Yes Index caches No Locking granularity Table MVCC No Storage limits RAM T-tree indexes No Transactions No Update statistics for data dictionary Yes 其他存储引擎（略） CSV ARCHIVE MERGE 参考：\nhttps://dev.mysql.com/doc/refman/8.4/en/manual-info.html\nhttps://www.cnblogs.com/kerrycode/p/11821042.html\nhttps://github.com/mysql/mysql-server/tree/8.4/sql\n","date":"2024-09-15T00:58:29+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BDmysql-%E6%A6%82%E8%A7%88/","title":"高性能MySql-概览"},{"content":"","date":"2024-09-15T00:56:01+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E6%A1%86%E6%9E%B6-netty/","title":"高性能网络通信框架 Netty"},{"content":"","date":"2024-09-15T00:47:54+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BD%E9%AB%98%E5%8F%AF%E7%94%A8-reids-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/","title":"高性能\u0026高可用 reids-分布式集群"},{"content":"","date":"2024-09-15T00:45:33+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BD-reids-%E7%A9%BA%E9%97%B4%E6%95%88%E7%8E%87/","title":"高性能 reids-空间效率"},{"content":"","date":"2024-09-15T00:45:27+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BD-reids-%E6%97%B6%E9%97%B4%E6%95%88%E7%8E%87/","title":"高性能 reids-时间效率"},{"content":"数学基础： 高等数学：导数、微分、偏导数（多元函数导数）\n线性代数：向量、行列式、矩阵的基本运算、秩\n高等数学 导数 \\[ f'(x_0) = \\frac{dy}{dx} = \\lim_{x \\to x_0} \\frac{f(x) - f(x_0)}{x - x_0} \\]极限 ε δ 语言： 函数 $f(x)$ 在点 $x_0$ 的某一去心邻域内有定义。如果存在常数 $a$，对于任意的 $\\epsilon \u0026gt; 0$，都存在 $\\delta \u0026gt; 0$，使得在 $0 \u0026lt; |x - x_0| \u0026lt; \\delta$ 时，不等式 $|f(x) - a| \u0026lt; \\epsilon$ 恒成立。那么常数 $a$ 就叫做函数 $f(x)$ 当 $x \\to x_0$ 时的极限，记作： $$ \\lim_{x \\to x_0} f(x) = a $$微分 函数变化量 = 变化率 * 参数变化量 $$ df(x) = f'(x) \\, dx $$偏导 对于一个多元函数 $f(x_1, x_2, \\ldots, x_n)$，它在点 $(x_1^0, x_2^0, \\ldots, x_n^0)$ 处的偏导数相对于 $x_i$ 是： $$ \\frac{\\partial f}{\\partial x_i} = \\lim_{h \\to 0} \\frac{f(x_1^0, \\ldots, x_i^0 + h, \\ldots, x_n^0) - f(x_1^0, \\ldots, x_i^0, \\ldots, x_n^0)}{h} $$偏导的链式法则 假设我们有两个函数 $u = g(x_1, x_2, \\ldots, x_n)$ 和 $y = f(u)$，其中 $u$ 是 $x_1, x_2, \\ldots, x_n$ 的函数，而 $y$ 是 $u$ 的函数。我们希望找到 $y$ 对 $x_i$ 的偏导数。\n链式法则的定义是：\n$$ \\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial u} \\cdot \\frac{\\partial u}{\\partial x_i} $$其中：\n$\\frac{\\partial y}{\\partial u}$ 是 $y$ 对 $u$ 的偏导数。 $\\frac{\\partial u}{\\partial x_i}$ 是 $u$ 对 $x_i$ 的偏导数。 证明 全微分关系为： $$ dz = \\frac{\\partial z}{\\partial u} \\, du + \\frac{\\partial z}{\\partial v} \\, dv $$由于 $u$ 和 $v$ 是 $x$ 和 $y$ 的函数，我们有： $$ du = \\frac{\\partial u}{\\partial x} \\, dx + \\frac{\\partial u}{\\partial y} \\, dy $$$$ dv = \\frac{\\partial v}{\\partial x} \\, dx + \\frac{\\partial v}{\\partial y} \\, dy $$将这些代入全微分公式中，得到： $$ dz = \\left( \\frac{\\partial z}{\\partial u} \\frac{\\partial u}{\\partial x} + \\frac{\\partial z}{\\partial v} \\frac{\\partial v}{\\partial x} \\right) dx + \\left( \\frac{\\partial z}{\\partial u} \\frac{\\partial u}{\\partial y} + \\frac{\\partial z}{\\partial v} \\frac{\\partial v}{\\partial y} \\right) dy $$链式法则的偏导数 根据全微分关系，链式法则的偏导数为： $$ \\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial u} \\frac{\\partial u}{\\partial x} + \\frac{\\partial z}{\\partial v} \\frac{\\partial v}{\\partial x} $$$$ \\frac{\\partial z}{\\partial y} = \\frac{\\partial z}{\\partial u} \\frac{\\partial u}{\\partial y} + \\frac{\\partial z}{\\partial v} \\frac{\\partial v}{\\partial y} $$线性代数 向量的定义 向量是一个具有大小和方向的量，通常在多维空间中表示为一个有序的数列。一个 $n$ 维向量可以写作：\n$$ \\mathbf{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix} $$行列式的定义 行列式是一个方阵的一个标量值，它可以用来描述矩阵的某些性质，比如可逆性。对于一个 $n \\times n$ 的方阵 $A$，行列式记作 $\\det(A)$ 或 $|A|$，可以表示为：\n对于 $2 \\times 2$ 矩阵：\n$$ \\det \\begin{pmatrix} a \u0026 b \\\\ c \u0026 d \\end{pmatrix} = ad - bc $$对于 $3 \\times 3$ 矩阵：\n$$ \\det \\begin{pmatrix} a \u0026 b \u0026 c \\\\ d \u0026 e \u0026 f \\\\ g \u0026 h \u0026 i \\end{pmatrix} = aei + bfg + cdh - ceg - bdi - afh $$矩阵的定义 矩阵是一个按照矩形阵列排列的数值集合。一个 $m \\times n$ 的矩阵可以表示为：\n$$ A = \\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n} \\\\ a_{21} \u0026 a_{22} \u0026 \\cdots \u0026 a_{2n} \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ a_{m1} \u0026 a_{m2} \u0026 \\cdots \u0026 a_{mn} \\end{bmatrix} $$矩阵的基本运算 1. 矩阵加法 两个同型矩阵 $A$ 和 $B$ 的加法是元素对应相加，得到的新矩阵为： 如果 $$ A = \\begin{bmatrix} a_{11} \u0026 a_{12} \\\\ a_{21} \u0026 a_{22} \\end{bmatrix} $$$$ B = \\begin{bmatrix} b_{11} \u0026 b_{12} \\\\ b_{21} \u0026 b_{22} \\end{bmatrix} $$ 那么 $$ A + B = \\begin{bmatrix} a_{11} + b_{11} \u0026 a_{12} + b_{12} \\\\ a_{21} + b_{21} \u0026 a_{22} + b_{22} \\end{bmatrix} $$2. 矩阵减法 两个同型矩阵 $A$ 和 $B$ 的减法是元素对应相减，得到的新矩阵为： $$ A - B = \\begin{bmatrix} a_{11} - b_{11} \u0026 a_{12} - b_{12} \\\\ a_{21} - b_{21} \u0026 a_{22} - b_{22} \\end{bmatrix} $$3. 矩阵数乘 矩阵 $A$ 与标量 $k$ 的数乘是矩阵中每个元素都乘以 $k$，得到的新矩阵为： 如果 $$ A = \\begin{bmatrix} a_{11} \u0026 a_{12} \\\\ a_{21} \u0026 a_{22} \\end{bmatrix} $$ 那么 $$ kA = \\begin{bmatrix} ka_{11} \u0026 ka_{12} \\\\ ka_{21} \u0026 ka_{22} \\end{bmatrix} $$4. 矩阵乘法 两个矩阵 $A$ 和 $B$ 的乘法是矩阵 $A$ 的行向量与矩阵 $B$ 的列向量的内积，得到的新矩阵 $C$ 为： 如果 $$ A = \\begin{bmatrix} a_{11} \u0026 a_{12} \\\\ a_{21} \u0026 a_{22} \\end{bmatrix} $$$$ B = \\begin{bmatrix} b_{11} \u0026 b_{12} \\\\ b_{21} \u0026 b_{22} \\end{bmatrix} $$ 那么 $$ C = AB = \\begin{bmatrix} a_{11}b_{11} + a_{12}b_{21} \u0026 a_{11}b_{12} + a_{12}b_{22} \\\\ a_{21}b_{11} + a_{22}b_{21} \u0026 a_{21}b_{12} + a_{22}b_{22} \\end{bmatrix} $$5. 矩阵转置 矩阵 $A$ 的转置是将矩阵 $A$ 的行和列互换得到的新矩阵 $A^T$： 如果 $$ A = \\begin{bmatrix} a_{11} \u0026 a_{12} \\\\ a_{21} \u0026 a_{22} \\end{bmatrix} $$ 那么 $$ A^T = \\begin{bmatrix} a_{11} \u0026 a_{21} \\\\ a_{12} \u0026 a_{22} \\end{bmatrix} $$6. 矩阵的逆 矩阵 $A$ 的逆矩阵 $A^{-1}$ 是使得 $AA^{-1} = A^{-1}A = I$ 的矩阵，其中 $I$ 是单位矩阵。对于 $2 \\times 2$ 矩阵 $A$，如果行列式 $\\det(A) \\neq 0$，其逆矩阵为： 如果 $$ A = \\begin{bmatrix} a \u0026 b \\\\ c \u0026 d \\end{bmatrix} $$ 那么 $$ A^{-1} = \\frac{1}{\\det(A)} \\begin{bmatrix} d \u0026 -b \\\\ -c \u0026 a \\end{bmatrix} $$ 其中行列式 $\\det(A)$ 为： $$ \\det(A) = ad - bc $$7. 矩阵的秩 矩阵的秩（rank）是矩阵中线性无关的行（或列）的最大数量。矩阵的秩可以用来判断矩阵的行或列的线性独立性。\n对于一个 $m \\times n$ 的矩阵 $A$，秩定义为：\n矩阵 $A$ 的行秩：矩阵 $A$ 的最大线性无关的行的数量。 矩阵 $A$ 的列秩：矩阵 $A$ 的最大线性无关的列的数量。 行秩和列秩总是相等，这个公共值称为矩阵的秩，记作 $\\text{rank}(A)$。\n举例 假设有一个矩阵 $A$：\n$$ A = \\begin{bmatrix} 1 \u0026 2 \u0026 3 \\\\ 4 \u0026 5 \u0026 6 \\\\ 7 \u0026 8 \u0026 9 \\end{bmatrix} $$矩阵 $A$ 的秩是 $2$，因为矩阵的行或列中最大数量的线性无关的行或列是 $2$。\n步骤 r2 = r2 - 4*r1\nr3 = r3 - 7*r1\nr2 = -1/3*r2\nr3 = r3 + 6*r2\n机器学习基本概念 ml类别 监督学习 有数据标注的机器学习\n分类问题 给出X样本，以及样本中每一行对应的标注结果集Y\n根据样本特征，预测新样本的结果\n回归问题 给出X样本，以及样本中每一行对应的标注结果集Y\n根据样本特征，预测新样本的趋势\n无监督学习 无数据标注的机器学习\n聚类问题 仅给出X样本\n通过算法划分出不同的类别。\n注： 大多数机器学习应用多属于监督学习，后续仅对knn聚类算法做了简单介绍，其他算法均为监督学习。\n","date":"2024-09-14T02:06:14+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","title":"神经网络"},{"content":"计算机网络 本文主要参考了谢希仁老师编著的《计算机网络》教材第七版，并且后续会更新本书的全部章节，帮助每个程序员新人来理解相关的概念。\n文章中包含了许多体系化的知识以及相关的发展历史，个人认为据因寻果是一种非常有助于理解学习的内容，激发学习的兴趣的一种学习方法。希望能给各位同学们带来些许帮助。\n网络概述 80后出生的许多人都被认为是生活在网络的时代，但其实，早在电报被广泛使用的二十世纪初，网络便渗透进了每个人的日常生活中。通信网络，使得每个人接收信息更加快速与便捷，直到计算机网络被广泛使用的现在，信息的透明度以及便捷度相较于非信息时代的时间里不可同日而语，现如今，某个明星早上出的八卦内容，在当天就能给某些企业的服务器带来巨大的流量压力；信息的快速传播也给此次的新型流感防疫工作带来了明显的帮助。如果你是相关专业的同学，阅读这篇文章能给你带来对网络的进一步理解，而非相关专业的同学也能收获一些通用的信息知识。\n网络的分类 电信网络 有线电视网络 计算机网络 网络类型 主要应用 应用抽象 电信网络 电报，电话，传真 音频内容 有线电视网络 电视 视频内容 计算机网络 计算机（电脑） 多媒体内容，数据文件 理论上来讲，三种网络融合成一种带宽足够大的网络即可提供所有服务，但出于对经济以及行政方面的考量，这样的设想还是很难推进。不过在应用层面，已经有许多计算机（包含pc，手机等个人计算机设备）软件已经提供了基于计算机网络的视频或通信功能。\n网络的性质 连通性 使用网络的两端用户之间，无论距离远近均能非常便捷，经济地交换各种信息，好像用户终端都彼此连通一般，故称其为连通性。\n共享性 网络上的资源能够共享，并且网络上公开的资源就好像在用户身边一样便于使用。\n网络的这两种性质，基本概述了网络的基本功能：数据传输。 不过网络对于数据传输的方法，却经历了大概3个时期：\n电路交换：整个报文的比特流连续的从源点直达终点。 这是一种非常”古老“的数据传输方式，通常用于电信网络（电报电话）。 它的工作流程大致如下： 建立连接\u0026ndash;\u0026gt;通信\u0026ndash;\u0026gt;释放连接 在整个通信期间，两个用户始终占用端到端的通信资源，这样虽然信息流传输速率比较快，但是将会导致通信成本非常高昂以及通信资源的大量浪费。\n报文交换：整个报文先传送到相邻节点，全部存储完成后查找转发表，转发到下一个节点，依次类推直到到达通信终点。 这种传输方式解决了用户对端到端通信资源的持续占用，不过每次转发需要存储整个报文，必然会导致传输速率非常慢，延迟非常高，因此这是一种较不成熟的过渡传输方法。\n分组交换：报文分组后将单个分组传输到相邻节点，存储下来后查找转发表，转发到下一个节点，依次类推直到到达通信终点。 在报文交换的基础上进行了分组，每次转发只需要存储一边单一分组即可，不同的划分也会影响到其传输性能，不过在研究者们的刻苦攻坚下，这个问题基本以及被解决，优秀的分组计划可以加快数据的传输，虽然速率可能比不过电路交换那种连续点到点的通信，不过通信资源占用量低，可以大大降低通信成本，让每个人都有参与网络使用的机会，加速网络的普及。\n网络性能主要指标 速率 单位：bps，bit per second，比特每秒 带宽（易混淆） 带宽分为时域带宽与频域带宽 频域带宽：电子信号所占据的频带宽度，单位Hz 时域带宽：即最高速率，单位与速率相同，bps 我们现实生活中讨论的带宽通常是指时域带宽，例如你在电信公司办理了一个100M光前宽带，这里的100M就是100Mbps，换算为字节后要除以8（1Byte=8bit），也就成为了你下载的下行速率12.5MB/s。\n而频域带宽，这里以5G移动网络信号为例： 频域带宽就是电子信号所占据的频带宽度，不同的频域带宽，根据频率波长的关系，它的性能也往往有所差异，因此，有限的优秀频段往往成为一种竞争化的资源。这里再以5G移动网络信号为例： 这里不难看出，各国的频域带宽都是不同的，以避免信号之间的相互干扰，不过具体的频段优劣，涉及到国与国之间的内容，这里不做详述。\n3.吞吐量（易混淆） 吞吐量表示的是单位时间内实际传输的信号数量，因此，单位又是bps（惊不惊喜意不意外）。 这里着重强调的是实际传输，因此这个参数也是一个能比较真实的反应你所使用的网络的性能的指标，它也往往会低于电信运营商所标识的额定时域带宽。\n计算机网络（互联网）概述 上面的内容还是对于所有网络这个宏观的概念进行讲解，下面进入计算机网络（后文简称计网）的概述内容。\n在RFC[1208]中，规定了互联网（Internet）与互连网（internet）属于不同的概念，简单地说，互连网包含了互联网（实际中两者基本通用）。\n计网的组成 计算机网络（网络）由若干个结点（非节点）和连接这些结点的链路所组成。\n这里结点与节点的区分，个人理解为结点可以包含多个节点 结点可以是由一个个微型的私人局域网，路由器，交换机等用以提供网络服务的host所构成\n这里所有接入互联网，由用户直接使用的主机被称为：互联网的边缘部分 大量网络和连接它们的路由器等为互联网的边缘部分提供服务的设施被称为：互联网的核心部分\n计算机网络的组成部分中，最为核心的部件是路由器，它是实现分组交换的关键构件，任务是转发所有被其收到的数据包分组。\n计网的通信架构 C/S，client and server 这里的client主要是向互联网申请各种服务的用户； server是在互联网范围内给用户提供实际服务的企业或个人。 互联网的绝大多数应用都是基于此架构。\nP2P，peer to peer，也可以理解为person to person 这里的每台主机既是客户端，又是服务端，相较于C/S架构使用量较少 最典型的应用就是P2P下载应用，每台主机都可以作为内容的暂存者，当你需要下载某些数据时，可以优先找到能提供更快速率下载的peer直接下载，不需要每次都访问官方的server，极大的加快下载速率。\n计网的发展 一、 单个网络ARPANET向互联网发展（实验阶段：1969-1990） 高级研究计划局网络（英语：Advanced Research Projects Agency Network），通称阿帕网（英语：ARPANET）是美国国防高级研究计划局开发的世界上第一个运营的数据包交换网络，是全球互联网的鼻祖。\n最初，arpanet只是一个单个的分组交换网，并非是一个互连的网络，随着时间的发展，通信需求的增加带来了许多通信协议的诞生，这些通信协议又有利于更高级的协议编写，慢慢地，由TCP/IP协议族（20世纪80年代，有心的同学可以结合计算机在这个时期的发展来进行更深度的思考）为主导的互联网开始显露出来。 \u0026ndash;wiki百科\n二、三级结构的互联网雏形（科研阶段：21世纪初期） 主干网络-\u0026gt;地区网络-\u0026gt;校园/企业网络\n三、多层次ISP结构的互联网（实用阶段：现在） 名词解释ISP：Internet Service Provider，互联网服务提供商，也就是我们国家的电信运营商（电信，移动等），基本上所有的网络服务（主干网）都是由他们建造并提供相应的服务。\n主干ISP-\u0026gt;地区ISP-\u0026gt;企业网络/本地ISP-\u0026gt;个人网络\n计网的标准化工作流程 组织：IETF，互联网工程部；IETF，互联网研究部\n三大阶段（由先到后） 互联网草案（每个草案大约保存6个月） 互联网建议标准（录入至RFC文档） 互联网标准（多个RFC文档的关联） 计网体系结构（重点） 仅仅有物理通路用以传输数据对于计算机之间还远远不够，面对计算机之间的通信，还需要处理以下几个问题：\n激活物理通路 识别接收对象 检测网络连接正常 审核准备工作 数据格式转换 出错备案 ARPANET提出了”分层”的方法，这些问题在后面的各个网络协议中被分别解决。\n网络协议 osi七层网络模型中，每一层的实现都有相对应的网络协议。 包含但不限于：ARP，RARP，IPv4/v6，TCP，HTTP，FTP，SMTP，SSL等协议 这些协议通常扮演者一个统一化的角色，因此我们需要了解网络协议的相关概念。\n定义 为进行网络中的数据交换而建立的规则，标准，或约定被称为网络协议。（==》这些内容规定了传输的数据格式及有关的同步问题。）\n三要素 语法：数据与控制信息的结构或格式 语义：控制及响应信息 同步：事件实现的详细说明 另：单机程序可以不需要任何网络协议的参与，例如一个简单的hello world程序。\n网络模型 tcp/ip模型 这是使用最为广泛的一个网络模型\nosi七层模型 这是最官方的一个网络模型\ntcp/ip五层网络模型 这是一个折中的网络模型\ntcp/ip模型中的网络接口被拆分为物理层与数据链路层。\n网络模型中的数据传输内容（以osi模型为例） 除物理层中传输的为比特流以外，其他各层都以数据包的形式来传输数据（数据包~=数据头部header+数据内容）。\n数据头部在每个网络协议中都有不同的规定，根据这些规定加上相关的算法，就可以解决上文提到的，计算机网络传输数据还需要处理的几个问题。\n激活物理通路 识别接收对象 检测网络连接正常 审核准备工作 数据格式转换 出错备案 ","date":"2022-03-06T00:00:00Z","image":"https://wencynyu.github.io/zh-cn/p/hello-world/cover_hu6307248181568134095.jpg","permalink":"https://wencynyu.github.io/zh-cn/p/hello-world/","title":"计算机网络基本发展"},{"content":"","date":"2024-09-15T01:23:56+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E6%9D%83%E9%99%90%E8%AE%BE%E8%AE%A1-%E9%89%B4%E6%9D%83%E6%8E%88%E6%9D%83/","title":"权限设计-鉴权授权"},{"content":"","date":"2024-09-15T01:12:40+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6-orm-spring/","title":"开发框架-orm-spring"},{"content":"","date":"2024-09-15T01:11:15+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6-aop-spring/","title":"开发框架-aop-spring"},{"content":"","date":"2024-09-15T01:11:09+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6-ioc-spring/","title":"开发框架-ioc-spring"},{"content":"","date":"2024-09-15T01:10:50+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6-%E6%A6%82%E8%A7%88-spring/","title":"开发框架-概览-spring"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt;\r\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt;\r\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\rDiff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] One line code block 1 \u0026lt;p\u0026gt;A paragraph\u0026lt;/p\u0026gt; List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-09-07T00:00:00Z","permalink":"https://wencynyu.github.io/zh-cn/p/markdown%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/","title":"Markdown基本语法"},{"content":"Hugo theme Stack supports the creation of interactive image galleries using Markdown. It\u0026rsquo;s powered by PhotoSwipe and its syntax was inspired by Typlog.\nTo use this feature, the image must be in the same directory as the Markdown file, as it uses Hugo\u0026rsquo;s page bundle feature to read the dimensions of the image. External images are not supported.\nSyntax 1 ![Image 1](1.jpg) ![Image 2](2.jpg) Result Photo by mymind and Luke Chesser on Unsplash\n","date":"2023-08-26T00:00:00Z","image":"https://wencynyu.github.io/zh-cn/p/%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD-%E5%B1%95%E7%A4%BA/2_hu15576070775610481867.jpg","permalink":"https://wencynyu.github.io/zh-cn/p/%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD-%E5%B1%95%E7%A4%BA/","title":"图片加载 \u0026 展示"},{"content":"For more details, check out the documentation.\nBilibili video Tencent video YouTube video Generic video file Your browser doesn't support HTML5 video. Here is a link to the video instead. Gist GitLab Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― A famous person, The book they wrote Photo by Codioful on Unsplash\n","date":"2023-08-25T00:00:00Z","image":"https://wencynyu.github.io/zh-cn/p/%E5%A4%96%E9%93%BE%E4%BD%BF%E7%94%A8/cover_hu17063188895770243625.jpg","permalink":"https://wencynyu.github.io/zh-cn/p/%E5%A4%96%E9%93%BE%E4%BD%BF%E7%94%A8/","title":"外链使用"},{"content":"Stack has built-in support for math typesetting using KaTeX.\nIt\u0026rsquo;s not enabled by default side-wide, but you can enable it for individual posts by adding math: true to the front matter. Or you can enable it side-wide by adding math = true to the params.article section in config.toml.\nInline math This is an inline mathematical expression: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\n1 $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$ Block math $$\r\\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$ 1 2 3 $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$ $$\rf(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)\\,e^{2 \\pi i \\xi x}\\,d\\xi\r$$ 1 2 3 $$ f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)\\,e^{2 \\pi i \\xi x}\\,d\\xi $$ ","date":"2023-08-24T00:00:00Z","permalink":"https://wencynyu.github.io/zh-cn/p/%E6%95%B0%E5%AD%A6%E6%94%AF%E6%8C%81-latex/","title":"数学支持-latex"}]