[{"content":"Mysql 事务与XLog（redo/bin/undo） innoDB 事务支持ACID mvcc 行锁 redolog（仅innoDB） \u0026amp; undolog .ibd文件存索引+数据 InnoDB的文件结构可以划分为多个段（segment）、区（extent）、页（page）等层级。每个索引都存储在特定的段中，而每个段又由多个区组成，每个区包含多个页。在InnoDB中，页是磁盘和内存之间交换数据的最小单位，通常是16KB大小。 Feature Support B-tree indexes Yes Clustered indexes Yes Compressed data Yes Data caches Yes Foreign key support Yes Full-text search indexes Yes Geospatial data type support Yes Geospatial indexing support Yes Hash indexes No Index caches Yes Locking granularity Row MVCC Yes Storage limits 64TB T-tree indexes No Transactions Yes Update statistics for data dictionary Yes 架构 源码分析 index page结构 每一个index page默认16KB。\n结构名称 字节大小 描述 文件位置 FIL Header 38 页面文件头，包含页面的元数据 fil0fil.cc INDEX Header 36 页面头，包含页面的基本信息，如类型、级别等 page0types.h FSEG Header 20 索引页头，包含索引页的特定信息 page0types.h System Record\n（Infimum \u0026amp; Supermum） 26 存储页中记录的目录结构 page0types.h User Record 存储实际索引记录的数据堆 page0types.h Free Space 管理页面中的空闲空间 page0types.h Page Directory 页面中的虚拟记录，用于 B+ 树的边界 page0types.h FIL Tailer 8 描述页面压缩的相关信息 page0types.h 元数据 FIL Header \u0026amp; Tailer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 /** MySQL-4.0.14版本中页面所属的空间ID（== 0），但在后续版本中是页面的“新”校验和 */ constexpr uint32_t FIL_PAGE_SPACE_OR_CHKSUM = 0; /** checksum 4字节 */ constexpr uint32_t FIL_PAGE_OFFSET = 4; /** IndexPage偏移量 4字节*/ constexpr uint32_t FIL_PAGE_PREV = 8; /** 前一个IndexPage的地址 4字节 */ constexpr uint32_t FIL_PAGE_NEXT = 12; /** 后一个IndexPage的地址 4字节 */ constexpr uint32_t FIL_PAGE_LSN = 16; /** 最新修改日志记录的结束LSN信息 8字节 */ constexpr uint32_t FIL_PAGE_TYPE = 24; /** PageType信息 2字节 */ constexpr uint32_t FIL_PAGE_FILE_FLUSH_LSN = 26; /** 仅在系统表空间的第一页中定义：文件至少已刷新到此LSN 8字节*/ constexpr uint32_t FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID = 34; /** SpaceId 4字节 */ constexpr uint32_t FIL_PAGE_DATA = 38; /** 文件页面尾部 */ /** 其中低4字节用于存储页面校验和，最后4字节应该与 `FIL_PAGE_LSN` 的最后4字节相同 */ constexpr uint32_t FIL_PAGE_END_LSN_OLD_CHKSUM = 8; /** 如果页面类型是 `FIL_PAGE_COMPRESSED`，则从 `FIL_PAGE_FILE_FLUSH_LSN` 开始的8个字节按以下方式分解： */ /** 控制信息版本格式（u8） */ constexpr uint32_t FIL_PAGE_VERSION = FIL_PAGE_FILE_FLUSH_LSN; /** 压缩算法（u8） */ constexpr uint32_t FIL_PAGE_ALGORITHM_V1 = FIL_PAGE_VERSION + 1; /** 原始页面类型（u16） */ constexpr uint32_t FIL_PAGE_ORIGINAL_TYPE_V1 = FIL_PAGE_ALGORITHM_V1 + 1; /** 原始数据大小（以字节为单位）（u16）*/ constexpr uint32_t FIL_PAGE_ORIGINAL_SIZE_V1 = FIL_PAGE_ORIGINAL_TYPE_V1 + 2; /** 压缩后的大小（u16） */ constexpr uint32_t FIL_PAGE_COMPRESS_SIZE_V1 = FIL_PAGE_ORIGINAL_SIZE_V1 + 2; /** 该字段重载了 `FIL_PAGE_FILE_FLUSH_LSN` 用于R树分裂序列号 */ constexpr uint32_t FIL_RTREE_SPLIT_SEQ_NUM = FIL_PAGE_FILE_FLUSH_LSN; /** 一个包装类，用于帮助打印和检查文件页面头部 */ struct Fil_page_header { /** 构造函数，接受指向页面头的指针作为参数 */ explicit Fil_page_header(const byte *frame) : m_frame(frame) {} /** 从页面头获取空间ID */ space_id_t get_space_id() const noexcept; /** 从页面头获取页面编号 */ page_no_t get_page_no() const noexcept; /** 获取 `FIL_PAGE_PREV` 字段的值 */ page_no_t get_page_prev() const noexcept; /** 获取 `FIL_PAGE_NEXT` 字段的值 */ page_no_t get_page_next() const noexcept; /** 从页面头获取页面类型 */ uint16_t get_page_type() const noexcept; private: /** 指向页面头的指针 */ const byte *m_frame{}; }; INDEX Header \u0026amp; FSEG Header（PAGE Header） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 constexpr uint32_t PAGE_HEADER = FSEG_PAGE_DATA; /** 索引页面头部的起始偏移量：从FIL_HEADER偏移位置38开始 */ constexpr uint32_t PAGE_N_DIR_SLOTS = 0; /** 页面目录中插槽的数量 2字节*/ constexpr uint32_t PAGE_HEAP_TOP = 2; /** 指向记录堆顶部的指针 2字节*/ constexpr uint32_t PAGE_N_HEAP = 4; /** 堆中的记录数量，bit 15 = 标志位 2字节 */ constexpr uint32_t PAGE_FREE = 6; /** 指向页面空闲记录列表的起始位置 2字节*/ constexpr uint32_t PAGE_GARBAGE = 8; /** 已删除记录的字节数 2字节*/ constexpr uint32_t PAGE_LAST_INSERT = 10; /** 最后插入的记录的指针 2字节；如果信息已通过删除重置，则为NULL */ constexpr uint32_t PAGE_DIRECTION = 12; /** 最后插入的方向：PAGE_LEFT，...枚举值 2字节*/ constexpr uint32_t PAGE_N_DIRECTION = 14; /** 向同一方向连续插入的记录数 2字节 */ constexpr uint32_t PAGE_N_RECS = 16; /** 页面上的用户记录数 2字节 */ constexpr uint32_t PAGE_MAX_TRX_ID = 18; /** 修改页面上记录的事务的最大事务ID；trx_id_t；仅在二级索引和插入缓冲树中定义 2字节 */ constexpr uint32_t PAGE_LEVEL = 26; /** 索引树节点的层级 2字节，叶子节点为 0 */ constexpr uint32_t PAGE_INDEX_ID = 28; /** 页面所属的索引ID 8字节 */ /** B树中叶子页的文件段头部：仅在B树的根页面中定义，而不在插入缓冲树的根页面中 */ constexpr uint32_t PAGE_BTR_SEG_LEAF = 36; constexpr uint32_t PAGE_BTR_IBUF_FREE_LIST = PAGE_BTR_SEG_LEAF; constexpr uint32_t PAGE_BTR_IBUF_FREE_LIST_NODE = PAGE_BTR_SEG_LEAF; /* 在PAGE_BTR_SEG_LEAF和PAGE_BTR_SEG_TOP的位置中， 如果页面是插入缓冲树的根页面，则此处会存储一个空闲列表基础节点； 如果页面在自由列表中，则该位置会存储自由列表节点 */ constexpr uint32_t PAGE_BTR_SEG_TOP = 36 + FSEG_HEADER_SIZE; /* B树中非叶子页的文件段头部：仅在B树的根页面中定义，而不在插入缓冲树的根页面中 */ /** 页面数据的起始位置 */ constexpr uint32_t PAGE_DATA = PAGE_HEADER + 36 + 2 * FSEG_HEADER_SIZE; System Record（Infimum \u0026amp; Supermum） 1 2 3 4 5 6 7 8 9 10 11 12 /** 老页面(mysql 5.1之前)的下界记录的偏移量 */ #define PAGE_OLD_INFIMUM (PAGE_DATA + 1 + REC_N_OLD_EXTRA_BYTES) // 1 + 6 /** 老页面的上界记录的偏移量 */ #define PAGE_OLD_SUPREMUM (PAGE_DATA + 2 + 2 * REC_N_OLD_EXTRA_BYTES + 8) // 2 + 2 * 6 + 8 /** 老页面的上界记录结束的偏移量 */ #define PAGE_OLD_SUPREMUM_END (PAGE_OLD_SUPREMUM + 9) // 2 + 2 * 6 + 8 + 9 = 31 /** 新页面的下界记录的偏移量 */ #define PAGE_NEW_INFIMUM (PAGE_DATA + REC_N_NEW_EXTRA_BYTES) // 5 /** 新页面的上界记录的偏移量 */ #define PAGE_NEW_SUPREMUM (PAGE_DATA + 2 * REC_N_NEW_EXTRA_BYTES + 8) // 2 * 5 + 8 /** 新页面的上界记录结束的偏移量 */ #define PAGE_NEW_SUPREMUM_END (PAGE_NEW_SUPREMUM + 8) // 2 * 5 + 8 + 8 = 26 实际索引数据 Record Header 老版本：16bit: pointer to next record + 13bit: heap_no + 4bit: n_owned + 10bit: col_size + 1bit: short_flag + 4bit: info (6B) 新版本：16bit: pointer to next record + 13bit: heap_no + 4bit: n_owned + 3bit: status + 4bit: info (5B) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 /* Maximum values for various fields (for non-blob tuples) */ constexpr uint32_t REC_MAX_N_FIELDS = 1024 - 1; constexpr uint32_t REC_MAX_HEAP_NO = 2 * 8192 - 1; constexpr uint32_t REC_MAX_N_OWNED = 16 - 1; /** row id: a 48-bit integer */ constexpr uint32_t DATA_ROW_ID = 0; /** stored length for row id */ constexpr uint32_t DATA_ROW_ID_LEN = 6; /** Transaction id: 6 bytes */ constexpr size_t DATA_TRX_ID = 1; /** Transaction ID type size in bytes. */ constexpr size_t DATA_TRX_ID_LEN = 6; /** Rollback data pointer: 7 bytes */ constexpr size_t DATA_ROLL_PTR = 2; /** Rollback data pointer type size in bytes. */ constexpr size_t DATA_ROLL_PTR_LEN = 7; /* Offsets of the bit-fields in an old-style record. NOTE! In the table the most significant bytes and bits are written below less significant. (1) byte offset (2) bit usage within byte downward from origin -\u0026gt; 1 8 bits pointer to next record 2 8 bits pointer to next record 3 1 bit short flag 7 bits number of fields 4 3 bits number of fields 5 bits heap number 5 8 bits heap number 6 4 bits n_owned 4 bits info bits */ /* Offsets of the bit-fields in a new-style record. NOTE! In the table the most significant bytes and bits are written below less significant. (1) byte offset (2) bit usage within byte downward from origin -\u0026gt; 1 8 bits relative offset of next record 2 8 bits relative offset of next record the relative offset is an unsigned 16-bit integer: (offset_of_next_record - offset_of_this_record) mod 64Ki, where mod is the modulo as a non-negative number; we can calculate the offset of the next record with the formula: relative_offset + offset_of_this_record mod UNIV_PAGE_SIZE 3 3 bits status: 000=conventional record 001=node pointer record (inside B-tree) 010=infimum record 011=supremum record 1xx=reserved 5 bits heap number 4 8 bits heap number 5 4 bits n_owned 4 bits info bits */ transaction数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 /** Mini-事务句柄和缓冲区 */ struct mtr_t { /** mtr 的状态变量 */ struct Impl { /** 锁等的备忘栈 */ mtr_buf_t m_memo; /** mini-事务日志 */ mtr_buf_t m_log; /** 如果在 ibuf 更改中 */ bool m_inside_ibuf; /** 如果 mini-事务可能修改了缓冲池页面 */ bool m_modifications; /** 如果 mini-事务被强制设置为 NO_LOG 模式，因为全局禁用了重做日志 */ bool m_marked_nolog; /** 启动时用于递增全局计数器的 shard 索引 */ size_t m_shard_index; /** 已经写入 mtr 日志的初始页面记录数 */ uint32_t m_n_log_recs; /** 指定应该记录的操作；默认值是 MTR_LOG_ALL */ mtr_log_t m_log_mode; /** 事务的状态 */ mtr_state_t m_state; /** 刷新观察者 */ Flush_observer *m_flush_observer; /** 所有者 mini-事务 */ mtr_t *m_mtr; }; mtr_t() { m_impl.m_state = MTR_STATE_INIT; m_impl.m_marked_nolog = false; m_impl.m_shard_index = 0; } ~mtr_t() { } /** 启动一个 mini-事务 @param sync 如果是同步 mini-事务，则为 true */ void start(bool sync = true); /** @return 判断是否为异步 mini-事务 */ bool is_async() const { return (!m_sync); } /** 请求未来的提交是同步的 */ void set_sync() { m_sync = true; } /** 提交 mini-事务 */ void commit(); /** 获取当前缓冲区大小 @return 保存点 */ ulint get_savepoint() const { ut_ad(is_active()); ut_ad(m_impl.m_magic_n == MTR_MAGIC_N); return (m_impl.m_memo.size()); } /** 释放 mtr 备忘栈中的 (索引树) s-latch */ inline void release_s_latch_at_savepoint(ulint savepoint, rw_lock_t *lock); /** 释放 mtr 备忘栈中的块 */ inline void release_block_at_savepoint(ulint savepoint, buf_block_t *block); /** 在保存点后为尚未加锁的块加 SX-latch */ inline void sx_latch_at_savepoint(ulint savepoint, buf_block_t *block); /** 在保存点后为尚未加锁的块加 X-latch */ inline void x_latch_at_savepoint(ulint savepoint, buf_block_t *block); /** 获取日志模式 @return 日志模式 */ inline mtr_log_t get_log_mode() const; /** 设置日志模式 @param mode 日志模式 @return 旧的日志模式 */ mtr_log_t set_log_mode(mtr_log_t mode); /** 从缓冲池中读取 1 - 4 字节 @param ptr 读取起始位置 @param type MLOG_1BYTE, MLOG_2BYTES, MLOG_4BYTES @return 读取的值 */ inline uint32_t read_ulint(const byte *ptr, mlog_id_t type) const; /** 锁定一个 rw-latch（共享模式） @param lock rw-lock @param location 锁定来源位置 */ inline void s_lock(rw_lock_t *lock, ut::Location location); /** 锁定一个 rw-latch（独占模式） @param lock rw-lock @param location 锁定来源位置 */ inline void x_lock(rw_lock_t *lock, ut::Location location); /** 锁定一个 rw-latch（SX 模式） @param lock rw-lock @param location 锁定来源位置 */ inline void sx_lock(rw_lock_t *lock, ut::Location location); /** 获取表空间的 X-latch @param[in] space 表空间实例 @param[in] location 来源位置 */ void x_lock_space(fil_space_t *space, ut::Location location); /** 释放备忘栈中的对象 @param object 对象 @param type 对象类型：MTR_MEMO_S_LOCK 等 */ void memo_release(const void *object, ulint type); /** 释放页面锁 */ void release_page(const void *ptr, mtr_memo_type_t type); /** 标记 mini-事务可能修改了缓冲池页面 */ void set_modified() { m_impl.m_modifications = true; } /** 判断 mtr 是否修改了缓冲池页面 @return 如果 mini-事务可能修改了缓冲池页面，则返回 true */ bool has_modifications() const { return m_impl.m_modifications; } /** 获取提交时的 LSN @return 提交时的 LSN @retval 0 如果事务只修改了临时表空间或全局禁用了日志 */ lsn_t commit_lsn() const { ut_ad(has_committed()); ut_ad(m_impl.m_log_mode == MTR_LOG_ALL); return (m_commit_lsn); } /** 进入变更缓冲区代码 */ void enter_ibuf() { m_impl.m_inside_ibuf = true; } /** 退出变更缓冲区代码 */ void exit_ibuf() { m_impl.m_inside_ibuf = false; } /** @return 如果当前在变更缓冲区代码中 */ bool is_inside_ibuf() const { return (m_impl.m_inside_ibuf); } /** @return mini-事务是否处于活动状态 */ bool is_active() const { return (m_impl.m_state == MTR_STATE_ACTIVE); } /** 获取刷新观察者 @return 刷新观察者 */ Flush_observer *get_flush_observer() const { return (m_impl.m_flush_observer); } /** 设置刷新观察者 @param[in] observer 刷新观察者 */ void set_flush_observer(Flush_observer *observer) { ut_ad(observer == nullptr || m_impl.m_log_mode == MTR_LOG_NO_REDO); m_impl.m_flush_observer = observer; } /** 打印 mini-事务的备忘对象（mtr_memo_slot_t）到输出流 @param[in] out 输出流 @return 输出流 */ std::ostream \u0026amp;print_memos(std::ostream \u0026amp;out) const; /** 标记日志记录已被添加 */ void added_rec() { ++m_impl.m_n_log_recs; } /** 检查是否有任何重做日志记录应在提交时写入重做日志 @return 如果至少有一个重做日志记录生成，则返回 true */ bool has_any_log_record() { return 0 \u0026lt; m_impl.m_n_log_recs; } /** 获取当前 mini-事务的缓冲区重做日志 @return 重做日志 */ const mtr_buf_t *get_log() const { ut_ad(m_impl.m_magic_n == MTR_MAGIC_N); return (\u0026amp;m_impl.m_log); } /** 获取当前 mini-事务的缓冲区重做日志 @return 重做日志 */ mtr_buf_t *get_log() { ut_ad(m_impl.m_magic_n == MTR_MAGIC_N); return (\u0026amp;m_impl.m_log); } /** 将对象推入 mtr 备忘栈 @param object 对象 @param type 对象类型：MTR_MEMO_S_LOCK 等 */ inline void memo_push(void *object, mtr_memo_type_t type); /** 矩阵检查是否应该忽略模式更新请求 */ static bool s_mode_update[MTR_LOG_MODE_MAX][MTR_LOG_MODE_MAX]; private: Impl m_impl; /** 提交时的 LSN */ lsn_t m_commit_lsn; /** 是否为同步 mini-事务 */ bool m_sync; class Command; friend class Command; }; 事务与XLog流程分析 start transaction do operation commit BufferPool写入operation数据，数据页DoubleWriteBuffer（读作buffer，实际为磁盘顺序写操作，避免16k内存页写入4k磁盘页非原子操作失败） 两阶段-1：写入redo_log，此时transaction为prepare阶段 两阶段-2：（写入bin_log，非innoDB引擎层）实际完成commit rollback transaction_id + rollback_ptr回滚指针，通过undo_log进行逆操作，回滚数据 mtr的使用 在开启一个mini transaction时，会初始化mtr对象中的m_log和m_memo成员，设置m_state为active。\n1 2 3 4 5 6 7 8 mtr_t::start | |-\u0026gt; 初始化mtr.m_impl-\u0026gt;m_log日志管理对象 | |-\u0026gt; 初始化mtr.m_impl-\u0026gt;m_memo锁管理对象 | m_log和m_memo都是mtr_buf_t，以block_t节点m_node域构建的双向链表 | |-\u0026gt; m_log_mode=MTR_LOG_ALL(记录所有的数据变更) \u0026amp; m_state=MTR_STATE_ACTIVE 提交一个mini transaction的过程比较复杂，大致流程是先将m_log中的日志写入公共log buffer，再将m_memo中的加锁并且发生修改的脏page加入flush list，最后释放m_memo中的所有锁。\n公共log buffer是按照log block格式存储的（包含12B的header和4B的trailer，详见前文中的日志块结构），每个log block大小为512B，并且持久化时以512B进行对齐。每个log block中能存储日志内容的空间为512-12-4=496B。\n公共log buffer有个原子变量log.sn，其统计的是公共buffer中曾经存储过的日志内容的大小。通过sn可以很容易计算出对应的lsn，其统计的是公共buffer中曾经存储过的以log block格式的日志量的大小。 lsn = (sn / 496 * 512 + sn % 512 + 12)\n公共log buffer是个循环buffer，其中有三个重要的位点log.write_lsn，log.sn对应的lsn，log.buf_limit_sn对应的lsn。其中log.write_lsn表示已写入磁盘的日志位点（不要求flush），log.sn对应的lsn表示已占位待拷贝的日志位点，log.buf_limit_sn对应的lsn表示可以占位的最大日志位点。满足log.write_lsn \u0026lt;= log.sn对应的lsn \u0026lt;= log.buf_limit_sn对应的lsn。\n将m_log中的日志写入公共log buffer：\n根据日志数m_n_log_recs是否为1，来判断是single log还是multiple log。对于single log，在日志的开头的日志类型字段中增加MLOG_SINGLE_REC_FLAG。而对于multiple log，在日志结尾增加1B的MLOG_MULTI_REC_END。 在公共log buffer中使用原子变量log.sn进行日志占位。 在往已占位的日志空间中拷贝日志前，有以下两种情况需要等待： 若当前的log.sn位点被SN_LOCKED锁定，则要等待log.sn_locked 超过占位前的log.sn。当公共log buffer需要在线变更大小的时候，会进行SN_LOCKED加锁。 若日志写入速度过快，来不及写磁盘，就会把log buffer占满，这时需要阻塞等待日志的写磁盘。 将m_log动态buffer拷贝到公共log buffer，是按照512B大小的buffer粒度进行拷贝的： 若日志长度超过log block剩余大小，则要做截断，并增加tail和新的header，以满足log block格式 若写到log buffer的结尾（默认大小为16M），要继续转向log buffer开头继续拷贝。由于log buffer大小是log block的倍数，所以这里不需要再次做截断。 每个buffer拷贝完成后触发一次log.recent_written的Link_buf更新（详见前文），log.recent_written记录完成拷贝的最大连续日志的lsn 当m_log日志都写完，要检查已写入的日志是否横跨log block，若横跨了，则要在结尾的log block的header的LOG_BLOCK_FIRST_REC_GROUP字段中标识新mtr的位点end_lsn。 将m_memo中的加锁并且发生修改的脏page加入flush list：\n遍历m_memo动态buffer中的每个buffer中的每个锁对象mtr_memo_slot_t 若是page锁，且该page发生了修改，则将该page加入flush list 触发一次log.recent_closed的Link_buf更新，log.recent_closed记录添加到flush list的最大连续日志的lsn 以下是详细流程图：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 mtr_t::commit | |-\u0026gt; mtr_t::Command | (m_n_log_recs\u0026gt;0 || m_modifications) | |-\u0026gt; (yes) |\tv | Command::execute 将mtr.m_impl-\u0026gt;m_log写入公共log buffer，把脏页加入flush list |\t| | |-\u0026gt; prepare_write | | | | | |-\u0026gt; 若 mtr.m_impl-\u0026gt;m_log_mode为 MTR_LOG_NO_REDO或MTR_LOG_NONE，则直接返回 | | | | | |-\u0026gt; 若 mtr.m_impl-\u0026gt;m_n_log_recs==1，则 m_log.front()-\u0026gt;begin()|=MLOG_SINGLE_REC_FLAG，在日志头Type字段中标识， | | 否则 m_log-\u0026gt;push(MLOG_MULTI_REC_END)，在日志结尾附加1B |\t| | |-\u0026gt; log_buffer_reserve 在公共log buffer中为日志预留空 | | | | | |-\u0026gt; log_buffer_s_lock_enter_reserve | | | | | | | |-\u0026gt; 对 log.pfs_psi加 s-lock | | | | | | | |-\u0026gt; log.sn.fetch_add(mtr.m_impl-\u0026gt;m_log.m_size) 在公共的log buffer中占位 | | | | | | | |-\u0026gt; log_buffer_s_lock_wait 若log.sn被SN_LOCKED，则等待log.sn_locked 超过占位前的log.sn | | | | | |-\u0026gt; log_translate_sn_to_lsn 将日志内容的偏移量log.sn 转为log block格式的偏移量start_lsn，start_lsn可以唯一表示日志在log block和公共log buffer中的位置 | | | | | |-\u0026gt; log_wait_for_space_after_reserving 若end_sn \u0026gt; log.buf_limit_sn，则等待 |\t| | |-\u0026gt; mtr_write_log_t(mtr.m_impl-\u0026gt;m_log.m_list) 将日志内容拷贝至预留的空间 | | | | | (loop mtr_buf_t::block in m_list) 将mtr.m_impl-\u0026gt;m_log中的日志按block粒度拷贝到公共log buffer | | | | | |-\u0026gt; log_buffer_write 以log block的 start_lsn%OS_FILE_LOG_BLOCK_SIZE位置的数据 拷贝到公共log buffer的 start_lsn%log.buf_size位置 | | | | | | | |-\u0026gt; left = OS_FILE_LOG_BLOCK_SIZE - LOG_BLOCK_TRL_SIZE - offset 若日志长度超过log block剩余大小，则要做截断 | | | | | | | |-\u0026gt; lsn_diff = left + LOG_BLOCK_TRL_SIZE + LOG_BLOCK_HDR_SIZE 若log block写满，要增加tail和新的header | | | | | | | |-\u0026gt; 若公共log buffer被写满，则下次从开头继续写。因为每个mtr的日志在解析时大小就不超过2M，肯定不会超过公共log buffer的大小16M | | | | | | | |-\u0026gt; log_block_set_first_rec_group 在新header中设置 LOG_BLOCK_FIRST_REC_GROUP为0 | | | | | |-\u0026gt; log_buffer_set_first_record_group 若mtr日志都写完且 mtr开头和结尾不在同一个log block中，则在新header中设置 LOG_BLOCK_FIRST_REC_GROUP为 end_lsn | | | | | |-\u0026gt; log_buffer_write_completed 每个block拷贝完成后均触发一次Link_buf(并查集)的更新，log.recent_written记录完成拷贝的最大连续日志的lsn | | | | | |-\u0026gt; log.recent_written.add_link_advance_tail 在recent_written-\u0026gt;m_links的slot中记录当前日志的end_lsn，m_tail表示已拷贝到log buffer连续日志的end_lsn | | | | | | | |-\u0026gt; 若m_tail为当前日志的start_lsn，则推进m_tail为当期日志的end_lsn | | | | | | | |-\u0026gt; 否则recent_written-\u0026gt;m_links[start_lsn%capacity] = end_lsn，并推进m_tail | | | v | | | log.recent_written.advance_tail_until 等到log.recent_written.m_tail推进到最大lsn | | | | | | | |-\u0026gt; 若recent_written-\u0026gt;m_links[m_tail%capacity] \u0026gt; m_tail，则使用cas更改recent_written-\u0026gt;m_links[m_tail%capacity] = m_tail 来排他访问 | | | | | | | |-\u0026gt; (loop next_position) 推进m_tail为此刻连续的最大lsn，即使没推进到当前日志，其它help线程会帮忙推进 | | | | | |-\u0026gt; 若log.recent_written.m_tail \u0026gt; log.current_ready_waiting_lsn，则os_event_set(log.closer_event) |\t| | |-\u0026gt; add_dirty_blocks_to_flush_list(mtr.m_impl-\u0026gt;m_memo) 将mtr锁管理中记录的脏页加入flush list | | | | | (reverse loop mtr_buf_t::block in m_memo) | | v | | (reverse loop mtr_memo_slot_t in block) | | | | | |-\u0026gt; add_to_flush 为了去掉flush_order_mutex，把mtr对应的脏页无序的添加到flush list，在做checkpoint时, 无法保证flush list 上面最头的page lsn是最小的 | | v | | add_dirty_page_to_flush_list 把修改后的page加入flush list，当mtr_memo_slot_t.type为MTR_MEMO_PAGE_X_FIX或MTR_MEMO_PAGE_SX_FIX， | | | 或为MTR_MEMO_BUF_FIX，且mtr_memo_slot_t.object-\u0026gt;made_dirty_with_no_latch | | v | | buf_flush_note_modification(mtr_memo_slot_t.object) |\t| | |-\u0026gt; log_buffer_close 将mtr锁管理中记录的脏页处理完后触发一次Link_buf更新，log.recent_closed记录添加到flush list的最大连续日志的lsn | | 以log.recent_closed.m_tail的lsn来做checkpoint肯定是安全的， | v | log_buffer_s_lock_exit_close | | | |-\u0026gt; 对 log.pfs_psi解锁 s-lock | | | |-\u0026gt; log.recent_closed.add_link_advance_tail | |-\u0026gt; Command::release_all |\t| | |-\u0026gt; Release_all(mtr.m_impl-\u0026gt;m_memo) 释放mtr持有的锁 | |-\u0026gt; Command::release_resources -\u0026gt; clean mtr.m_impl-\u0026gt;m_log \u0026amp; m_memo ","date":"2024-12-03T00:59:34+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BDmysql-%E4%BA%8B%E5%8A%A1%E4%B8%8Exlog/","title":"高性能MySql-事务与xlog"},{"content":"netty讲解 常见概念：\n网络编程 网络模型（5/7层）：物理层（RJ45接口-水晶头） -\u0026gt; 链路层（PPPoE） -\u0026gt; 网络层（IP） -\u0026gt; 传输层（TCP/UDP） -\u0026gt; 应用层（会话层/加密层/应用层） 对于有外部网络通信需求的app，通常在网络层，基于socket套接字进行通信，这里对于未说明的绝大多数情况，都是基于ip协议进行的 后文中的通信也是基于使用IP协议的网络层介绍，传输层则以TCP为主 阻塞/非阻塞IO（这里学习过程中会有一些比喻理解，例如印象中的烧水蜂鸣器，但是最后还是直接基于计算机IO介绍，希望能帮助理解） 操作系统（OS）的所有指令操作都是基于内存的，为了保障系统安全，通常有内核/应用内存的逻辑划分，应用不允许直接访问内核的内存地址，因此在IO过程中存在IO设备 -\u0026gt; 内核内存 -\u0026gt; 应用内存 -\u0026gt; 业务逻辑 -\u0026gt; 应用内存 -\u0026gt; 内核内存 -\u0026gt; IO设备的流程 阻塞IO：线程调用read/write方法后，需要持续等待IO设备完成将数据（通常是网络/磁盘等慢设备）写入内核内存后，再从内核内存中拷贝到应用内存，此时完成一个read/write操作，继续执行后续业务指令（这里业务指令等待read/write后立即执行） 非阻塞IO：线程调用read/write方法后，立即返回调用成功/失败的返回值，然后继续执行后续指令（可能是非后续业务指令，或者其他完成实际内容IO的业务指令） 此时如果后续指令对read/write返回的实际内容值有依赖，则线程可以执行其他任务（IO/业务） OS完成将IO设备数据写入内核内存，再从内核内存中拷贝到应用内存后，此时完成实际内容的IO流程，通常由OS控制发出一个完成信号（可读/写），然后线程会根据OS的任务调度情况继续完成后续的实际业务指令（也就是说在返回调用成功/失败值后，线程可能分配其他任务执行，然后实际内容IO完成后，再执行后续有内容依赖的业务逻辑） 场景辅助理解：业务逻辑为，a调用网络请求后直接返回a 在某一时间点，a和b同时发起网络请求 a -\u0026gt; io调用 -\u0026gt; b -\u0026gt; io调用 -\u0026gt; a io完成，执行a业务，返回a -\u0026gt; b io完成，执行b业务，返回b C10K问题：有10000个client发起请求的场景，通常为高并发的概括性描述 从BIO开始 服务死循环中accept阻塞方法，当有连接被accept才会继续执行 accept返回一个socket实例，实例中包含FileDescriptor，InputStream和OutputStream 每次对accept建立的连接都需要读取内核中的请求信息到jvm，然后解析请求信息 每次返回响应信息时也需要通过Stream流从jvm写入内核中，然后通过网卡硬件返回至client端 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 public class BlockingServer { public static void main(String[] args) { try { // 监听本地8000端口的tcp请求信息 ServerSocket server = new ServerSocket(8000, 1024, InetAddress.getLocalHost()); while (true){ try { System.out.println(\u0026#34;server wait for accept...\u0026#34;); Socket accept = server.accept(); System.out.println(\u0026#34;server accept success...\u0026#34;); // 这里改为每次accept后开一个新线程进行服务即是传统bio模型 // 读数据，网卡到内核 -\u0026gt; 内核到应用 DataInputStream in = new DataInputStream(accept.getInputStream()); System.out.println(in.readUTF()); DataOutputStream out = new DataOutputStream(accept.getOutputStream()); // 写数据，应用到内核 -\u0026gt; 内核到网卡 out.writeUTF(\u0026#34;hello, \u0026#34; + accept.getRemoteSocketAddress() + \u0026#34;!! this is server data!!\u0026#34;); accept.close(); }catch (Exception e){ e.printStackTrace(); } } }catch (Exception e){ e.printStackTrace(); } } } 优缺点 优点\n便于理解，实现简单 对于小服务（client并发\u0026lt;200）而言，非常方便 缺点\n每次请求需要开新线程对外提供服务，client并发超高C10K场景时线程数量过多，且java中线程映射到操作系统的ULP线程中，线程间的管理和切换代价在服务的整体占比中越来越大 传统的stream流式io，阻塞时间较多，此时线程被挂起但是必要的栈内存上下文仍然需要维护 在io过程中存在4次拷贝，3次内核/用户态的切换，在高并发场景会存在一定的性能影响 java原生NIO多路复用 默认情况Selector的实现使用Epoll，windows下是WEpoll，macos是KQueue，可以通过java.nio.channels.spi.SelectorProvider 系统变量来进行控制 在主线程中调用select阻塞方法（封装系统层的epoll_wait方法），每当有注册的关注事件产生式会返回关注的事件数 有关注事件发生时，遍历发生的关注事件列表SelectionKey，每个SelectionKey对应一个fd，对这些fd的可读/写状态进行判断，根据业务需要进行读写 通过ByteBuffer进行io流程，支持 非阻塞 I/O 操作，虽然默认使用Heap内存，但有需要时可以选用DirectMemory和MMap操作，减少一次网卡从内核态拷贝到本地的操作（零拷贝）。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 public class NIOServer { public static void main(String[] args) { Charset charset = StandardCharsets.UTF_8; InetSocketAddress address = null; Selector selector = null; ServerSocketChannel channel = null; try { address = new InetSocketAddress(InetAddress.getLocalHost(), 8000); selector = Selector.open(); // 默认输出：sun.nio.ch.EPollSelectorImpl System.out.println(selector.getClass().getName()); channel = ServerSocketChannel.open(); // 创建一个socketChannel，并置为非阻塞，然后将该channel与端口绑定 channel.configureBlocking(false); channel.bind(address, 1024); // 最后将该channel与selector进行注册，监听端口可注册为关注accept操作 channel.register(selector, SelectionKey.OP_ACCEPT); while (true) { int n = selector.select(); if (n == 0){ continue; } // 遍历selector的全部关注key，对不同key进行分别处理 Set\u0026lt;SelectionKey\u0026gt; keySet = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = keySet.iterator(); SelectionKey key = null; while (iterator.hasNext()) { key = iterator.next(); // 遍历完成后从selector的选择set中移除，避免重复处理同一个channel iterator.remove(); try { // 当前key为可accept，也就是有其他client通过socket进行连接 if (key.isAcceptable()){ // accept方法会返回一个普通通道，每个通道在内核中都对应一个socket缓冲区 SocketChannel sc = channel.accept(); sc.configureBlocking(false); // 向selector注册这个通道为可读（建立连接后首先要读取client的信息），同时提供这个新通道相关的缓冲区 sc.register(selector, SelectionKey.OP_READ, new Buffers(256, 256)); System.out.println(\u0026#34;accept from: \u0026#34; + sc.getRemoteAddress()); } // 当前key为可read， if (key.isReadable()) { // 通过附件形式获取当前可读通道的Buffer区 Buffers attachment = (Buffers)key.attachment(); ByteBuffer readBuffer = attachment.getReadBuffer(); ByteBuffer writeBuffer = attachment.gerWriteBuffer(); // 获取当前可读通道 SocketChannel sc = (SocketChannel) key.channel(); // 从读缓冲区读入数据 sc.read(readBuffer); readBuffer.flip(); // utf-8解码显示字符数据 CharBuffer charBuffer = charset.decode(readBuffer); System.out.println(charBuffer.array()); // 读完数据后根据请求内容返回服务端数据 writeBuffer.put(\u0026#34;server response: \u0026#34;.getBytes(StandardCharsets.UTF_8)); writeBuffer.put(readBuffer); readBuffer.rewind(); readBuffer.clear(); // 操作+r，通过按位或来进行修改 key.interestOps(key.interestOps() | SelectionKey.OP_WRITE); } // 当前key为可write if (key.isWritable()) { Buffers buffers = (Buffers)key.attachment(); ByteBuffer writeBuffer = buffers.gerWriteBuffer(); writeBuffer.flip(); SocketChannel sc = (SocketChannel) key.channel(); int len = 0; while(writeBuffer.hasRemaining()){ len = sc.write(writeBuffer); /*说明底层的socket写缓冲已满*/ if(len == 0){ break; } } writeBuffer.compact(); /*说明数据全部写入到底层的socket写缓冲区*/ if(len != 0){ /*取消通道的写事件*/ key.interestOps(key.interestOps() \u0026amp; (~SelectionKey.OP_WRITE)); } } }catch (Exception e){ System.out.println(\u0026#34;service encounter client error\u0026#34;); e.printStackTrace(); // 客户端连接出现异常，从selector中移除这个key key.cancel(); key.channel().close(); } } } }catch (Exception e){ System.out.println(\u0026#34;serverThread is interrupted\u0026#34;); }finally { try{ selector.close(); }catch(Exception e){ System.out.println(\u0026#34;selector close failed\u0026#34;); }finally{ System.out.println(\u0026#34;server close\u0026#34;); } } } } 优缺点 优点\n对于高并发服务器而言，性能支持友好，对于C10K问题而言不需要开辟10k个线程 mmap操作可以减少一次内存拷贝操作 缺点\n较难理解，编程模型相对复杂 netty nio多路复用 与JDK的NIO默认情况一致，Selector的默认实现使用Epoll，windows下是WEpoll，macos是KQueue，可以通过java.nio.channels.spi.SelectorProvider 系统变量来进行控制 netty作为基于JDK NIO封装的框架，将accept流程与服务流程解耦，在bootstrap实例中明确划分为bossGroup和workerGroup两个参数，相较原生NIO职责更清晰 作为框架层，netty将一些常用的操作/问题进行了封装或处理，包括Pooled内存池与Unpool内存申请，提取抽象类ChannelHandlerAdapter等，开发者可以更关注于业务实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 public class NettyServer { public static void main(String[] args) { EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(Runtime.getRuntime().availableProcessors() * 2); try { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workerGroup).channel(NioServerSocketChannel.class) .localAddress(new InetSocketAddress(8000)) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel socketChannel) throws Exception { socketChannel.pipeline().addLast(new NettyServerHandler()); } }); ChannelFuture future = bootstrap.bind().sync(); future.channel().closeFuture().sync(); } catch (Exception e) { e.printStackTrace(); } finally { try { bossGroup.shutdownGracefully().sync(); workerGroup.shutdownGracefully().sync(); } catch (InterruptedException e) { e.printStackTrace(); } } } } // 继承绑定channel的处理适配器，netty自带了http的处理器可以继承后实现特殊需求 class NettyServerHandler extends ChannelInboundHandlerAdapter { @Override public void channelRegistered(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;server registered...\u0026#34;); ctx.writeAndFlush(Unpooled.copiedBuffer(\u0026#34;server registered...\u0026#34;, StandardCharsets.UTF_8)); super.channelRegistered(ctx); } @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;server inactive...\u0026#34;); ctx.writeAndFlush(Unpooled.copiedBuffer(\u0026#34;server inactive...\u0026#34;, StandardCharsets.UTF_8)); super.channelInactive(ctx); } @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;server read complete...\u0026#34;); ctx.writeAndFlush(Unpooled.copiedBuffer(\u0026#34;server read complete...\u0026#34;, StandardCharsets.UTF_8)); super.channelReadComplete(ctx); } @Override public void channelUnregistered(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;server unregistered...\u0026#34;); ctx.writeAndFlush(Unpooled.copiedBuffer(\u0026#34;server unregistered...\u0026#34;, StandardCharsets.UTF_8)); super.channelUnregistered(ctx); } @Override public void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;server write changed...\u0026#34;); ctx.writeAndFlush(Unpooled.copiedBuffer(\u0026#34;server write changed...\u0026#34;, StandardCharsets.UTF_8)); super.channelWritabilityChanged(ctx); } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\u0026#34;server read...\u0026#34;); ByteBuf receivePkg = (ByteBuf) msg; System.out.println(receivePkg); String receiveData = receivePkg.toString(StandardCharsets.UTF_8); System.out.println(receiveData); ctx.writeAndFlush(Unpooled.copiedBuffer(\u0026#34;[server] receive client\u0026#39;s data: \u0026#34; + receiveData + \u0026#34;\\n\u0026#34;, StandardCharsets.UTF_8)); super.channelRead(ctx, msg); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;server active...tcp channel has been established.\u0026#34;); super.channelActive(ctx); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { // socket 异常丢弃，因为关闭client时会发生Connection reset if (!(cause instanceof SocketException)) { System.err.println(cause.getMessage()); super.exceptionCaught(ctx, cause); } } } 优缺点 优点\n与原生nio一样，对于高并发服务器而言，性能支持友好，对于C10K问题而言不需要开辟10k个线程 ByteBuf相对原生ByteBuffer封装更优秀，功能支持更全，默认使用堆外内存，并且有自己的内存池管理机制 编程模型相对原生nio更好理解，框架层的解耦实现很不错，开发能更关注业务 缺点（不大）\n相较BIO的开发难度还是更高一些 资源使用相较原生nio更多（框架层的抽象 \u0026amp; 内存管理） 总结 使用java处理常见的高性能服务器场景，用netty就完了，或者没有自定义协议的需求，直接使用基于netty再封装的开发框架，例如vertx。\n使用netty的大型项目 GRPC ElasticSearch Kafka Discord（国外的社区聊天app） Twitter （国外的社交媒体app） CAT（美团开发的一个日志系统） ","date":"2024-11-30T01:23:56+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E6%A1%86%E6%9E%B6-netty/","title":"高性能网络通信框架 Netty"},{"content":"redis通信 源码分析 系统初始化 \u0026amp; eventloop事件循环总线构建 从main函数说起（原300+行，精简部分非核心内容后包含注释100+行） 网络通信相关主要为：在main函数中启动epoll监听，io多路复用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 int main(int argc, char **argv) { struct timeval tv; int j; char config_from_stdin = 0; /* 系统基础依赖初始化： 1. 时区设置 2. 内存oom处理方法 3. 随机数/哈希种子生成 4. crc64校验码初始化 */ char *exec_name = strrchr(argv[0], \u0026#39;/\u0026#39;); if (exec_name == NULL) exec_name = argv[0]; server.sentinel_mode = checkForSentinelMode(argc,argv, exec_name); initServerConfig(); ACLInit(); /* 初始化 ACL（访问控制列表）系统，网络连接时需要根据ACL控制权限，此时未加载实际配置 */ moduleInitModulesSystem(); connTypeInitialize(); /* 存储可执行文件路径和启动参数，用于以后重启服务器 */ server.executable = getAbsolutePath(argv[0]); server.exec_argv = zmalloc(sizeof(char*)*(argc+1)); server.exec_argv[argc] = NULL; for (j = 0; j \u0026lt; argc; j++) server.exec_argv[j] = zstrdup(argv[j]); /* 初始化 Sentinel 相关配置（如果是 Sentinel 模式） */ if (server.sentinel_mode) { initSentinelConfig(); initSentinel(); } /* 检查是否需要启动 redis-check-rdb 或 redis-check-aof 模式 */ if (strstr(exec_name,\u0026#34;redis-check-rdb\u0026#34;) != NULL) redis_check_rdb_main(argc,argv,NULL); else if (strstr(exec_name,\u0026#34;redis-check-aof\u0026#34;) != NULL) redis_check_aof_main(argc,argv); /* 参数解析 */ if (argc \u0026gt;= 2) { j = 1; sds options = sdsempty(); // 使用内部定义的sds字符串结构 /* 解析特殊参数 --version，--help */ if (strcmp(argv[1], \u0026#34;-v\u0026#34;) == 0 || strcmp(argv[1], \u0026#34;--version\u0026#34;) == 0) { sds version = getVersion(); printf(\u0026#34;Redis server %s\\n\u0026#34;, version); sdsfree(version); exit(0); } if (strcmp(argv[1], \u0026#34;--help\u0026#34;) == 0 || strcmp(argv[1], \u0026#34;-h\u0026#34;) == 0) usage(); sds *argv_tmp; int argc_tmp; int handled_last_config_arg = 1; while(j \u0026lt; argc) { /* 遍历解析参数 */ j++; } /* 根据参数完成必要文件配置的加载 */ loadServerConfig(server.configfile, config_from_stdin, options); if (server.sentinel_mode) loadSentinelConfigFromQueue(); sdsfree(options); } if (server.sentinel_mode) sentinelCheckConfigFile(); /* 核心：启动服务 */ initServer(); // 核心中的核心：载入server对象相关的核心组件：signal信号处理器，thread线程管理器，eventloop事件处理总线等 if (background || server.pidfile) createPidFile(); if (server.set_proc_title) redisSetProcTitle(NULL); redisAsciiArt(); // 打印启动redis的ASCII文字 checkTcpBacklogSettings(); if (server.cluster_enabled) { clusterInit(); } if (!server.sentinel_mode) { moduleInitModulesSystemLast(); moduleLoadFromQueue(); } // acl读取实际配置 ACLLoadUsersAtStartup(); initListeners(); if (server.cluster_enabled) { clusterInitLast(); } InitServerLast(); if (!server.sentinel_mode) { // 非sentinel模式 serverLog(LL_NOTICE,\u0026#34;Server initialized\u0026#34;); aofLoadManifestFromDisk(); loadDataFromDisk(); aofOpenIfNeededOnServerStart(); aofDelHistoryFiles(); applyAppendOnlyConfig(); // 集群模式校验 if (server.cluster_enabled) { serverAssert(verifyClusterConfigWithData() == C_OK); } // 打印所有监听器的状态 for (j = 0; j \u0026lt; CONN_TYPE_MAX; j++) { connListener *listener = \u0026amp;server.listeners[j]; if (listener-\u0026gt;ct == NULL) continue; serverLog(LL_NOTICE,\u0026#34;Ready to accept connections %s\u0026#34;, listener-\u0026gt;ct-\u0026gt;get_type(NULL)); } if (server.supervised_mode == SUPERVISED_SYSTEMD) { // 如果是由 systemd 监督运行的 Redis 实例，通知 systemd Redis 状态 } } else { sentinelIsRunning(); if (server.supervised_mode == SUPERVISED_SYSTEMD) { // 如果是由 systemd 监督运行的 sentinel 实例，通知 systemd sentinel 状态 } } /* 内存分配过小（1MB）警告 */ if (server.maxmemory \u0026gt; 0 \u0026amp;\u0026amp; server.maxmemory \u0026lt; 1024*1024) { serverLog(LL_WARNING,\u0026#34;WARNING: You specified a maxmemory value that is less than 1MB (current value is %llu bytes). Are you sure this is what you really want?\u0026#34;, server.maxmemory); } redisSetCpuAffinity(server.server_cpulist); setOOMScoreAdj(-1); // epoll监听，io多路复用，死循环 aeMain(server.el); aeDeleteEventLoop(server.el); return 0; } 核心中的核心：initServer方法，载入server对象相关的核心组件：signal信号处理器，thread线程管理器，eventloop事件处理总线等。（原200+行，精简部分非核心内容后包含注释60+行） 网络通信相关主要为：在初始化函数中创建thread线程管理器，eventloop事件处理总线 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 void initServer(void) { // 信号处理器，例如ctrl+c发送SIGKILL信号，此时需要关闭服务 setupSignalHandlers(); // 线程管理器初始化 ThreadsManager_init(); makeThreadKillable(); /* 在从配置系统设置默认值后进行初始化 */ server.aof_state = server.aof_enabled ? AOF_ON : AOF_OFF; server.fsynced_reploff = server.aof_enabled ? 0 : -1; server.hz = server.config_hz; // 心跳频率 server.pid = getpid(); // 创建eventloop事件处理总线，基于epoll机制（linux） server.el = aeCreateEventLoop(server.maxclients+CONFIG_FDSET_INCR); if (server.el == NULL) { serverLog(LL_WARNING, \u0026#34;Failed creating the event loop. Error message: \u0026#39;%s\u0026#39;\u0026#34;, strerror(errno)); exit(1); } /* 创建定时器回调，这是我们处理许多后台操作的方式， 比如客户端超时、未访问的过期键的淘汰等 */ if (aeCreateTimeEvent(server.el, 1, serverCron, NULL, NULL) == AE_ERR) { serverPanic(\u0026#34;Can\u0026#39;t create event loop timers.\u0026#34;); exit(1); } /* 为用于唤醒事件循环的管道注册一个可读事件， 用于模块线程间的通信 */ if (aeCreateFileEvent(server.el, server.module_pipe[0], AE_READABLE, modulePipeReadable,NULL) == AE_ERR) { serverPanic( \u0026#34;Error registering the readable event for the module pipe.\u0026#34;); } /* 注册epoll阻塞前后的回调函数（需在加载持久化之前完成，因为它会被 processEventsWhileBlocked 使用） */ aeSetBeforeSleepProc(server.el,beforeSleep); aeSetAfterSleepProc(server.el,afterSleep); /* 32位老系统受限于寻址上限32bit，最多访问2^32个字节，也就是4294967296B -\u0026gt; 4GB，redis会默认限制3GB上限 */ if (server.arch_bits == 32 \u0026amp;\u0026amp; server.maxmemory == 0) { serverLog(LL_WARNING,\u0026#34;Warning: 32 bit instance detected but no memory limit set. Setting 3 GB maxmemory limit with \u0026#39;noeviction\u0026#39; policy now.\u0026#34;); server.maxmemory = 3072LL*(1024*1024); /* 3 GB */ server.maxmemory_policy = MAXMEMORY_NO_EVICTION; } // 脚本系统初始化 luaEnvInit(); scriptingInit(1); if (functionsInit() == C_ERR) { serverPanic(\u0026#34;Functions initialization failed, check the server logs.\u0026#34;); exit(1); } // 基本监控初始化：提供慢查询告警/延迟监控等功能 slowlogInit(); latencyMonitorInit(); // 参照配置初始化密码，一般不启用 ACLUpdateDefaultUserPassword(server.requirepass); // 定时器功能初始化 applyWatchdogPeriod(); if (server.maxmemory_clients != 0) initServerClientMemUsageBuckets(); } aeCreateEventLoop方法：创建事件循环总线 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 aeEventLoop *aeCreateEventLoop(int setsize) { aeEventLoop *eventLoop; monotonicInit(); /* just in case the calling app didn\u0026#39;t initialize */ // 分配内存：最大感兴趣的fd为setsize if ((eventLoop = zmalloc(sizeof(*eventLoop))) == NULL) goto err; eventLoop-\u0026gt;events = zmalloc(sizeof(aeFileEvent)*setsize); eventLoop-\u0026gt;fired = zmalloc(sizeof(aeFiredEvent)*setsize); if (eventLoop-\u0026gt;events == NULL || eventLoop-\u0026gt;fired == NULL) goto err; eventLoop-\u0026gt;setsize = setsize; eventLoop-\u0026gt;timeEventHead = NULL; eventLoop-\u0026gt;timeEventNextId = 0; eventLoop-\u0026gt;stop = 0; eventLoop-\u0026gt;maxfd = -1; eventLoop-\u0026gt;beforesleep = NULL; eventLoop-\u0026gt;aftersleep = NULL; eventLoop-\u0026gt;flags = 0; if (aeApiCreate(eventLoop) == -1) goto err; // 核心：调用封装的函数aeApiCreate /* Events的关注事件默认置为0（不关注任何事件）*/ for (int i = 0; i \u0026lt; setsize; i++) eventLoop-\u0026gt;events[i].mask = AE_NONE; return eventLoop; err: // 失败则释放内存 if (eventLoop) { zfree(eventLoop-\u0026gt;events); zfree(eventLoop-\u0026gt;fired); zfree(eventLoop); } return NULL; } /* ae_epoll.c，仅在上面代码中调用，创建事件总线\t这里依赖系统内置库函数：epoll_create，其中size参数仅为参考值，对较新的linux版本来说无实际作用 */ static int aeApiCreate(aeEventLoop *eventLoop) { aeApiState *state = zmalloc(sizeof(aeApiState)); if (!state) return -1; state-\u0026gt;events = zmalloc(sizeof(struct epoll_event)*eventLoop-\u0026gt;setsize); if (!state-\u0026gt;events) { zfree(state); return -1; } state-\u0026gt;epfd = epoll_create(1024); /* 1024 is just a hint for the kernel */ if (state-\u0026gt;epfd == -1) { zfree(state-\u0026gt;events); zfree(state); return -1; } anetCloexec(state-\u0026gt;epfd); eventLoop-\u0026gt;apidata = state; return 0; } ae_epoll.c封装系统库函数（无精简） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 #include \u0026lt;sys/epoll.h\u0026gt; typedef struct aeApiState { int epfd; struct epoll_event *events; } aeApiState; /* 仅在aeCreateEventLoop代码中调用，创建事件总线\t依赖系统内置库函数：epoll_create，其中： size参数仅为参考值，对较新的linux版本来说无实际作用 */ static int aeApiCreate(aeEventLoop *eventLoop) { aeApiState *state = zmalloc(sizeof(aeApiState)); if (!state) return -1; state-\u0026gt;events = zmalloc(sizeof(struct epoll_event)*eventLoop-\u0026gt;setsize); if (!state-\u0026gt;events) { zfree(state); return -1; } state-\u0026gt;epfd = epoll_create(1024); /* 1024 is just a hint for the kernel */ if (state-\u0026gt;epfd == -1) { zfree(state-\u0026gt;events); zfree(state); return -1; } anetCloexec(state-\u0026gt;epfd); eventLoop-\u0026gt;apidata = state; return 0; } // resize event数组，类似vector(c)/list(java)/slice(golang/python)动态扩容 static int aeApiResize(aeEventLoop *eventLoop, int setsize) { aeApiState *state = eventLoop-\u0026gt;apidata; state-\u0026gt;events = zrealloc(state-\u0026gt;events, sizeof(struct epoll_event)*setsize); return 0; } // 释放资源 static void aeApiFree(aeEventLoop *eventLoop) { aeApiState *state = eventLoop-\u0026gt;apidata; close(state-\u0026gt;epfd); zfree(state-\u0026gt;events); zfree(state); } /* 在eventloop中注册新的fd，mask为感兴趣的事件 依赖系统内置库函数epoll_ctl，其中： epfd为事件总线fd， op为注册操作，枚举EPOLL_CTL_ADD, EPOLL_CTL_ADD, EPOLL_CTL_DEL， fd为注册的新fd， ee为新建的epoll_event结构体实例 */ static int aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask) { aeApiState *state = eventLoop-\u0026gt;apidata; struct epoll_event ee = {0}; /* avoid valgrind warning */ /* If the fd was already monitored for some event, we need a MOD * operation. Otherwise we need an ADD operation. */ int op = eventLoop-\u0026gt;events[fd].mask == AE_NONE ? EPOLL_CTL_ADD : EPOLL_CTL_MOD; ee.events = 0; mask |= eventLoop-\u0026gt;events[fd].mask; /* Merge old events */ if (mask \u0026amp; AE_READABLE) ee.events |= EPOLLIN; if (mask \u0026amp; AE_WRITABLE) ee.events |= EPOLLOUT; ee.data.fd = fd; if (epoll_ctl(state-\u0026gt;epfd,op,fd,\u0026amp;ee) == -1) return -1; return 0; } /* 在eventloop中注册新的fd，mask为感兴趣的事件 依赖系统内置库函数epoll_ctl，其中： epfd为事件总线fd， op为注册操作，枚举EPOLL_CTL_ADD, EPOLL_CTL_ADD, EPOLL_CTL_DEL， fd为注册的新fd， ee为新建的epoll_event结构体实例，关注的mask写在这个结构体中 */ static void aeApiDelEvent(aeEventLoop *eventLoop, int fd, int delmask) { aeApiState *state = eventLoop-\u0026gt;apidata; struct epoll_event ee = {0}; /* avoid valgrind warning */ int mask = eventLoop-\u0026gt;events[fd].mask \u0026amp; (~delmask); ee.events = 0; if (mask \u0026amp; AE_READABLE) ee.events |= EPOLLIN; if (mask \u0026amp; AE_WRITABLE) ee.events |= EPOLLOUT; ee.data.fd = fd; if (mask != AE_NONE) { epoll_ctl(state-\u0026gt;epfd,EPOLL_CTL_MOD,fd,\u0026amp;ee); } else { /* Note, Kernel \u0026lt; 2.6.9 requires a non null event pointer even for * EPOLL_CTL_DEL. */ epoll_ctl(state-\u0026gt;epfd,EPOLL_CTL_DEL,fd,\u0026amp;ee); } } /* 在eventloop中注册新的fd，mask为感兴趣的事件 依赖系统内置库函数epoll_wait，其中： epfd为事件总线fd， events为已注册的全部感兴趣事件， tvp相关为等待时间，-1为一直阻塞，直到有注册的感兴趣事件发生 */ static int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp) { aeApiState *state = eventLoop-\u0026gt;apidata; int retval, numevents = 0; retval = epoll_wait(state-\u0026gt;epfd,state-\u0026gt;events,eventLoop-\u0026gt;setsize, tvp ? (tvp-\u0026gt;tv_sec*1000 + (tvp-\u0026gt;tv_usec + 999)/1000) : -1); if (retval \u0026gt; 0) { int j; numevents = retval; for (j = 0; j \u0026lt; numevents; j++) { int mask = 0; struct epoll_event *e = state-\u0026gt;events+j; if (e-\u0026gt;events \u0026amp; EPOLLIN) mask |= AE_READABLE; if (e-\u0026gt;events \u0026amp; EPOLLOUT) mask |= AE_WRITABLE; if (e-\u0026gt;events \u0026amp; EPOLLERR) mask |= AE_WRITABLE|AE_READABLE; if (e-\u0026gt;events \u0026amp; EPOLLHUP) mask |= AE_WRITABLE|AE_READABLE; eventLoop-\u0026gt;fired[j].fd = e-\u0026gt;data.fd; eventLoop-\u0026gt;fired[j].mask = mask; } } else if (retval == -1 \u0026amp;\u0026amp; errno != EINTR) { panic(\u0026#34;aeApiPoll: epoll_wait, %s\u0026#34;, strerror(errno)); } return numevents; } static char *aeApiName(void) { return \u0026#34;epoll\u0026#34;; } 哪些地方调用了注册事件 server启动过程中：initListeners -\u0026gt; createSocketAcceptHandler （accept） connSocketAcceptHandler 创建客户端连接时：ConnectionType -\u0026gt; connSocketConnect（connect） ae_handler -\u0026gt; connSocketSetReadHandler 建立client通信时：createClient -\u0026gt; readQueryFromClient ae_handler -\u0026gt; connSocketSetWriteHandler 初始化服务端时：initServer -\u0026gt; aeSetBeforeSleepProc -\u0026gt; beforeSleep -\u0026gt; handleClientsWithPendingWritesUsingThreads -\u0026gt; sendReplyToClient 同步rdb数据：initServer -\u0026gt; aeCreateTimeEvent(server.el, 1, serverCron, NULL, NULL) -\u0026gt; serverCron -\u0026gt; checkChildrenDone -\u0026gt; replicationStartPendingFork -\u0026gt; rdbSaveToSlavesSockets rdbPipeReadHandler sentinel通信：initServer -\u0026gt; aeCreateTimeEvent(server.el, 1, serverCron, NULL, NULL) -\u0026gt; serverCron -\u0026gt; sentinelTimer -\u0026gt; sentinelHandleDictOfRedisInstances -\u0026gt; sentinelHandleRedisInstance -\u0026gt; sentinelReconnectInstance -\u0026gt; redisAeAttach -\u0026gt; redisAeAddWrite pipeline管道的bio通信：initServer -\u0026gt; InitServerLast -\u0026gt; bioInit 注册事件处理：main -\u0026gt; aeMain -\u0026gt; aeApiPoll -\u0026gt; epoll_wait 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 // 死循环处理事件 void aeMain(aeEventLoop *eventLoop) { eventLoop-\u0026gt;stop = 0; while (!eventLoop-\u0026gt;stop) { aeProcessEvents(eventLoop, AE_ALL_EVENTS| AE_CALL_BEFORE_SLEEP| AE_CALL_AFTER_SLEEP); } } typedef struct aeEventLoop { int maxfd; /* highest file descriptor currently registered */ int setsize; /* max number of file descriptors tracked */ long long timeEventNextId; aeFileEvent *events; /* Registered events */ aeFiredEvent *fired; /* Fired events */ aeTimeEvent *timeEventHead; int stop; void *apidata; /* This is used for polling API specific data */ aeBeforeSleepProc *beforesleep; aeBeforeSleepProc *aftersleep; int flags; } aeEventLoop; typedef struct aeFileEvent { int mask; /* one of AE_(READABLE|WRITABLE|BARRIER) */ aeFileProc *rfileProc; aeFileProc *wfileProc; void *clientData; } aeFileEvent; int aeProcessEvents(aeEventLoop *eventLoop, int flags) { int processed = 0, numevents; /* 如果没有文件事件和时间事件需要处理，直接返回 */ if (!(flags \u0026amp; AE_TIME_EVENTS) \u0026amp;\u0026amp; !(flags \u0026amp; AE_FILE_EVENTS)) return 0; /* 即使没有文件事件，如果有时间事件，也需要调用 aeApiPoll 来等待下一次时间事件的触发 */ if (eventLoop-\u0026gt;maxfd != -1 || ((flags \u0026amp; AE_TIME_EVENTS) \u0026amp;\u0026amp; !(flags \u0026amp; AE_DONT_WAIT))) { int j; struct timeval tv, *tvp = NULL; /* NULL means infinite wait. */ int64_t usUntilTimer; if (eventLoop-\u0026gt;beforesleep != NULL \u0026amp;\u0026amp; (flags \u0026amp; AE_CALL_BEFORE_SLEEP)) /* Before sleep callback. */ eventLoop-\u0026gt;beforesleep(eventLoop); /* eventLoop-\u0026gt;flags 可能会在 beforeSleep 中发生改变，所以需要在调用 beforeSleep 后重新检查 同时，flags 参数优先级更高，特别是 AE_DONT_WAIT 设置时，应忽略 eventLoop-\u0026gt;flags 中的值 */ if ((flags \u0026amp; AE_DONT_WAIT) || (eventLoop-\u0026gt;flags \u0026amp; AE_DONT_WAIT)) { tv.tv_sec = tv.tv_usec = 0; tvp = \u0026amp;tv; } else if (flags \u0026amp; AE_TIME_EVENTS) { usUntilTimer = usUntilEarliestTimer(eventLoop); if (usUntilTimer \u0026gt;= 0) { tv.tv_sec = usUntilTimer / 1000000; tv.tv_usec = usUntilTimer % 1000000; tvp = \u0026amp;tv; } } /* 调用aeApiPoll多路复用方法，Call the multiplexing API, will return only on timeout or when some event fires. */ numevents = aeApiPoll(eventLoop, tvp); /* 如果没有请求处理文件事件，就跳过文件事件的处理 */ if (!(flags \u0026amp; AE_FILE_EVENTS)) { numevents = 0; } /* After sleep callback. */ if (eventLoop-\u0026gt;aftersleep != NULL \u0026amp;\u0026amp; flags \u0026amp; AE_CALL_AFTER_SLEEP) eventLoop-\u0026gt;aftersleep(eventLoop); for (j = 0; j \u0026lt; numevents; j++) { int fd = eventLoop-\u0026gt;fired[j].fd; aeFileEvent *fe = \u0026amp;eventLoop-\u0026gt;events[fd]; int mask = eventLoop-\u0026gt;fired[j].mask; int fired = 0; /* Number of events fired for current fd. */ /* 默认情况下，先执行可读事件，再执行可写事件。这个顺序可以确保有可读数据时，优先处理读取请求。 * 如果设置了 AE_BARRIER 标志，则表示我们希望反转执行顺序，先执行可写事件。 */ int invert = fe-\u0026gt;mask \u0026amp; AE_BARRIER; /* 检查事件是否仍然有效：可能已经处理过的事件在当前回合中已经被移除 */ if (!invert \u0026amp;\u0026amp; fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_READABLE) { fe-\u0026gt;rfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); fired++; fe = \u0026amp;eventLoop-\u0026gt;events[fd]; /* Refresh in case of resize. */ } /* 执行可写事件 */ if (fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_WRITABLE) { if (!fired || fe-\u0026gt;wfileProc != fe-\u0026gt;rfileProc) { fe-\u0026gt;wfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); fired++; } } /* 如果需要反转执行顺序，在可写事件后执行可读事件 */ if (invert) { fe = \u0026amp;eventLoop-\u0026gt;events[fd]; /* Refresh in case of resize. */ if ((fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_READABLE) \u0026amp;\u0026amp; (!fired || fe-\u0026gt;wfileProc != fe-\u0026gt;rfileProc)) { fe-\u0026gt;rfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); fired++; } } processed++; } } /* 如果需要处理时间事件，则继续处理时间事件 */ if (flags \u0026amp; AE_TIME_EVENTS) processed += processTimeEvents(eventLoop); return processed; } 多路复用处理方法（类似netty中的handler实现） 协议解析：createClient -\u0026gt; readQueryFromClient -\u0026gt; processInputBuffer -\u0026gt; processXXXBuffer -\u0026gt; processCommandAndResetClient inline：processInlineBuffer multi：processMultibulkBuffer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 void readQueryFromClient(connection *conn) { client *c = connGetPrivateData(conn); int nread, big_arg = 0; size_t qblen, readlen; /* 如果启用了线程化 I/O，并且需要在退出事件循环时稍后读取客户端数据 */ if (postponeClientRead(c)) return; /* 更新服务器的总读取次数 */ atomicIncr(server.stat_total_reads_processed, 1); readlen = PROTO_IOBUF_LEN; /* 如果这是一个多批量请求，并且正在处理一个较大的批量回复，尽量确保查询缓冲区 * 精确包含表示对象的 SDS 字符串，即使这可能会导致更多的 read(2) 调用。 * 这样，函数 processMultiBulkBuffer() 可以避免复制缓冲区来创建 Redis 对象。 */ if (c-\u0026gt;reqtype == PROTO_REQ_MULTIBULK \u0026amp;\u0026amp; c-\u0026gt;multibulklen \u0026amp;\u0026amp; c-\u0026gt;bulklen != -1 \u0026amp;\u0026amp; c-\u0026gt;bulklen \u0026gt;= PROTO_MBULK_BIG_ARG) { /* 对于大的参数，客户端总是使用其私有的查询缓冲区。 * 使用可重用的查询缓冲区可能会导致其超出 32k，最终让客户端接管这个缓冲区。 */ if (!c-\u0026gt;querybuf) c-\u0026gt;querybuf = sdsempty(); ssize_t remaining = (size_t)(c-\u0026gt;bulklen+2)-(sdslen(c-\u0026gt;querybuf)-c-\u0026gt;qb_pos); big_arg = 1; /* 注意：\u0026#39;remaining\u0026#39; 变量在某些边缘情况下可能为零，例如当在 CLIENT PAUSE 后恢复被阻塞的客户端时 */ if (remaining \u0026gt; 0) readlen = remaining; /* 如果是主客户端，在遇到大参数时需要扩大读取长度，但不需要对齐到下一个参数，可以读取更多数据 */ if (c-\u0026gt;flags \u0026amp; CLIENT_MASTER \u0026amp;\u0026amp; readlen \u0026lt; PROTO_IOBUF_LEN) readlen = PROTO_IOBUF_LEN; } else if (c-\u0026gt;querybuf == NULL) { if (unlikely(thread_reusable_qb_used)) { /* 如果可重用的查询缓冲区已被其他客户端使用，切换到使用客户端的私有查询缓冲区。 * 这种情况仅在通过 processEventsWhileBlocked() 执行嵌套命令时发生。 */ c-\u0026gt;querybuf = sdsnewlen(NULL, PROTO_IOBUF_LEN); sdsclear(c-\u0026gt;querybuf); } else { /* 如果查询缓冲区不存在，则创建可重用的查询缓冲区 */ if (!thread_reusable_qb) { thread_reusable_qb = sdsnewlen(NULL, PROTO_IOBUF_LEN); sdsclear(thread_reusable_qb); } /* 将可重用的查询缓冲区分配给客户端，并标记为正在使用 */ serverAssert(sdslen(thread_reusable_qb) == 0); c-\u0026gt;querybuf = thread_reusable_qb; c-\u0026gt;flags |= CLIENT_REUSABLE_QUERYBUFFER; thread_reusable_qb_used = 1; } } qblen = sdslen(c-\u0026gt;querybuf); if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; // 主客户端的查询缓冲区可以贪婪扩展 (big_arg || sdsalloc(c-\u0026gt;querybuf) \u0026lt; PROTO_IOBUF_LEN)) { /* 在读取大参数时，我们不会读取超过一个参数的内容到查询缓冲区， * 所以不需要预分配多于所需的空间，因此使用非贪婪扩展。 */ c-\u0026gt;querybuf = sdsMakeRoomForNonGreedy(c-\u0026gt;querybuf, readlen); /* 稍后将峰值设置为已使用的部分，但这里我们过度分配，因为我们知道需要的空间，确保在使用前不会被缩小。 */ if (c-\u0026gt;querybuf_peak \u0026lt; qblen + readlen) c-\u0026gt;querybuf_peak = qblen + readlen; } else { c-\u0026gt;querybuf = sdsMakeRoomFor(c-\u0026gt;querybuf, readlen); /* 从套接字中尽可能多地读取数据，以节省 read(2) 系统调用次数。 */ readlen = sdsavail(c-\u0026gt;querybuf); } nread = connRead(c-\u0026gt;conn, c-\u0026gt;querybuf+qblen, readlen); if (nread == -1) { if (connGetState(conn) == CONN_STATE_CONNECTED) { goto done; } else { serverLog(LL_VERBOSE, \u0026#34;从客户端读取数据时出错: %s\u0026#34;, connGetLastError(c-\u0026gt;conn)); freeClientAsync(c); goto done; } } else if (nread == 0) { if (server.verbosity \u0026lt;= LL_VERBOSE) { sds info = catClientInfoString(sdsempty(), c); serverLog(LL_VERBOSE, \u0026#34;客户端关闭了连接 %s\u0026#34;, info); sdsfree(info); } freeClientAsync(c); goto done; } /* 更新查询缓冲区的长度 */ sdsIncrLen(c-\u0026gt;querybuf, nread); qblen = sdslen(c-\u0026gt;querybuf); if (c-\u0026gt;querybuf_peak \u0026lt; qblen) c-\u0026gt;querybuf_peak = qblen; /* 更新最后交互时间 */ c-\u0026gt;lastinteraction = server.unixtime; if (c-\u0026gt;flags \u0026amp; CLIENT_MASTER) { c-\u0026gt;read_reploff += nread; atomicIncr(server.stat_net_repl_input_bytes, nread); } else { atomicIncr(server.stat_net_input_bytes, nread); } /* 对于普通客户端，如果查询缓冲区的大小超过限制或需要身份验证，则关闭客户端连接 */ if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; /* MULTI/EXEC 队列中的命令尚未执行，因此它们也算作查询缓冲区的一部分 */ (c-\u0026gt;mstate.argv_len_sums + sdslen(c-\u0026gt;querybuf) \u0026gt; server.client_max_querybuf_len || (c-\u0026gt;mstate.argv_len_sums + sdslen(c-\u0026gt;querybuf) \u0026gt; 1024*1024 \u0026amp;\u0026amp; authRequired(c)))) { sds ci = catClientInfoString(sdsempty(),c), bytes = sdsempty(); bytes = sdscatrepr(bytes,c-\u0026gt;querybuf,64); serverLog(LL_WARNING,\u0026#34;关闭客户端，查询缓冲区超过最大限制: %s (查询缓冲区初始字节: %s)\u0026#34;, ci, bytes); sdsfree(ci); sdsfree(bytes); freeClientAsync(c); atomicIncr(server.stat_client_qbuf_limit_disconnections, 1); goto done; } /* 如果客户端输入缓冲区还有数据，继续解析并检查是否有完整的命令需要执行 */ if (processInputBuffer(c) == C_ERR) c = NULL; done: if (c \u0026amp;\u0026amp; (c-\u0026gt;flags \u0026amp; CLIENT_REUSABLE_QUERYBUFFER)) { serverAssert(c-\u0026gt;qb_pos == 0); /* 确保客户端的查询缓冲区在 processInputBuffer 中被修剪 */ resetReusableQueryBuf(c); } beforeNextClient(c); } processInputBuffer读取client请求信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 /* 该函数在每次客户端结构体 \u0026#39;c\u0026#39; 中有更多查询缓冲区需要处理时被调用， * 可能是因为我们从套接字读取了更多的数据，或者客户端被阻塞并在之后重新激活， * 所以可能存在待处理的查询缓冲区，这些缓冲区可能已经代表一个完整的命令需要处理。 * 如果在处理过程中客户端已经被释放，则返回 C_ERR */ int processInputBuffer(client *c) { /* 当输入缓冲区有内容时，继续处理 */ while(c-\u0026gt;qb_pos \u0026lt; sdslen(c-\u0026gt;querybuf)) { /* 如果客户端当前被阻塞，立即中止 */ if (c-\u0026gt;flags \u0026amp; CLIENT_BLOCKED) break; /* 如果客户端有待处理的命令，不要继续处理更多的缓冲区 */ if (c-\u0026gt;flags \u0026amp; CLIENT_PENDING_COMMAND) break; /* 如果客户端是主客户端，并且当前有忙碌脚本，暂停处理输入 */ if (isInsideYieldingLongCommand() \u0026amp;\u0026amp; c-\u0026gt;flags \u0026amp; CLIENT_MASTER) break; /* 如果设置了 CLIENT_CLOSE_AFTER_REPLY 标志，处理完回复后就关闭连接， * 不允许继续处理更多的命令 */ if (c-\u0026gt;flags \u0026amp; (CLIENT_CLOSE_AFTER_REPLY|CLIENT_CLOSE_ASAP)) break; /* 如果请求类型未知，判断请求类型 */ if (!c-\u0026gt;reqtype) { if (c-\u0026gt;querybuf[c-\u0026gt;qb_pos] == \u0026#39;*\u0026#39;) { c-\u0026gt;reqtype = PROTO_REQ_MULTIBULK; // 多批量请求 } else { c-\u0026gt;reqtype = PROTO_REQ_INLINE; // 单行命令 } } /* 根据请求类型处理缓冲区 */ if (c-\u0026gt;reqtype == PROTO_REQ_INLINE) { if (processInlineBuffer(c) != C_OK) break; // 处理单行命令 } else if (c-\u0026gt;reqtype == PROTO_REQ_MULTIBULK) { if (processMultibulkBuffer(c) != C_OK) break; // 处理多批量命令 } else { serverPanic(\u0026#34;Unknown request type\u0026#34;); // 未知的请求类型，程序崩溃 } /* 多批量请求处理可能导致 argc \u0026lt;= 0 */ if (c-\u0026gt;argc == 0) { resetClientInternal(c, 0); // 如果没有有效的参数，重置客户端 } else { /* 如果是 I/O 线程上下文，不能在此执行命令，只能标记客户端需要处理命令 */ if (io_threads_op != IO_THREADS_OP_IDLE) { serverAssert(io_threads_op == IO_THREADS_OP_READ); c-\u0026gt;flags |= CLIENT_PENDING_COMMAND; // 设置为待处理命令状态 break; } /* 准备好执行命令了 */ if (processCommandAndResetClient(c) == C_ERR) { /* 如果客户端已经不再有效，避免继续执行，直接返回 */ return C_ERR; } } } /* 如果客户端是主客户端，需要裁剪查询缓冲区 */ if (c-\u0026gt;flags \u0026amp; CLIENT_MASTER) { /* 如果客户端是主客户端，裁剪查询缓冲区到 repl_applied 指定的位置， * 因为主客户端的查询缓冲区不仅用于解析命令，还用于代理给子复制实例。 * * 需要裁剪查询缓冲区的场景： * 1. 没有接收到完整的命令 * 2. 主客户端因为客户端暂停而被阻塞 * 3. I/O 线程操作读取，主客户端被标记为 CLIENT_PENDING_COMMAND * * 在这些场景下，qb_pos 指向当前命令的一部分或下一个命令的开始位置， * 当前命令尚未应用，因此 repl_applied 不等于 qb_pos。*/ if (c-\u0026gt;repl_applied) { sdsrange(c-\u0026gt;querybuf, c-\u0026gt;repl_applied, -1); // 剩余的命令数据 c-\u0026gt;qb_pos -= c-\u0026gt;repl_applied; c-\u0026gt;repl_applied = 0; } } else if (c-\u0026gt;qb_pos) { /* 如果客户端不是主客户端，裁剪查询缓冲区 */ sdsrange(c-\u0026gt;querybuf, c-\u0026gt;qb_pos, -1); // 将查询缓冲区裁剪到当前位置 c-\u0026gt;qb_pos = 0; // 重置查询缓冲区位置 } /* 在处理查询缓冲区后更新客户端的内存使用情况， * 这对查询缓冲区比较大且没有在上述循环中被完全处理的客户端很重要（ * 例如部分发送的大命令）。*/ if (io_threads_op == IO_THREADS_OP_IDLE) updateClientMemUsageAndBucket(c); return C_OK; // 返回处理成功 } 协议解析 processInlineBuffer：set a b这样的简单命令 processMultibulkBuffer：mset a b c d这样的复合命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 /* 类似于 processMultibulkBuffer()，但是用于处理 inline 协议，而不是 RESP 协议。 * 该函数消耗客户端的查询缓冲区，并在客户端结构体中创建一个准备执行的命令。 * 如果命令已经准备好执行，则返回 C_OK；如果仍然需要读取更多协议数据才能形成一个有效的命令，则返回 C_ERR。 * 当出现协议错误时，返回 C_ERR；在这种情况下，客户端结构体会被设置为回复错误并关闭连接。 */ int processInlineBuffer(client *c) { char *newline; int argc, j, linefeed_chars = 1; sds *argv, aux; size_t querylen; /* 查找换行符的位置 */ newline = strchr(c-\u0026gt;querybuf + c-\u0026gt;qb_pos, \u0026#39;\\n\u0026#39;); /* 如果没有找到 \\r\\n 则返回，不做处理 */ if (newline == NULL) { if (sdslen(c-\u0026gt;querybuf) - c-\u0026gt;qb_pos \u0026gt; PROTO_INLINE_MAX_SIZE) { addReplyError(c, \u0026#34;Protocol error: too big inline request\u0026#34;); setProtocolError(\u0026#34;too big inline request\u0026#34;, c); } return C_ERR; } /* 处理 \\r\\n 的情况 */ if (newline != c-\u0026gt;querybuf + c-\u0026gt;qb_pos \u0026amp;\u0026amp; *(newline - 1) == \u0026#39;\\r\u0026#39;) { newline--; // 将 newline 指向 \\r 的前一个字符 linefeed_chars++; // 计算换行符的字符数 } /* 截取从当前指针到 \\r\\n 之间的内容 */ querylen = newline - (c-\u0026gt;querybuf + c-\u0026gt;qb_pos); aux = sdsnewlen(c-\u0026gt;querybuf + c-\u0026gt;qb_pos, querylen); // 创建一个新的 sds 字符串 argv = sdssplitargs(aux, \u0026amp;argc); // 分割命令行参数 sdsfree(aux); // 释放临时变量 aux if (argv == NULL) { addReplyError(c, \u0026#34;Protocol error: unbalanced quotes in request\u0026#34;); setProtocolError(\u0026#34;unbalanced quotes in inline request\u0026#34;, c); return C_ERR; } /* 如果查询长度为 0 且客户端是从属节点， * 则表示通过换行符刷新最后的 ACK 时间。 * 这是为了让从属节点在加载大型 RDB 文件时能够持续保持连接 */ if (querylen == 0 \u0026amp;\u0026amp; clientTypeIsSlave(c)) { c-\u0026gt;repl_ack_time = server.unixtime; } /* 主节点不应该发送 inline 协议来执行实际的命令。 * 如果发生这种情况，可能是 Redis 协议出现了同步问题， * 比如由于 PSYNC 出错导致的协议不一致。 * * 但是有一个例外：主节点可能只会发送一个换行符来保持连接活动。 */ if (querylen != 0 \u0026amp;\u0026amp; c-\u0026gt;flags \u0026amp; CLIENT_MASTER) { sdsfreesplitres(argv, argc); // 释放参数数组 serverLog(LL_WARNING, \u0026#34;WARNING: Receiving inline protocol from master, master stream corruption? Closing the master connection and discarding the cached master.\u0026#34;); setProtocolError(\u0026#34;Master using the inline protocol. Desync?\u0026#34;, c); return C_ERR; } /* 移动查询缓冲区位置，指向下一个查询命令 */ c-\u0026gt;qb_pos += querylen + linefeed_chars; /* 在客户端结构体中设置 argv 数组 */ if (argc) { /* 如果参数数量超过当前分配的空间，重新分配内存 */ if (unlikely(argc \u0026gt; c-\u0026gt;argv_len)) { zfree(c-\u0026gt;argv); // 释放旧的 argv c-\u0026gt;argv = zmalloc(sizeof(robj*) * argc); // 分配新的 argv 数组 c-\u0026gt;argv_len = argc; } c-\u0026gt;argv_len_sum = 0; // 重置参数长度总和 } /* 为所有的参数创建 Redis 对象 */ for (c-\u0026gt;argc = 0, j = 0; j \u0026lt; argc; j++) { c-\u0026gt;argv[c-\u0026gt;argc] = createObject(OBJ_STRING, argv[j]); // 创建字符串类型的 Redis 对象 c-\u0026gt;argc++; // 增加参数计数 c-\u0026gt;argv_len_sum += sdslen(argv[j]); // 更新参数总长度 } zfree(argv); // 释放临时分割后的参数数组 return C_OK; // 返回命令已准备好执行 } /* 处理客户端 \u0026#39;c\u0026#39; 的查询缓冲区，并为命令执行设置客户端的参数向量。 * 如果客户端有一个格式正确、准备执行的命令，返回 C_OK， * 否则，如果还需要更多的数据才能获得完整的命令，返回 C_ERR。 * 如果出现协议错误，返回 C_ERR；在这种情况下，客户端结构会被设置为回复错误并关闭连接。 * * 当 processInputBuffer() 检测到下一个命令是 RESP 格式时会调用此函数， * 因为命令的第一个字节是 \u0026#39;*\u0026#39;。否则，对于 inline 命令会调用 processInlineBuffer()。*/ int processMultibulkBuffer(client *c) { char *newline = NULL; int ok; long long ll; if (c-\u0026gt;multibulklen == 0) { /* 客户端应该已经被重置 */ serverAssertWithInfo(c, NULL, c-\u0026gt;argc == 0); /* 多重批量长度不能在没有 \\r\\n 的情况下读取 */ newline = strchr(c-\u0026gt;querybuf + c-\u0026gt;qb_pos, \u0026#39;\\r\u0026#39;); if (newline == NULL) { if (sdslen(c-\u0026gt;querybuf) - c-\u0026gt;qb_pos \u0026gt; PROTO_INLINE_MAX_SIZE) { addReplyError(c, \u0026#34;Protocol error: too big mbulk count string\u0026#34;); setProtocolError(\u0026#34;too big mbulk count string\u0026#34;, c); } return C_ERR; } /* 缓冲区中应也包含 \\n */ if (newline - (c-\u0026gt;querybuf + c-\u0026gt;qb_pos) \u0026gt; (ssize_t)(sdslen(c-\u0026gt;querybuf) - c-\u0026gt;qb_pos - 2)) return C_ERR; /* 确定这是一整行，因为 newline != NULL， * 所以可以继续解析多重批量长度 */ serverAssertWithInfo(c, NULL, c-\u0026gt;querybuf[c-\u0026gt;qb_pos] == \u0026#39;*\u0026#39;); ok = string2ll(c-\u0026gt;querybuf + 1 + c-\u0026gt;qb_pos, newline - (c-\u0026gt;querybuf + 1 + c-\u0026gt;qb_pos), \u0026amp;ll); if (!ok || ll \u0026gt; INT_MAX) { addReplyError(c, \u0026#34;Protocol error: invalid multibulk length\u0026#34;); setProtocolError(\u0026#34;invalid mbulk count\u0026#34;, c); return C_ERR; } else if (ll \u0026gt; 10 \u0026amp;\u0026amp; authRequired(c)) { addReplyError(c, \u0026#34;Protocol error: unauthenticated multibulk length\u0026#34;); setProtocolError(\u0026#34;unauth mbulk count\u0026#34;, c); return C_ERR; } c-\u0026gt;qb_pos = (newline - c-\u0026gt;querybuf) + 2; if (ll \u0026lt;= 0) return C_OK; c-\u0026gt;multibulklen = ll; /* 在客户端结构体中设置 argv 数组。 * 如果空间不足或者需要逐步分配空间，创建新的 argv */ if (unlikely(c-\u0026gt;multibulklen \u0026gt; c-\u0026gt;argv_len || c-\u0026gt;multibulklen \u0026gt; 1024)) { zfree(c-\u0026gt;argv); c-\u0026gt;argv_len = min(c-\u0026gt;multibulklen, 1024); c-\u0026gt;argv = zmalloc(sizeof(robj*) * c-\u0026gt;argv_len); } c-\u0026gt;argv_len_sum = 0; } serverAssertWithInfo(c, NULL, c-\u0026gt;multibulklen \u0026gt; 0); while (c-\u0026gt;multibulklen) { /* 如果未知，读取批量长度 */ if (c-\u0026gt;bulklen == -1) { newline = strchr(c-\u0026gt;querybuf + c-\u0026gt;qb_pos, \u0026#39;\\r\u0026#39;); if (newline == NULL) { if (sdslen(c-\u0026gt;querybuf) - c-\u0026gt;qb_pos \u0026gt; PROTO_INLINE_MAX_SIZE) { addReplyError(c, \u0026#34;Protocol error: too big bulk count string\u0026#34;); setProtocolError(\u0026#34;too big bulk count string\u0026#34;, c); return C_ERR; } break; } /* 缓冲区中也应该包含 \\n */ if (newline - (c-\u0026gt;querybuf + c-\u0026gt;qb_pos) \u0026gt; (ssize_t)(sdslen(c-\u0026gt;querybuf) - c-\u0026gt;qb_pos - 2)) break; if (c-\u0026gt;querybuf[c-\u0026gt;qb_pos] != \u0026#39;$\u0026#39;) { addReplyErrorFormat(c, \u0026#34;Protocol error: expected \u0026#39;$\u0026#39;, got \u0026#39;%c\u0026#39;\u0026#34;, c-\u0026gt;querybuf[c-\u0026gt;qb_pos]); setProtocolError(\u0026#34;expected $ but got something else\u0026#34;, c); return C_ERR; } ok = string2ll(c-\u0026gt;querybuf + c-\u0026gt;qb_pos + 1, newline - (c-\u0026gt;querybuf + c-\u0026gt;qb_pos + 1), \u0026amp;ll); if (!ok || ll \u0026lt; 0 || (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; ll \u0026gt; server.proto_max_bulk_len)) { addReplyError(c, \u0026#34;Protocol error: invalid bulk length\u0026#34;); setProtocolError(\u0026#34;invalid bulk length\u0026#34;, c); return C_ERR; } else if (ll \u0026gt; 16384 \u0026amp;\u0026amp; authRequired(c)) { addReplyError(c, \u0026#34;Protocol error: unauthenticated bulk length\u0026#34;); setProtocolError(\u0026#34;unauth bulk length\u0026#34;, c); return C_ERR; } c-\u0026gt;qb_pos = newline - c-\u0026gt;querybuf + 2; if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; ll \u0026gt;= PROTO_MBULK_BIG_ARG) { /* 如果客户端不是主节点（因为主节点的查询缓冲区只能在数据应用并发送给从节点后修剪）。 * * 如果我们将从网络读取一个较大的对象，尝试使其从 c-\u0026gt;querybuf 边界开始，这样可以优化对象创建， * 避免对数据进行大量复制。 * * 但是只有当未解析的数据长度小于或等于 ll+2 时才这样做。否则，修剪查询缓冲区就是浪费时间， * 因为此时查询缓冲区不仅仅包含我们的大批量数据。 */ if (sdslen(c-\u0026gt;querybuf) - c-\u0026gt;qb_pos \u0026lt;= (size_t)ll + 2) { sdsrange(c-\u0026gt;querybuf, c-\u0026gt;qb_pos, -1); c-\u0026gt;qb_pos = 0; /* 提示 sds 库有关字符串长度的预期 */ c-\u0026gt;querybuf = sdsMakeRoomForNonGreedy(c-\u0026gt;querybuf, ll + 2 - sdslen(c-\u0026gt;querybuf)); /* 我们后续会设置峰值为使用的部分，但此时超额分配是为了确保不会在使用前被缩小 */ if (c-\u0026gt;querybuf_peak \u0026lt; (size_t)ll + 2) c-\u0026gt;querybuf_peak = ll + 2; } } c-\u0026gt;bulklen = ll; } /* 读取批量参数 */ if (sdslen(c-\u0026gt;querybuf) - c-\u0026gt;qb_pos \u0026lt; (size_t)(c-\u0026gt;bulklen + 2)) { /* 数据不足（+2 是指尾部的 \\r\\n） */ break; } else { /* 检查是否有足够的空间存储参数，如果没有则进行扩展 */ if (c-\u0026gt;argc \u0026gt;= c-\u0026gt;argv_len) { c-\u0026gt;argv_len = min(c-\u0026gt;argv_len \u0026lt; INT_MAX / 2 ? c-\u0026gt;argv_len * 2 : INT_MAX, c-\u0026gt;argc + c-\u0026gt;multibulklen); c-\u0026gt;argv = zrealloc(c-\u0026gt;argv, sizeof(robj*) * c-\u0026gt;argv_len); } /* 优化：如果非主节点客户端的缓冲区仅包含我们的批量元素， * 那么直接使用当前的 sds 字符串而不是通过复制创建一个新的对象 */ if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; c-\u0026gt;qb_pos == 0 \u0026amp;\u0026amp; c-\u0026gt;bulklen \u0026gt;= PROTO_MBULK_BIG_ARG \u0026amp;\u0026amp; sdslen(c-\u0026gt;querybuf) == (size_t)(c-\u0026gt;bulklen + 2)) { c-\u0026gt;argv[c-\u0026gt;argc++] = createObject(OBJ_STRING, c-\u0026gt;querybuf); c-\u0026gt;argv_len_sum += c-\u0026gt;bulklen; sdsIncrLen(c-\u0026gt;querybuf, -2); /* 去除 CRLF */ /* 假设如果我们看到一个大的参数，接下来可能会看到另一个类似的 */ c-\u0026gt;querybuf = sdsnewlen(SDS_NOINIT, c-\u0026gt;bulklen + 2); sdsclear(c-\u0026gt;querybuf); } else { c-\u0026gt;argv[c-\u0026gt;argc++] = createStringObject(c-\u0026gt;querybuf + c-\u0026gt;qb_pos, c-\u0026gt;bulklen); c-\u0026gt;argv_len_sum += c-\u0026gt;bulklen; c-\u0026gt;qb_pos += c-\u0026gt;bulklen + 2; } c-\u0026gt;bulklen = -1; c-\u0026gt;multibulklen--; } } /* 当 c-\u0026gt;multibulklen 为 0 时，表示命令处理完成 */ if (c-\u0026gt;multibulklen == 0) return C_OK; /* 仍然没有准备好处理命令 */ return C_ERR; } processCommand处理命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 /* 这个函数调用 processCommand()，同时执行一些对于客户端来说有用的额外任务： * * 1. 将当前客户端设置为 \u0026#39;c\u0026#39;。 * 2. 如果命令已处理，则调用 commandProcessed()。 * * 如果处理命令过程中客户端被释放，则返回 C_ERR，否则返回 C_OK。 */ int processCommandAndResetClient(client *c) { int deadclient = 0; client *old_client = server.current_client; // 设置当前处理的客户端为 \u0026#39;c\u0026#39; server.current_client = c; // 处理命令 if (processCommand(c) == C_OK) { // 如果命令成功处理，调用 commandProcessed() commandProcessed(c); // 更新客户端的内存使用情况，考虑到命令执行后可能导致输出缓冲区的增长 if (c-\u0026gt;conn) updateClientMemUsageAndBucket(c); } // 检查当前客户端是否为空，如果为空表示客户端已经被释放 if (server.current_client == NULL) deadclient = 1; /* * 恢复之前的客户端设置。这个恢复是必要的，因为在脚本超时的情况下， * 我们会从 processEventsWhileBlocked 中进入该代码，这会导致设置 server.current_client。 * 如果不恢复，可能会错误地返回 1，表示客户端已经死掉，并停止从客户端缓冲区读取数据。 */ server.current_client = old_client; // performEvictions 可能会刷新从节点的输出缓冲区，这可能导致 // 从节点（可能是当前活动的客户端）被释放。 return deadclient ? C_ERR : C_OK; } 返回写入的resp给client：initServer -\u0026gt; aeSetBeforeSleepProc -\u0026gt; beforeSleep -\u0026gt; handleClientsWithPendingWritesUsingThreads -\u0026gt; sendReplyToClient 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 /* 将数据写入客户端的输出缓冲区。如果客户端在调用后仍然有效，返回 C_OK， * 如果因错误而被释放，返回 C_ERR。如果设置了 handler_installed，则会尝试清除写事件。 * * 该函数由线程调用，但总是将 handler_installed 设置为 0。因此，当 handler_installed 设置为 0 时， * 该函数必须是线程安全的。*/ int writeToClient(client *c, int handler_installed) { /* 更新服务器的总写入次数 */ atomicIncr(server.stat_total_writes_processed, 1); ssize_t nwritten = 0, totwritten = 0; /* 循环写入客户端的待处理回复 */ while(clientHasPendingReplies(c)) { int ret = _writeToClient(c, \u0026amp;nwritten); if (ret == C_ERR) break; totwritten += nwritten; /* 注意：我们避免一次写入超过 NET_MAX_WRITES_PER_EVENT 字节。 * 在单线程服务器中，即使来自超高速链接的大请求总是能接受数据， * 也应该服务其他客户端（在实际场景中可以考虑 \u0026#39;KEYS *\u0026#39; 命令通过回环接口）。 * * 然而，如果超出了最大内存限制，我们会忽略此限制，尽可能地发送数据。 * * 此外，如果客户端是从节点或监视器，我们会尽可能多地发送数据， * 否则，在高速流量下，复制/输出缓冲区可能会无限增长。*/ if (totwritten \u0026gt; NET_MAX_WRITES_PER_EVENT \u0026amp;\u0026amp; (server.maxmemory == 0 || zmalloc_used_memory() \u0026lt; server.maxmemory) \u0026amp;\u0026amp; !(c-\u0026gt;flags \u0026amp; CLIENT_SLAVE)) break; } /* 更新统计信息，记录已经发送的字节数 */ if (unlikely(clientTypeIsSlave(c))) { atomicIncr(server.stat_net_repl_output_bytes, totwritten); } else { atomicIncr(server.stat_net_output_bytes, totwritten); } /* 检查写入是否成功 */ if (nwritten == -1) { if (connGetState(c-\u0026gt;conn) != CONN_STATE_CONNECTED) { serverLog(LL_VERBOSE, \u0026#34;Error writing to client: %s\u0026#34;, connGetLastError(c-\u0026gt;conn)); freeClientAsync(c); return C_ERR; } } /* 如果有数据写入，更新客户端的最后交互时间 */ if (totwritten \u0026gt; 0) { /* 对于表示主节点的客户端，不计算发送数据作为一次交互， * 因为我们总是发送 REPLCONF ACK 命令，这些命令只占用一些时间来填充套接字输出缓冲区。 * 我们仅依赖接收到的数据或 ping 命令来检测超时。 */ if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER)) c-\u0026gt;lastinteraction = server.unixtime; } /* 如果客户端没有待处理的回复 */ if (!clientHasPendingReplies(c)) { c-\u0026gt;sentlen = 0; /* 请注意，writeToClient() 是在线程中调用的，但 aeDeleteFileEvent() 不是线程安全的： * 然而，由于 writeToClient() 总是在线程中将 handler_installed 设置为 0， * 所以我们可以放心。*/ if (handler_installed) { serverAssert(io_threads_op == IO_THREADS_OP_IDLE); connSetWriteHandler(c-\u0026gt;conn, NULL); } /* 在发送完整回复后关闭连接。 */ if (c-\u0026gt;flags \u0026amp; CLIENT_CLOSE_AFTER_REPLY) { freeClientAsync(c); return C_ERR; } } /* 在写入数据后更新客户端的内存使用情况。 * 由于这不是线程安全的，所以我们会有条件地执行此操作。 * 如果是多线程写入，则将在 handleClientsWithPendingWritesUsingThreads() 中处理。*/ if (io_threads_op == IO_THREADS_OP_IDLE) updateClientMemUsageAndBucket(c); return C_OK; } 内核函数分析 doc：https://man7.org/linux/man-pages/man7/epoll.7.html\nepoll_create int epoll_create(int size);\n参数介绍 size：这个参数是建议值，用于指定内部事件数组的大小。实际应用中，这个值一般可以传入一个合适的值，epoll 内部会根据操作系统的能力来分配内存。此参数已经在 Linux 2.6.8 中被废弃，并且没有实际意义，但为了兼容，依然存在。\n返回值 fd文件描述符id。\nepoll_ctl int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);\n参数介绍 epfd：通过 epoll_create 创建的 epoll 文件描述符。\nop：操作类型，EPOLL_CTL_ADD、EPOLL_CTL_MOD 和 EPOLL_CTL_DEL 分别表示添加、修改和删除文件描述符的操作。\nfd：要监控的文件描述符。\nevent：指定需要监控的事件，类型为 struct epoll_event，它定义了感兴趣的事件类型（如 EPOLLIN、EPOLLOUT、EPOLLRDHUP 等）以及一个用户自定义数据字段。\n返回值 0：成功\n-1：失败\nepoll_wait int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);\n参数介绍 epfd：通过 epoll_create 创建的 epoll 文件描述符。\nevents：一个数组，用于存放返回的事件。\nmaxevents：指定返回的最大事件数。如果有更多的事件发生，则需要调用多次 epoll_wait。\ntimeout：等待时间（毫秒）。如果设置为 -1，则会无限期阻塞，直到有事件发生。如果设置为 0，则立刻返回，不会阻塞。\n返回值 0：成功\n-1：失败\n边缘触发 \u0026amp; 水平触发 边缘触发et：状态发生变更才通知 水平触发lt：可读/写则通知 特性 水平触发（LT） 边缘触发（ET） 事件通知 一旦满足条件就会持续通知，直到事件被处理完 只在状态变化时通知一次，后续不再通知，直到状态再次变化 事件类型 当文件描述符的状态符合条件时（例如，有数据可读），会持续触发事件，直到条件被处理 只会在文件描述符的状态从“未就绪”变为“就绪”时触发一次事件 处理要求 处理一次事件后，可能会有更多的事件继续被通知 处理完事件后，必须尽可能多地处理数据，否则会错过后续事件 适用场景 适合简单场景，容易处理 适合高并发和高性能要求的场景，减少事件通知的次数 控制 由epoll_ctl注册的event.events控制，event：指定需要监控的事件，类型为 struct epoll_event，它定义了感兴趣的事件类型（如 EPOLLIN、EPOLLOUT、EPOLLRDHUP 等）以及一个用户自定义数据字段。\n当传入事件类型EPOLLET时，该fd为边缘触发。\n默认情况为水平触发。\n对于redis而言，使用的均为水平触发 nginx中存在边缘触发的使用 epoll_wait如何实现等待 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 static int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, struct timespec64 *timeout) { int res, eavail, timed_out = 0; u64 slack = 0; wait_queue_entry_t wait; ktime_t expires, *to = NULL; lockdep_assert_irqs_enabled(); // 如果有超时时间，并且不为零，则转换超时时间为ktime格式 if (timeout \u0026amp;\u0026amp; (timeout-\u0026gt;tv_sec | timeout-\u0026gt;tv_nsec)) { slack = select_estimate_accuracy(timeout); to = \u0026amp;expires; *to = timespec64_to_ktime(*timeout); } else if (timeout) { // 如果超时时间为零，表示非阻塞操作 timed_out = 1; } // 检查是否有可用的事件 eavail = ep_events_available(ep); while (1) { // 如果有事件，则将事件发送到用户空间 if (eavail) { res = ep_send_events(ep, events, maxevents); if (res) { // 如果发送成功，挂起 NAPI 中断 if (res \u0026gt; 0) ep_suspend_napi_irqs(ep); return res; } } // 如果超时标志为真，直接返回 if (timed_out) return 0; // 如果没有事件，执行忙等待 eavail = ep_busy_loop(ep, timed_out); if (eavail) continue; // 检查是否有信号中断 if (signal_pending(current)) return -EINTR; // 初始化等待队列 init_wait(\u0026amp;wait); wait.func = ep_autoremove_wake_function; // 加锁，检查事件是否可用 write_lock_irq(\u0026amp;ep-\u0026gt;lock); __set_current_state(TASK_INTERRUPTIBLE); // 再次检查是否有可用事件 eavail = ep_events_available(ep); if (!eavail) // 如果没有事件，加入到等待队列 __add_wait_queue_exclusive(\u0026amp;ep-\u0026gt;wq, \u0026amp;wait); write_unlock_irq(\u0026amp;ep-\u0026gt;lock); // 如果没有事件，调用高精度定时器进行等待 if (!eavail) timed_out = !schedule_hrtimeout_range(to, slack, HRTIMER_MODE_ABS); // 设置当前任务为运行状态 __set_current_state(TASK_RUNNING); // 被唤醒后检查是否有事件 eavail = 1; // 如果等待队列不为空，移除当前等待条目 if (!list_empty_careful(\u0026amp;wait.entry)) { write_lock_irq(\u0026amp;ep-\u0026gt;lock); if (timed_out) // 如果超时，则再次检查等待队列是否为空 eavail = list_empty(\u0026amp;wait.entry); // 从等待队列中移除当前条目 __remove_wait_queue(\u0026amp;ep-\u0026gt;wq, \u0026amp;wait); write_unlock_irq(\u0026amp;ep-\u0026gt;lock); } } } 总结 阻塞实现：当没有事件发生且超时条件为 -1 时，ep_poll 会通过将当前进程加入到等待队列中来实现阻塞，直到事件发生或者超时。\n忙等待的作用：忙等待是在没有事件的情况下不断轮询检查事件队列，如果有事件，则立即处理。如果没有事件，则避免过早地阻塞。\n等待队列的加入：在忙等待检查之后，ep_poll 会在确认没有事件且没有超时时，将进程加入等待队列。等待队列保证了进程可以被挂起，直到有事件发生或者超时。\n一直没有事件发生的例子 没有事件的情况下，eavail 会持续为 0。\nep_events_available，返回0，当 eavail == 0 时，代码会先进入忙等待阶段，并尝试重新检查是否有事件。 避免直接进入阻塞，提高执行效率（类似jvm中先轻量级cas锁，满足一定条件后再升级为依赖os的重锁） 如果经过忙等待仍然没有事件，ep_busy_loop返回0，此时 eavail == 0 ，epoll 会进入等待队列并阻塞当前线程，直到事件发生。 当进程被唤醒后，eavail 被强制设置为 1，表示进入下一轮事件的处理。 ","date":"2024-11-21T01:23:56+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BD-reids-%E9%80%9A%E4%BF%A1/","title":"高性能 reids-通信"},{"content":"redis高性能 - 数据结构 五种基本数据结构（源码struct） string - sds 1 2 3 4 5 6 struct __attribute__ ((__packed__)) sdshdr64/* 32/16/8 */ { uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; 普通C字符串（char*，char[]，cstring）：定长，效率低，不安全\n容量写死 常用api没有，例如计算字符串长度的基本需求，需要o(n)去遍历计算 \u0026lsquo;/0\u0026rsquo;作为cstring的终止符，遇到则标记字符串结束 sds：动态扩展，效率高，二进制安全（兼容\u0026rsquo;/0\u0026rsquo;）\n动态分配，包括预分配 \u0026amp; 惰性释放机制 对sds扩展时，例如concat连接新内容，此时若当前容量不够，则会自动申请新的空间用于存储 扩展后len \u0026lt; 1MB: 等长扩展 扩展后len \u0026gt; 1MB: 扩展1MB -\u0026gt; 避免指数增长（类似TCP协议中的快速恢复，先指数增长，到达阈值后线性增长） 实现一些常用的高效api，例如结构体中使用一个int8/16/32/64的整型数字即可记录字符串长度，调用时直接o(1)返回即可 sds的buf[]数组可以存\u0026rsquo;/0\u0026rsquo;而不被打断 list - linklist/ziplist 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 typedef struct listNode { struct listNode *prev; struct listNode *next; void *value; } listNode; typedef struct listIter { listNode *next; int direction; } listIter; typedef struct list { listNode *head; listNode *tail; void *(*dup)(void *ptr); void (*free)(void *ptr); int (*match)(void *ptr, void *key); unsigned long len; } list; 常见的双向链表实现，因此在api层，还可以把该结构当作\nstack栈：先入后出 queue队列：先入先出 set - dict/intset dict这里不解释，后续hash结构中介绍，了解到的几乎所有常见编程语言内置库中的set结构也基本是这样实现，dict的value为空即是一个key set。\n1 2 3 4 5 typedef struct intset { uint32_t encoding; uint32_t length; int8_t contents[]; } intset; 在仅存整型数字集合时，使用intset结构优化内存使用。\n由encoding属性决定数组格式 内部实际内容保存使用int8数组，int64 -\u0026gt; int8[8] 添加新元素时： 根据新元素类型分配内存空间 原数组元素转为最高级别类型，并维持有序性 zset - skiplist \u0026amp; dict 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /* ZSETs use a specialized version of Skiplists */ typedef struct zskiplistNode { sds ele; double score; struct zskiplistNode *backward; struct zskiplistLevel { struct zskiplistNode *forward; unsigned long span; } level[]; } zskiplistNode; typedef struct zskiplist { struct zskiplistNode *header, *tail; unsigned long length; int level; } zskiplist; typedef struct zset { dict *dict; zskiplist *zsl; } zset; 特征\n高效排序：通过跳表可以高效地进行元素排序，操作的时间复杂度为 O(log N) 支持范围查询：可以快速地根据分数范围进行查询，并返回有序的数据 空间效率：Redis 通过字典和跳表的组合，保证了 ZSET 在高效存储数据的同时，还能提供高效的查询和插入操作 hash - dict/ziplist 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 struct dictEntry { void *key; union { void *val; uint64_t u64; int64_t s64; double d; } v; struct dictEntry *next; /* Next entry in the same hash bucket. */ }; typedef struct { void *key; dictEntry *next; } dictEntryNoValue; struct dict { dictType *type; dictEntry **ht_table[2]; unsigned long ht_used[2]; long rehashidx; /* rehashing not in progress if rehashidx == -1 */ /* Keep small vars at end for optimal (minimal) struct padding */ unsigned pauserehash : 15; /* If \u0026gt;0 rehashing is paused */ unsigned useStoredKeyApi : 1; /* See comment of storedHashFunction above */ signed char ht_size_exp[2]; /* exponent of size. (size = 1\u0026lt;\u0026lt;exp) */ int16_t pauseAutoResize; /* If \u0026gt;0 automatic resizing is disallowed (\u0026lt;0 indicates coding error) */ void *metadata[]; }; /* If safe is set to 1 this is a safe iterator, that means, you can call * dictAdd, dictFind, and other functions against the dictionary even while * iterating. Otherwise it is a non safe iterator, and only dictNext() * should be called while iterating. */ typedef struct dictIterator { dict *d; long index; int table, safe; dictEntry *entry, *nextEntry; /* unsafe iterator fingerprint for misuse detection. */ unsigned long long fingerprint; } dictIterator; typedef struct dictStats { int htidx; unsigned long buckets; unsigned long maxChainLen; unsigned long totalChainLen; unsigned long htSize; unsigned long htUsed; unsigned long *clvector; } dictStats; 使用MurmurHash2算法计算key的hash值 拉链法处理hash冲突 渐进式hash处理扩展收缩：避免在 rehash 时造成长时间的阻塞（空间换时间） 同时维护两个hash_table，初始时，ht[0] 存储所有的键值对，而 ht[1] 为空 字典中设定rehashidx=0，开始扩/缩容 对字典中的每一次操作（包含get/set/del等操作），将ht[0]在rehashidx上的所有k-v对rehash至ht[1]，完成rehash后rehashidx+1 当ht[0]所有k-v对rehash完成后，rehashidx置为-1 ziplist - 压缩列表，非独立对外服务结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 /* Each entry in the ziplist is either a string or an integer. */ typedef struct { /* When string is used, it is provided with the length (slen). */ unsigned char *sval; unsigned int slen; /* When integer is used, \u0026#39;sval\u0026#39; is NULL, and lval holds the value. */ long long lval; } ziplistEntry; typedef struct zlentry { unsigned int prevrawlensize; /* Bytes used to encode the previous entry len*/ unsigned int prevrawlen; /* Previous entry len. */ unsigned int lensize; /* Bytes used to encode this entry type/len. For example strings have a 1, 2 or 5 bytes header. Integers always use a single byte.*/ unsigned int len; /* Bytes used to represent the actual entry. For strings this is just the string length while for integers it is 1, 2, 3, 4, 8 or 0 (for 4 bit immediate) depending on the number range. */ unsigned int headersize; /* prevrawlensize + lensize. */ unsigned char encoding; /* Set to ZIP_STR_* or ZIP_INT_* depending on the entry encoding. However for 4 bits immediate integers this can assume a range of values and must be range-checked. */ unsigned char *p; /* Pointer to the very start of the entry, that is, this points to prev-entry-len field. */ } zlentry; // 4字节：zlbytes使用字节数总量 + 4字节：zltail偏移量 + 2字节：zllen列表元素数量（长度） #define ZIPLIST_HEADER_SIZE (sizeof(uint32_t)*2+sizeof(uint16_t)) // 1字节：标记末端 #define ZIPLIST_END_SIZE (sizeof(uint8_t)) /* Create a new empty ziplist. */ unsigned char *ziplistNew(void) { unsigned int bytes = ZIPLIST_HEADER_SIZE+ZIPLIST_END_SIZE; unsigned char *zl = zmalloc(bytes); ZIPLIST_BYTES(zl) = intrev32ifbe(bytes); ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(ZIPLIST_HEADER_SIZE); ZIPLIST_LENGTH(zl) = 0; zl[bytes-1] = ZIP_END; return zl; } /** 标准结构（from源码注释）： * [0f 00 00 00] [0c 00 00 00] [02 00] [00 f3] [02 f6] [ff] * | | | | | | * zlbytes zltail zllen \u0026#34;2\u0026#34; \u0026#34;5\u0026#34; end */ ziplist在内存中是一段连续内容，在小容量时可以节约通过指针访问的寻址时间 通过自定义压缩结构，时间换空间，节约内存，减少内存的碎片化 因此，这是一个相对小众的redis优化结构 hash-max-ziplist-entries：压缩链表最大元素数量 hash-max-ziplist-value：压缩链表最大元素空间 当list/hash结构超过配置的阈值时，会转用标准实现存储 使用场景分析（个人向） 分布式锁，session信息，或者其他简单对象存储，此时使用string即可 同步一些结构化的数据，例如同步db中的某些热点表数据，此时可以使用hash结构 hset table_name index_key table_row_info 排序向需求，例如推荐系统中排序、排名功能，基于分数的推荐算法，此时可以使用zset结构 ZREVRANGE commandation_item_rank 0 5 WITHSCORES 队列queue/栈stack的使用，此时可以通过list进行模拟 lpush queue x + rpop queue：x先入先出 lpush stack x + lpop stack：x先入后出 ","date":"2024-10-25T01:23:56+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BD-reids-%E5%86%85%E5%AD%98%E6%95%88%E7%8E%87/","title":"高性能 reids-内存效率"},{"content":"redis高可用集群 sentinel（主从）集群 cluster（分布式）集群 主从集群 slaveof host指令：将当前redis服务实例置为指定host的从节点。\nslave节点发送sync请求至host主节点（master） master节点触发bgsave操作，将当前db数据全量更新至rdb二进制备份文件中 master节点完成rdb全量备份后，将其发送至slave节点 后续的增量写操作master会通过psync指令主动推送至slave节点 slave节点进行rdb数据加载 增量的psync数据主要通过slave节点的offset偏移量进行对比，有offset时仅同步增量数据 sentinel集群 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 typedef struct sentinelRedisInstance { int flags; /* 参见 SRI_... 定义 */ char *name; /* 当前 Sentinel 视角下的主节点名称 */ char *runid; /* 当前实例的运行ID，如果是 Sentinel 则为其唯一 ID */ uint64_t config_epoch; /* 配置纪元 */ sentinelAddr *addr; /* 主节点的地址 */ instanceLink *link; /* 与实例的连接，可能被多个 Sentinel 共享 */ mstime_t last_pub_time; /* 上次通过 Pub/Sub 发送 Hello 消息的时间 */ mstime_t last_hello_time; /* 仅当 SRI_SENTINEL 设置时有效，表示上次通过 Pub/Sub 收到 Hello 消息的时间 */ mstime_t last_master_down_reply_time; /* 上次回复 SENTINEL is-master-down 命令的时间 */ mstime_t s_down_since_time; /* 视为下线的时间（主观下线） */ mstime_t o_down_since_time; /* 视为下线的时间（客观下线） */ mstime_t down_after_period; /* 在此时间段后认为该节点下线 */ mstime_t master_reboot_down_after_period; /* 在此时间段后认为主节点重新启动后下线 */ mstime_t master_reboot_since_time; /* 主节点重启时间 */ mstime_t info_refresh; /* 上次接收到 INFO 输出的时间 */ dict *renamed_commands; /* 此实例中重命名的命令：Sentinel 将使用此表中的替代命令来执行操作，如 SLAVEOF、CONFIG、INFO 等 */ /* 节点角色及其首次观察时间。用于延迟替换实例报告的角色，避免在主节点报告新配置之前进行不必要的操作 */ int role_reported; mstime_t role_reported_time; mstime_t slave_conf_change_time; /* 上次从节点的主地址变化时间 */ /* 主节点特定字段 */ dict *sentinels; /* 监控相同主节点的其他 Sentinel */ dict *slaves; /* 当前主节点的从节点 */ unsigned int quorum;/* 需要多少个 Sentinel 达成共识才能认为主节点失败 */ int parallel_syncs; /* 同时重新配置的从节点数 */ /* 从节点特定字段 */ mstime_t master_link_down_time; /* 从节点与主节点的复制链路断开时间 */ int slave_priority; /* 从节点的优先级（由其 INFO 输出提供） */ int replica_announced; /* 从节点的状态是否已通过 INFO 输出进行公告 */ mstime_t slave_reconf_sent_time; /* 上次发送 SLAVE OF \u0026lt;new\u0026gt; 命令的时间 */ struct sentinelRedisInstance *master; /* 如果是从节点，指向主节点实例 */ char *slave_master_host; /* 从节点报告的主节点主机 */ int slave_master_port; /* 从节点报告的主节点端口 */ int slave_master_link_status; /* 从节点报告的主节点链路状态 */ unsigned long long slave_repl_offset; /* 从节点的复制偏移量 */ /* 故障转移相关 */ char *leader; /* 如果是主节点，该字段是应该执行故障转移的 Sentinel 的 runid。如果是 Sentinel，则是此 Sentinel 选举的领导者的 runid */ uint64_t leader_epoch; /* 领导者字段的纪元 */ uint64_t failover_epoch; /* 当前故障转移的纪元 */ int failover_state; /* 参见 SENTINEL_FAILOVER_STATE_* 定义 */ mstime_t failover_state_change_time; /* 故障转移状态变化的时间 */ mstime_t failover_start_time; /* 上次故障转移尝试开始的时间 */ mstime_t failover_timeout; /* 刷新故障转移状态的最大时间 */ mstime_t failover_delay_logged; /* 记录的故障转移开始时间 */ struct sentinelRedisInstance *promoted_slave; /* 被提升为主节点的从节点实例 */ sds info; /* 缓存的 INFO 输出 */ } sentinelRedisInstance; struct sentinelState { char myid[CONFIG_RUN_ID_SIZE+1]; /* 此 Sentinel 的 ID */ uint64_t current_epoch; /* 当前纪元 */ dict *masters; /* 监控的主节点字典。键是实例名称，值是 sentinelRedisInstance 结构体的指针 */ int tilt; /* 当前是否处于 TILT 模式？ */ int running_scripts; /* 当前正在执行的脚本数量 */ mstime_t tilt_start_time; /* TILT 模式开始的时间 */ mstime_t previous_time; /* 上次运行时间处理的时间 */ list *scripts_queue; /* 用户脚本的执行队列 */ char *announce_ip; /* 如果非 NULL，向其他 Sentinel 通告的 IP 地址 */ int announce_port; /* 如果非零，向其他 Sentinel 通告的端口 */ unsigned long simfailure_flags; /* 模拟故障标志 */ int resolve_hostnames; /* 是否支持使用主机名，假设 DNS 已正确配置 */ int announce_hostnames; /* 是否使用主机名而非 IP 地址通告给其他 Sentinel */ } sentinel; sentinel配置 Redis Sentinel 是一个独立的进程，通常和 Redis 实例在不同的机器上运行。我们需要至少三个 Sentinel 节点来保证集群的稳定性和故障转移功能。假设我们在以下机器上启动 Sentinel：\nRedis 主节点：192.168.1.10:6379\nRedis 从节点 1：192.168.1.11:6379\nRedis 从节点 2：192.168.1.12:6379\nSentinel 1：192.168.1.20:26379\nSentinel 2：192.168.1.21:26379\nSentinel 3：192.168.1.22:26379\n新建sentinel.conf\n1 2 3 4 5 6 7 8 9 10 port 26379 daemonize yes # 配置监控的主节点 sentinel monitor master 192.168.1.10 6379 2 # 配置故障转移的参数 sentinel down-after-milliseconds master 5000 sentinel parallel-syncs master 1 sentinel failover-timeout master 60000 1 redis-server /path/to/sentinel.conf --sentinel 分布式集群 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 struct _clusterNode { mstime_t ctime; /* 节点对象的创建时间。 */ char name[CLUSTER_NAMELEN]; /* 节点名称，十六进制字符串，大小为 sha1 的长度。 */ char shard_id[CLUSTER_NAMELEN]; /* 分片ID，十六进制字符串，大小为 sha1 的长度。 */ int flags; /* 节点的标志，可能是 CLUSTER_NODE_... */ uint64_t configEpoch; /* 节点最后观察到的配置纪元（configEpoch）。 */ unsigned char slots[CLUSTER_SLOTS / 8]; /* 当前节点负责的槽位。 */ uint16_t *slot_info_pairs; /* 以 (start/end) 对的形式表示的槽位信息（连续的槽位索引）。 */ int slot_info_pairs_count; /* slot_info_pairs 中已使用的槽位数量。 */ int numslots; /* 当前节点负责的槽位数量。 */ int numslaves; /* 如果该节点是主节点，则为其从节点的数量。 */ clusterNode **slaves; /* 当前节点的从节点指针数组。 */ clusterNode *slaveof; /* 指向主节点的指针。如果当前节点是从节点但没有在表中找到主节点，可能为 NULL。 */ unsigned long long last_in_ping_gossip; /* 上次通过 PING 消息中传播的 gossip 编号。 */ mstime_t ping_sent; /* 最近一次发送 PING 消息的时间。 */ mstime_t pong_received; /* 最近一次收到 PONG 响应的时间。 */ mstime_t data_received; /* 最近一次收到数据的时间。 */ mstime_t fail_time; /* 节点状态被设置为 FAIL 的时间。 */ mstime_t voted_time; /* 最近一次为当前主节点的某个从节点投票的时间。 */ mstime_t repl_offset_time; /* 接收到当前节点的复制偏移量的时间。 */ mstime_t orphaned_time; /* 节点变为孤立主节点的起始时间。 */ long long repl_offset; /* 当前节点的最后已知复制偏移量。 */ char ip[NET_IP_STR_LEN]; /* 当前节点的最新已知 IP 地址。 */ sds hostname; /* 当前节点的已知主机名。 */ sds human_nodename; /* 当前节点的可读主机名（人类可读）。 */ int tcp_port; /* 当前节点的客户端 TCP 端口。 */ int tls_port; /* 当前节点的客户端 TLS 端口。 */ int cport; /* 当前节点的集群通信端口。 */ clusterLink *link; /* 当前节点到其他节点的 TCP/IP 链接。 */ clusterLink *inbound_link; /* 当前节点从其他节点接受的 TCP/IP 链接。 */ list *fail_reports; /* 报告当前节点为故障节点的其他节点列表。 */ }; struct clusterState { clusterNode *myself; /* 当前节点的指针。 */ uint64_t currentEpoch; /* 当前集群的纪元（epoch）。 */ int state; /* 当前集群的状态，如 CLUSTER_OK, CLUSTER_FAIL 等。 */ int size; /* 至少拥有一个槽位的主节点数量。 */ dict *nodes; /* 节点名称到 clusterNode 结构体的哈希表。 */ dict *shards; /* 分片ID到节点列表的哈希表。 */ dict *nodes_black_list; /* 临时不重新添加的节点黑名单。 */ clusterNode *migrating_slots_to[CLUSTER_SLOTS]; /* 正在迁移的槽位的目标节点。 */ clusterNode *importing_slots_from[CLUSTER_SLOTS]; /* 正在导入的槽位的源节点。 */ clusterNode *slots[CLUSTER_SLOTS]; /* 集群槽位到节点的映射。 */ /* 以下字段用于从节点参与选举时的状态管理。 */ mstime_t failover_auth_time; /* 上一次或下一次选举的时间。 */ int failover_auth_count; /* 当前已收到的选票数量。 */ int failover_auth_sent; /* 是否已经请求过选票。 */ int failover_auth_rank; /* 当前从节点在选举中的排名。 */ uint64_t failover_auth_epoch; /* 当前选举的纪元。 */ int cant_failover_reason; /* 当前从节点无法进行故障转移的原因。见 CANT_FAILOVER_* 宏。 */ /* 手动故障转移状态： */ mstime_t mf_end; /* 手动故障转移的时间限制（毫秒时间戳），如果没有正在进行的故障转移则为零。 */ /* 主节点的手动故障转移状态。 */ clusterNode *mf_slave; /* 执行手动故障转移的从节点。 */ /* 从节点的手动故障转移状态。 */ long long mf_master_offset; /* 从节点需要的主节点偏移量，-1 表示尚未接收到偏移量。 */ int mf_can_start; /* 如果非零，表示可以开始请求主节点投票。 */ /* 以下字段用于主节点参与选举时的状态管理。 */ uint64_t lastVoteEpoch; /* 上一次投票授权的纪元。 */ int todo_before_sleep; /* 在集群进入休眠前需要执行的操作。 */ /* 统计信息 */ /* 按类型统计的消息发送和接收数量。 */ long long stats_bus_messages_sent[CLUSTERMSG_TYPE_COUNT]; long long stats_bus_messages_received[CLUSTERMSG_TYPE_COUNT]; long long stats_pfail_nodes; /* PFAIL 状态下的节点数量（不包括没有地址的节点）。 */ unsigned long long stat_cluster_links_buffer_limit_exceeded; /* 由于超过缓冲区限制而释放的集群链接总数。 */ /* 在槽位迁移期间，节点停止声明拥有某个槽位时，通过 PING 消息传播的槽位所有权状态。 */ unsigned char owner_not_claiming_slot[CLUSTER_SLOTS / 8]; }; cluster配置 修改原有的redis.conf配置，开启集群模式\n1 cluster-enabled yes 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ## 根据192.168.1.10 ~ 192.168.1.15六台redis服务实例，创建一个1副本的集群 redis-cli --cluster create 192.168.1.10:6379 192.168.1.11:6379 192.168.1.12:6379 192.168.1.13:6379 192.168.1.14:6379 192.168.1.15:6379 --cluster-replicas 1 ## 检查集群状态 redis-cli -h 192.168.1.10 -p 6379 cluster info ## 集群扩缩容 redis-cli --cluster add-node 192.168.1.16:6379 192.168.1.10:6379 redis-cli --cluster del-node 192.168.1.16:6379 192.168.1.10:6379 ## rehash重新分配hash槽 redis-cli --cluster reshard 192.168.1.10:6379 ## 系统会提示你按以下步骤进行： ## 选择迁移的槽的数量 ## 选择要迁移的源节点 ## 选择目标节点 gossip分布式传播算法 主要用于AP模式的分布式集群 节点之间会定期发送 PING 请求，以检查彼此的健康状况。如果某个节点未能在指定时间内回复 PONG，它将被标记为“故障”节点（此时仅标记，不进入故障流程） 超过半数以上的主观下线 -\u0026gt; 客观下线，进入节点故障流程 选主流程 主节点故障后的选举过程 当 Redis 集群的主节点（Master）发生故障时，集群通过以下步骤来选举新的主节点：\n1. 故障检测 Redis 集群中的每个节点定期通过 Gossip 协议（基于 PING/PONG 消息）来相互检查对方的状态。如果一个节点长时间未响应其他节点的心跳消息，或者无法访问该节点时，该节点会被标记为故障节点。 节点之间也会通过 fail reports（失败报告）来相互通知某个节点的失败状态。如果一个节点在多次心跳中没有响应，它会被标记为 PFAIL（可能失败）状态。这个状态会传播给其他节点。 2. 节点故障确认 当集群中的一个主节点失败时，其他节点会观察到该节点长时间没有响应，且处于 PFAIL 状态。 一旦故障被确认，集群中的其他节点会开始启动故障转移（failover）流程，选举新的主节点。 3. 选举新的主节点 故障转移的选举过程是通过 从节点投票 来完成的。每个主节点都有一个或多个从节点，这些从节点可以参与选举过程。 如果主节点故障，集群会尝试从它的从节点中选举出一个新的主节点。选举的步骤如下： 候选条件：从节点需要满足以下条件才能被选为新的主节点： 从节点必须是主节点的有效复制副本，且与主节点的数据同步。 从节点的复制偏移量必须接近主节点的最后复制偏移量，确保数据不会丢失太多。 从节点的 configEpoch 和其他选举相关的条件（如 voted_time）也会被检查。 投票：所有与故障主节点关联的从节点都会进行投票，选择一个从节点成为新的主节点。投票的依据通常是复制偏移量、节点的健康状态以及当前选举的纪元（configEpoch）等。 选举成功：一旦一个从节点收到了多数节点的投票，它会被提升为新的主节点。这个过程会被广播到整个集群，并更新节点状态。新选举出来的主节点会开始负责处理它原来从主节点负责的槽位。 ","date":"2024-10-20T01:23:56+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BD%E9%AB%98%E5%8F%AF%E7%94%A8-reids-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/","title":"高性能\u0026高可用 reids-分布式集群"},{"content":"数学基础： 高等数学：导数、微分、偏导数（多元函数导数）\n线性代数：向量、行列式、矩阵的基本运算、秩\n高等数学 导数 \\[ f'(x_0) = \\frac{dy}{dx} = \\lim_{x \\to x_0} \\frac{f(x) - f(x_0)}{x - x_0} \\]极限 ε δ 语言： 函数 $f(x)$ 在点 $x_0$ 的某一去心邻域内有定义。如果存在常数 $a$，对于任意的 $\\epsilon \u0026gt; 0$，都存在 $\\delta \u0026gt; 0$，使得在 $0 \u0026lt; |x - x_0| \u0026lt; \\delta$ 时，不等式 $|f(x) - a| \u0026lt; \\epsilon$ 恒成立。那么常数 $a$ 就叫做函数 $f(x)$ 当 $x \\to x_0$ 时的极限，记作： $$ \\lim_{x \\to x_0} f(x) = a $$微分 函数变化量 = 变化率 * 参数变化量 $$ df(x) = f'(x) \\, dx $$偏导 对于一个多元函数 $f(x_1, x_2, \\ldots, x_n)$，它在点 $(x_1^0, x_2^0, \\ldots, x_n^0)$ 处的偏导数相对于 $x_i$ 是： $$ \\frac{\\partial f}{\\partial x_i} = \\lim_{h \\to 0} \\frac{f(x_1^0, \\ldots, x_i^0 + h, \\ldots, x_n^0) - f(x_1^0, \\ldots, x_i^0, \\ldots, x_n^0)}{h} $$偏导的链式法则 假设我们有两个函数 $u = g(x_1, x_2, \\ldots, x_n)$ 和 $y = f(u)$，其中 $u$ 是 $x_1, x_2, \\ldots, x_n$ 的函数，而 $y$ 是 $u$ 的函数。我们希望找到 $y$ 对 $x_i$ 的偏导数。\n链式法则的定义是：\n$$ \\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial u} \\cdot \\frac{\\partial u}{\\partial x_i} $$其中：\n$\\frac{\\partial y}{\\partial u}$ 是 $y$ 对 $u$ 的偏导数。 $\\frac{\\partial u}{\\partial x_i}$ 是 $u$ 对 $x_i$ 的偏导数。 证明 全微分关系为： $$ dz = \\frac{\\partial z}{\\partial u} \\, du + \\frac{\\partial z}{\\partial v} \\, dv $$由于 $u$ 和 $v$ 是 $x$ 和 $y$ 的函数，我们有： $$ du = \\frac{\\partial u}{\\partial x} \\, dx + \\frac{\\partial u}{\\partial y} \\, dy $$$$ dv = \\frac{\\partial v}{\\partial x} \\, dx + \\frac{\\partial v}{\\partial y} \\, dy $$将这些代入全微分公式中，得到： $$ dz = \\left( \\frac{\\partial z}{\\partial u} \\frac{\\partial u}{\\partial x} + \\frac{\\partial z}{\\partial v} \\frac{\\partial v}{\\partial x} \\right) dx + \\left( \\frac{\\partial z}{\\partial u} \\frac{\\partial u}{\\partial y} + \\frac{\\partial z}{\\partial v} \\frac{\\partial v}{\\partial y} \\right) dy $$链式法则的偏导数 根据全微分关系，链式法则的偏导数为： $$ \\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial u} \\frac{\\partial u}{\\partial x} + \\frac{\\partial z}{\\partial v} \\frac{\\partial v}{\\partial x} $$$$ \\frac{\\partial z}{\\partial y} = \\frac{\\partial z}{\\partial u} \\frac{\\partial u}{\\partial y} + \\frac{\\partial z}{\\partial v} \\frac{\\partial v}{\\partial y} $$线性代数 向量的定义 向量是一个具有大小和方向的量，通常在多维空间中表示为一个有序的数列。一个 $n$ 维向量可以写作：\n$$ \\mathbf{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix} $$行列式的定义 行列式是一个方阵的一个标量值，它可以用来描述矩阵的某些性质，比如可逆性。对于一个 $n \\times n$ 的方阵 $A$，行列式记作 $\\det(A)$ 或 $|A|$，可以表示为：\n对于 $2 \\times 2$ 矩阵：\n$$ \\det \\begin{pmatrix} a \u0026 b \\\\ c \u0026 d \\end{pmatrix} = ad - bc $$对于 $3 \\times 3$ 矩阵：\n$$ \\det \\begin{pmatrix} a \u0026 b \u0026 c \\\\ d \u0026 e \u0026 f \\\\ g \u0026 h \u0026 i \\end{pmatrix} = aei + bfg + cdh - ceg - bdi - afh $$矩阵的定义 矩阵是一个按照矩形阵列排列的数值集合。一个 $m \\times n$ 的矩阵可以表示为：\n$$ A = \\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n} \\\\ a_{21} \u0026 a_{22} \u0026 \\cdots \u0026 a_{2n} \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ a_{m1} \u0026 a_{m2} \u0026 \\cdots \u0026 a_{mn} \\end{bmatrix} $$矩阵的基本运算 1. 矩阵加法 两个同型矩阵 $A$ 和 $B$ 的加法是元素对应相加，得到的新矩阵为： 如果 $$ A = \\begin{bmatrix} a_{11} \u0026 a_{12} \\\\ a_{21} \u0026 a_{22} \\end{bmatrix} $$$$ B = \\begin{bmatrix} b_{11} \u0026 b_{12} \\\\ b_{21} \u0026 b_{22} \\end{bmatrix} $$ 那么 $$ A + B = \\begin{bmatrix} a_{11} + b_{11} \u0026 a_{12} + b_{12} \\\\ a_{21} + b_{21} \u0026 a_{22} + b_{22} \\end{bmatrix} $$2. 矩阵减法 两个同型矩阵 $A$ 和 $B$ 的减法是元素对应相减，得到的新矩阵为： $$ A - B = \\begin{bmatrix} a_{11} - b_{11} \u0026 a_{12} - b_{12} \\\\ a_{21} - b_{21} \u0026 a_{22} - b_{22} \\end{bmatrix} $$3. 矩阵数乘 矩阵 $A$ 与标量 $k$ 的数乘是矩阵中每个元素都乘以 $k$，得到的新矩阵为： 如果 $$ A = \\begin{bmatrix} a_{11} \u0026 a_{12} \\\\ a_{21} \u0026 a_{22} \\end{bmatrix} $$ 那么 $$ kA = \\begin{bmatrix} ka_{11} \u0026 ka_{12} \\\\ ka_{21} \u0026 ka_{22} \\end{bmatrix} $$4. 矩阵乘法 两个矩阵 $A$ 和 $B$ 的乘法是矩阵 $A$ 的行向量与矩阵 $B$ 的列向量的内积，得到的新矩阵 $C$ 为： 如果 $$ A = \\begin{bmatrix} a_{11} \u0026 a_{12} \\\\ a_{21} \u0026 a_{22} \\end{bmatrix} $$$$ B = \\begin{bmatrix} b_{11} \u0026 b_{12} \\\\ b_{21} \u0026 b_{22} \\end{bmatrix} $$ 那么 $$ C = AB = \\begin{bmatrix} a_{11}b_{11} + a_{12}b_{21} \u0026 a_{11}b_{12} + a_{12}b_{22} \\\\ a_{21}b_{11} + a_{22}b_{21} \u0026 a_{21}b_{12} + a_{22}b_{22} \\end{bmatrix} $$5. 矩阵转置 矩阵 $A$ 的转置是将矩阵 $A$ 的行和列互换得到的新矩阵 $A^T$： 如果 $$ A = \\begin{bmatrix} a_{11} \u0026 a_{12} \\\\ a_{21} \u0026 a_{22} \\end{bmatrix} $$ 那么 $$ A^T = \\begin{bmatrix} a_{11} \u0026 a_{21} \\\\ a_{12} \u0026 a_{22} \\end{bmatrix} $$6. 矩阵的逆 矩阵 $A$ 的逆矩阵 $A^{-1}$ 是使得 $AA^{-1} = A^{-1}A = I$ 的矩阵，其中 $I$ 是单位矩阵。对于 $2 \\times 2$ 矩阵 $A$，如果行列式 $\\det(A) \\neq 0$，其逆矩阵为： 如果 $$ A = \\begin{bmatrix} a \u0026 b \\\\ c \u0026 d \\end{bmatrix} $$ 那么 $$ A^{-1} = \\frac{1}{\\det(A)} \\begin{bmatrix} d \u0026 -b \\\\ -c \u0026 a \\end{bmatrix} $$ 其中行列式 $\\det(A)$ 为： $$ \\det(A) = ad - bc $$7. 矩阵的秩 矩阵的秩（rank）是矩阵中线性无关的行（或列）的最大数量。矩阵的秩可以用来判断矩阵的行或列的线性独立性。\n对于一个 $m \\times n$ 的矩阵 $A$，秩定义为：\n矩阵 $A$ 的行秩：矩阵 $A$ 的最大线性无关的行的数量。 矩阵 $A$ 的列秩：矩阵 $A$ 的最大线性无关的列的数量。 行秩和列秩总是相等，这个公共值称为矩阵的秩，记作 $\\text{rank}(A)$。\n举例 假设有一个矩阵 $A$：\n$$ A = \\begin{bmatrix} 1 \u0026 2 \u0026 3 \\\\ 4 \u0026 5 \u0026 6 \\\\ 7 \u0026 8 \u0026 9 \\end{bmatrix} $$矩阵 $A$ 的秩是 $2$，因为矩阵的行或列中最大数量的线性无关的行或列是 $2$。\n步骤 r2 = r2 - 4*r1\nr3 = r3 - 7*r1\nr2 = -1/3*r2\nr3 = r3 + 6*r2\n机器学习基本概念 ml类别 监督学习 有数据标注的机器学习\n分类问题 给出X样本，以及样本中每一行对应的标注结果集Y\n根据样本特征，预测新样本的结果\n回归问题 给出X样本，以及样本中每一行对应的标注结果集Y\n根据样本特征，预测新样本的趋势\n无监督学习 无数据标注的机器学习\n聚类问题 仅给出X样本\n通过算法划分出不同的类别。\n注： 大多数机器学习应用多属于监督学习，后续仅对knn聚类算法做了简单介绍，其他算法均为监督学习。\n","date":"2024-10-14T02:06:14+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","title":"神经网络"},{"content":"计算机网络 本文主要参考了谢希仁老师编著的《计算机网络》教材第七版，并且后续会更新本书的全部章节，帮助每个程序员新人来理解相关的概念。\n文章中包含了许多体系化的知识以及相关的发展历史，个人认为据因寻果是一种非常有助于理解学习的内容，激发学习的兴趣的一种学习方法。希望能给各位同学们带来些许帮助。\n网络概述 80后出生的许多人都被认为是生活在网络的时代，但其实，早在电报被广泛使用的二十世纪初，网络便渗透进了每个人的日常生活中。通信网络，使得每个人接收信息更加快速与便捷，直到计算机网络被广泛使用的现在，信息的透明度以及便捷度相较于非信息时代的时间里不可同日而语，现如今，某个明星早上出的八卦内容，在当天就能给某些企业的服务器带来巨大的流量压力；信息的快速传播也给此次的新型流感防疫工作带来了明显的帮助。如果你是相关专业的同学，阅读这篇文章能给你带来对网络的进一步理解，而非相关专业的同学也能收获一些通用的信息知识。\n网络的分类 电信网络 有线电视网络 计算机网络 网络类型 主要应用 应用抽象 电信网络 电报，电话，传真 音频内容 有线电视网络 电视 视频内容 计算机网络 计算机（电脑） 多媒体内容，数据文件 理论上来讲，三种网络融合成一种带宽足够大的网络即可提供所有服务，但出于对经济以及行政方面的考量，这样的设想还是很难推进。不过在应用层面，已经有许多计算机（包含pc，手机等个人计算机设备）软件已经提供了基于计算机网络的视频或通信功能。\n网络的性质 连通性 使用网络的两端用户之间，无论距离远近均能非常便捷，经济地交换各种信息，好像用户终端都彼此连通一般，故称其为连通性。\n共享性 网络上的资源能够共享，并且网络上公开的资源就好像在用户身边一样便于使用。\n网络的这两种性质，基本概述了网络的基本功能：数据传输。 不过网络对于数据传输的方法，却经历了大概3个时期：\n电路交换：整个报文的比特流连续的从源点直达终点。 这是一种非常”古老“的数据传输方式，通常用于电信网络（电报电话）。 它的工作流程大致如下： 建立连接\u0026ndash;\u0026gt;通信\u0026ndash;\u0026gt;释放连接 在整个通信期间，两个用户始终占用端到端的通信资源，这样虽然信息流传输速率比较快，但是将会导致通信成本非常高昂以及通信资源的大量浪费。\n报文交换：整个报文先传送到相邻节点，全部存储完成后查找转发表，转发到下一个节点，依次类推直到到达通信终点。 这种传输方式解决了用户对端到端通信资源的持续占用，不过每次转发需要存储整个报文，必然会导致传输速率非常慢，延迟非常高，因此这是一种较不成熟的过渡传输方法。\n分组交换：报文分组后将单个分组传输到相邻节点，存储下来后查找转发表，转发到下一个节点，依次类推直到到达通信终点。 在报文交换的基础上进行了分组，每次转发只需要存储一边单一分组即可，不同的划分也会影响到其传输性能，不过在研究者们的刻苦攻坚下，这个问题基本以及被解决，优秀的分组计划可以加快数据的传输，虽然速率可能比不过电路交换那种连续点到点的通信，不过通信资源占用量低，可以大大降低通信成本，让每个人都有参与网络使用的机会，加速网络的普及。\n网络性能主要指标 速率 单位：bps，bit per second，比特每秒 带宽（易混淆） 带宽分为时域带宽与频域带宽 频域带宽：电子信号所占据的频带宽度，单位Hz 时域带宽：即最高速率，单位与速率相同，bps 我们现实生活中讨论的带宽通常是指时域带宽，例如你在电信公司办理了一个100M光前宽带，这里的100M就是100Mbps，换算为字节后要除以8（1Byte=8bit），也就成为了你下载的下行速率12.5MB/s。\n而频域带宽，这里以5G移动网络信号为例： 频域带宽就是电子信号所占据的频带宽度，不同的频域带宽，根据频率波长的关系，它的性能也往往有所差异，因此，有限的优秀频段往往成为一种竞争化的资源。这里再以5G移动网络信号为例： 这里不难看出，各国的频域带宽都是不同的，以避免信号之间的相互干扰，不过具体的频段优劣，涉及到国与国之间的内容，这里不做详述。\n3.吞吐量（易混淆） 吞吐量表示的是单位时间内实际传输的信号数量，因此，单位又是bps（惊不惊喜意不意外）。 这里着重强调的是实际传输，因此这个参数也是一个能比较真实的反应你所使用的网络的性能的指标，它也往往会低于电信运营商所标识的额定时域带宽。\n计算机网络（互联网）概述 上面的内容还是对于所有网络这个宏观的概念进行讲解，下面进入计算机网络（后文简称计网）的概述内容。\n在RFC[1208]中，规定了互联网（Internet）与互连网（internet）属于不同的概念，简单地说，互连网包含了互联网（实际中两者基本通用）。\n计网的组成 计算机网络（网络）由若干个结点（非节点）和连接这些结点的链路所组成。\n这里结点与节点的区分，个人理解为结点可以包含多个节点 结点可以是由一个个微型的私人局域网，路由器，交换机等用以提供网络服务的host所构成\n这里所有接入互联网，由用户直接使用的主机被称为：互联网的边缘部分 大量网络和连接它们的路由器等为互联网的边缘部分提供服务的设施被称为：互联网的核心部分\n计算机网络的组成部分中，最为核心的部件是路由器，它是实现分组交换的关键构件，任务是转发所有被其收到的数据包分组。\n计网的通信架构 C/S，client and server 这里的client主要是向互联网申请各种服务的用户； server是在互联网范围内给用户提供实际服务的企业或个人。 互联网的绝大多数应用都是基于此架构。\nP2P，peer to peer，也可以理解为person to person 这里的每台主机既是客户端，又是服务端，相较于C/S架构使用量较少 最典型的应用就是P2P下载应用，每台主机都可以作为内容的暂存者，当你需要下载某些数据时，可以优先找到能提供更快速率下载的peer直接下载，不需要每次都访问官方的server，极大的加快下载速率。\n计网的发展 一、 单个网络ARPANET向互联网发展（实验阶段：1969-1990） 高级研究计划局网络（英语：Advanced Research Projects Agency Network），通称阿帕网（英语：ARPANET）是美国国防高级研究计划局开发的世界上第一个运营的数据包交换网络，是全球互联网的鼻祖。\n最初，arpanet只是一个单个的分组交换网，并非是一个互连的网络，随着时间的发展，通信需求的增加带来了许多通信协议的诞生，这些通信协议又有利于更高级的协议编写，慢慢地，由TCP/IP协议族（20世纪80年代，有心的同学可以结合计算机在这个时期的发展来进行更深度的思考）为主导的互联网开始显露出来。 \u0026ndash;wiki百科\n二、三级结构的互联网雏形（科研阶段：21世纪初期） 主干网络-\u0026gt;地区网络-\u0026gt;校园/企业网络\n三、多层次ISP结构的互联网（实用阶段：现在） 名词解释ISP：Internet Service Provider，互联网服务提供商，也就是我们国家的电信运营商（电信，移动等），基本上所有的网络服务（主干网）都是由他们建造并提供相应的服务。\n主干ISP-\u0026gt;地区ISP-\u0026gt;企业网络/本地ISP-\u0026gt;个人网络\n计网的标准化工作流程 组织：IETF，互联网工程部；IETF，互联网研究部\n三大阶段（由先到后） 互联网草案（每个草案大约保存6个月） 互联网建议标准（录入至RFC文档） 互联网标准（多个RFC文档的关联） 计网体系结构（重点） 仅仅有物理通路用以传输数据对于计算机之间还远远不够，面对计算机之间的通信，还需要处理以下几个问题：\n激活物理通路 识别接收对象 检测网络连接正常 审核准备工作 数据格式转换 出错备案 ARPANET提出了”分层”的方法，这些问题在后面的各个网络协议中被分别解决。\n网络协议 osi七层网络模型中，每一层的实现都有相对应的网络协议。 包含但不限于：ARP，RARP，IPv4/v6，TCP，HTTP，FTP，SMTP，SSL等协议 这些协议通常扮演者一个统一化的角色，因此我们需要了解网络协议的相关概念。\n定义 为进行网络中的数据交换而建立的规则，标准，或约定被称为网络协议。（==》这些内容规定了传输的数据格式及有关的同步问题。）\n三要素 语法：数据与控制信息的结构或格式 语义：控制及响应信息 同步：事件实现的详细说明 另：单机程序可以不需要任何网络协议的参与，例如一个简单的hello world程序。\n网络模型 tcp/ip模型 这是使用最为广泛的一个网络模型\nosi七层模型 这是最官方的一个网络模型\ntcp/ip五层网络模型 这是一个折中的网络模型\ntcp/ip模型中的网络接口被拆分为物理层与数据链路层。\n网络模型中的数据传输内容（以osi模型为例） 除物理层中传输的为比特流以外，其他各层都以数据包的形式来传输数据（数据包~=数据头部header+数据内容）。\n数据头部在每个网络协议中都有不同的规定，根据这些规定加上相关的算法，就可以解决上文提到的，计算机网络传输数据还需要处理的几个问题。\n激活物理通路 识别接收对象 检测网络连接正常 审核准备工作 数据格式转换 出错备案 ","date":"2024-10-06T00:00:00+08:00","image":"https://wencynyu.github.io/zh-cn/p/hello-world/cover_hu6307248181568134095.jpg","permalink":"https://wencynyu.github.io/zh-cn/p/hello-world/","title":"计算机网络基本发展"},{"content":"MySQL概览 关系型（行存储） 持久化（硬盘/外存） 事务支持（ACID） OLTP（on-line transaction processing） 通常用于主业务侧场景，例如电商购物、旅游购票、外卖下单等场景。\n区分于非主业务侧，会存在诸如商业分析、ai训练数据、用户画像等B端应用场景。此时MySQL也会被用作Data Lake数据湖的数据源，通过一些同步方式，例如binlog订阅、kafka-connector + 流式计算组件 flink/spark 传输至Elastic Search、Cassandra、Hbase等这样的OLAP（on-line analysis processing）大数据存储组件，而后B端工作人员基于这些OLAP组件进行后续的操作。\n架构 client/server\nbinlog\n源码结构（核心） client：客户端实现 sql：服务端实现 auth binlog optimizer parser key lock mysqld sql-command sql-connect storage：存储引擎实现 innobase myisam vio：virtual io，系统io的抽象层 省略include、share、route、test、script等非核心内容。\n流程 client端发起通信请求，通过tcp建立连接connection。 server端进行user/password鉴权（auth）。 数据库mysql的user表中进行验证。 验证通过后，通过mysql 的权限表（mysql中的 user、db、columns_privilege、Host 表，分别存储的是全局级别、数据库级别、表级别、列级别）查询当前用户的权限。 client端通过connection发送执行的sql脚本语句。 server端收到sql后对查询操作进行缓存判定（cache）。 在 MYSQL5.6以后默认关闭缓存，并且在 8.0 后功能置为Deprecated废弃，不推荐使用。原因是：在大多数使用场景下cache命中率过低（必须是两个完全一致的查询语句才能命中缓存）。 server端缓存未命中则进行sql解析（parser）。 from -\u0026gt; on -\u0026gt; join -\u0026gt; where -\u0026gt; group by -\u0026gt; having+聚合函数 -\u0026gt; select -\u0026gt; order by -\u0026gt; limit server端解析成功后优化器会根据索引信息选择相对最佳方案（optimizer）。 优化器会根据扫描行数、是否使用临时表、是否排序等来判断是否使用某个索引，其中扫描行数的计算可以通过统计信息来估算得出。 统计信息可以看作是索引唯一数的数量，mysql内部通过部分采样来估算：具体就是选择 N 个数据页，统计这些页上数据的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了。 由于索引数据会变化，所以索引的统计信息也会变化。当变更的数据行数超过 1/M 的时候，就会重新计算一次统计信息。也可以通过 \u0026ldquo;analyze table 表名\u0026rdquo; 来重新计算索引的统计信息。 统计信息是否持久化：通过innodb_stats_persistent，设置为 on 的时候，表示统计信息会持久化存储。持久化存储开启时，默认的 N 是 20，M 是 10。设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。 server端将优化器选择的索引方案交由存储引擎执行器进行数据查询（executor）。 server端将查询结果写入缓存 \u0026amp; 返回给client端。 client端接收到返回结果，完成sql操作。 如果client端是通过sdk（编程语言connector）进行连接，后续则可以通过一些orm框架进行table - model映射。 优化器 - 实操理解 建表 \u0026amp; 查询该表的统计信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 create table t_user( id bigint auto_increment comment \u0026#39;pk id\u0026#39; primary key, username varchar(256) not null, real_name varchar(32) default \u0026#39;\u0026#39; not null, nick_name varchar(32) default \u0026#39;\u0026#39; not null, password varchar(256) not null, phone_number varchar(16) default \u0026#39;\u0026#39; not null, locale varchar(8) default \u0026#39;\u0026#39; not null, country varchar(2) default \u0026#39;\u0026#39; not null ) comment \u0026#39;user table\u0026#39;; create index idx_country_locale_user on t_user (country, locale, username); create index idx_locale_user on t_user (locale, username); create index idx_real_name on t_user (real_name); select * from mysql.innodb_index_stats where table_name = \u0026#39;t_user\u0026#39;; 返回结果：\n# database_name table_name index_name last_update stat_name stat_value sample_size stat_description 1 db_rag_application t_user PRIMARY 2024/9/21 15:27 n_diff_pfx01 0 1 id 2 db_rag_application t_user PRIMARY 2024/9/21 15:27 n_leaf_pages 1 Number of leaf pages in the index 3 db_rag_application t_user PRIMARY 2024/9/21 15:27 size 1 Number of pages in the index 4 db_rag_application t_user idx_country_locale_user 2024/9/21 15:27 n_diff_pfx01 0 1 country 5 db_rag_application t_user idx_country_locale_user 2024/9/21 15:27 n_diff_pfx02 0 1 country,locale 6 db_rag_application t_user idx_country_locale_user 2024/9/21 15:27 n_diff_pfx03 0 1 country,locale,username 7 db_rag_application t_user idx_country_locale_user 2024/9/21 15:27 n_diff_pfx04 0 1 country,locale,username,id 8 db_rag_application t_user idx_country_locale_user 2024/9/21 15:27 n_leaf_pages 1 Number of leaf pages in the index 9 db_rag_application t_user idx_country_locale_user 2024/9/21 15:27 size 1 Number of pages in the index 10 db_rag_application t_user idx_locale_user 2024/9/21 15:27 n_diff_pfx01 0 1 locale 11 db_rag_application t_user idx_locale_user 2024/9/21 15:27 n_diff_pfx02 0 1 locale,username 12 db_rag_application t_user idx_locale_user 2024/9/21 15:27 n_diff_pfx03 0 1 locale,username,id 13 db_rag_application t_user idx_locale_user 2024/9/21 15:27 n_leaf_pages 1 Number of leaf pages in the index 14 db_rag_application t_user idx_locale_user 2024/9/21 15:27 size 1 Number of pages in the index 15 db_rag_application t_user idx_real_name 2024/9/21 15:27 n_diff_pfx01 0 1 real_name 16 db_rag_application t_user idx_real_name 2024/9/21 15:27 n_diff_pfx02 0 1 real_name,id 17 db_rag_application t_user idx_real_name 2024/9/21 15:27 n_leaf_pages 1 Number of leaf pages in the index 18 db_rag_application t_user idx_real_name 2024/9/21 15:27 size 1 Number of pages in the index 总结 MySQL会对表中的每个索引建立统计数据，存放在mysql.innodb_index_stats 表中，表字段相对清晰，不赘述。 普通索引（secondary/covering）含有n个字段时，会保存n+1条不同组合（额外增加id统计）的统计数据。 例如user表中key (country, locale, user)，产生4个统计数据记录 country, locale, user country, locale country country, locale, user, id 根据以上索引的统计数据，优化器可以找到相对最优的索引，而后进行execute查询数据。 MySQL优化经典操作 \u0026amp; 实现源码 mysql-server大部分操作源码位于sql目录下：https://github.com/mysql/mysql-server/tree/8.4/sql\nexplain 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 // ignore head include class Item; class Query_block; class Query_expression; class Query_term; class String; class THD; struct AccessPath; struct TABLE; template \u0026lt;class T\u0026gt; class mem_root_deque; extern const char *join_type_str[]; /** Table modification plan for JOIN-less statements (update/delete) */ class Modification_plan { public: THD *const thd; ///\u0026lt; Owning thread const enum_mod_type mod_type; ///\u0026lt; Modification type - MT_INSERT/MT_UPDATE/etc TABLE *table; ///\u0026lt; Table to modify enum join_type type = JT_UNKNOWN; AccessPath *range_scan{nullptr}; Item *condition{nullptr}; uint key; ///\u0026lt; Key to use ha_rows limit; ///\u0026lt; Limit bool need_tmp_table; ///\u0026lt; Whether tmp table needs to be used bool need_sort; ///\u0026lt; Whether to use filesort bool used_key_is_modified; ///\u0026lt; Whether the key used to scan is modified const char *message; ///\u0026lt; Arbitrary message bool zero_result; ///\u0026lt; true \u0026lt;=\u0026gt; plan will not be executed ha_rows examined_rows; ///\u0026lt; # of rows expected to be examined in the table Modification_plan(THD *thd_arg, enum_mod_type mt, TABLE *table_arg, enum join_type type_arg, AccessPath *quick_arg, Item *condition_arg, uint key_arg, ha_rows limit_arg, bool need_tmp_table_arg, bool need_sort_arg, bool used_key_is_modified_arg, ha_rows rows); Modification_plan(THD *thd_arg, enum_mod_type mt, TABLE *table_arg, const char *message_arg, bool zero_result_arg, ha_rows rows); ~Modification_plan(); private: void register_in_thd(); }; /** 这个类用于实现对 INSERT、REPLACE 和多表 UPDATE/DELETE 的 EXPLAIN 功能。它会在执行过程中取消对数据的实际修改。 通过重写 prepare()、start_execution() 和 cleanup() 方法，保证在准备和执行时调用底层的拦截器，但不会进行实际的数据修改。 原文（部分）：it suppresses table data modification by the underlying interceptor object. Thus, we can use Query_result_explain object in the context of EXPLAIN INSERT/ REPLACE/UPDATE/DELETE query like we use Query_result_send in the context of EXPLAIN SELECT command */ class Query_result_explain : public Query_result_send { protected: /** Pointer to underlying Query_result_insert, Query_result_update or Query_result_delete object. */ Query_result *interceptor; public: Query_result_explain(Query_expression *unit_arg, Query_result *interceptor_arg) : Query_result_send(), interceptor(interceptor_arg) { unit = unit_arg; } bool use_protocol_adapter() const override { return false; } protected: bool prepare(THD *thd, const mem_root_deque\u0026lt;Item *\u0026gt; \u0026amp;list, Query_expression *u) override { return Query_result_send::prepare(thd, list, u) || interceptor-\u0026gt;prepare(thd, list, u); } bool start_execution(THD *thd) override { return Query_result_send::start_execution(thd) || interceptor-\u0026gt;start_execution(thd); } void cleanup() override { Query_result_send::cleanup(); interceptor-\u0026gt;cleanup(); } }; /** * Wrapper class for writing EXPLAIN output to a user variable. * * This class overrides Query_result_send::send_data() to write the output of * the EXPLAIN query to the user variable specified by m_variable_name. */ class Query_result_explain_into_var final : public Query_result_explain { public: Query_result_explain_into_var(Query_expression *expr, Query_result *child, std::string_view variable_name) : Query_result_explain(expr, child), m_variable_name(variable_name) {} bool send_result_set_metadata(THD *, const mem_root_deque\u0026lt;Item *\u0026gt; \u0026amp;, uint) override { return false; } bool send_data(THD *thd, const mem_root_deque\u0026lt;Item *\u0026gt; \u0026amp;items) override; bool send_eof(THD *thd) override; private: std::string_view m_variable_name; }; // explain单表CUD写操作函数 bool explain_single_table_modification(THD *explain_thd, const THD *query_thd, const Modification_plan *plan, Query_block *select); // explain复杂CRUD操作函数 bool explain_query(THD *explain_thd, const THD *query_thd, Query_expression *unit); // 多个query block查询块（子查询，细节可查询query_term.h内容）时，会调用这个函数，相当于explain_query的进阶函数，可能会被explain_query多次调用 bool explain_query_specification(THD *explain_thd, const THD *query_thd, Query_term *query_term, enum_parsing_context ctx); class Sql_cmd_explain_other_thread final : public Sql_cmd { public: explicit Sql_cmd_explain_other_thread(my_thread_id thread_id) : m_thread_id(thread_id) {} enum_sql_command sql_command_code() const override { return SQLCOM_EXPLAIN_OTHER; } bool execute(THD *thd) override; private: /// connection_id in EXPLAIN FOR CONNECTION \\\u0026lt;connection_id\\\u0026gt; my_thread_id m_thread_id; }; // Used to generate the \u0026#34;query\u0026#34; field in JSON explain object. void print_query_for_explain(const THD *query_thd, Query_expression *unit, String *str); #endif /* OPT_EXPLAIN_INCLUDED */ 这里实现源码过多，感兴趣自行阅读。\nstatistic 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 struct TABLE; typedef float rec_per_key_t; class KEY; /** 这里内容较少且命名清晰，直接参考原文 Guesstimate for \u0026#34;records per key\u0026#34; when index statistics is not available. @param table the table @param key the index @param used_keyparts the number of key part that should be included in the estimate @return estimated records per key value */ rec_per_key_t guess_rec_per_key(const TABLE *const table, const KEY *const key, uint used_keyparts); #endif /* OPT_STATISTICS_INCLUDED */ // 实现：opt_statistic.cc rec_per_key_t guess_rec_per_key(const TABLE *const table, const KEY *const key, uint used_keyparts) { // 参数校验 assert(used_keyparts \u0026gt;= 1); assert(used_keyparts \u0026lt;= key-\u0026gt;actual_key_parts); assert(!key-\u0026gt;has_records_per_key(used_keyparts - 1)); // 从 table 对象中获取总记录数 const ha_rows table_rows = table-\u0026gt;file-\u0026gt;stats.records; /* 预估key匹配records： 如果统计信息中有key匹配的records记录就直接使用 没有的话唯一索引默认匹配一个，普通索引默认匹配10个 */ rec_per_key_t rec_per_key_all; if (key-\u0026gt;has_records_per_key(key-\u0026gt;user_defined_key_parts - 1)) rec_per_key_all = key-\u0026gt;records_per_key(key-\u0026gt;user_defined_key_parts - 1); else { if (key-\u0026gt;actual_flags \u0026amp; HA_NOSAME) rec_per_key_all = 1.0f; // Unique index else { rec_per_key_all = 10.0f; // Non-unique index /* 之前假设普通索引匹配10条，如果是很小的这里需要调整实际匹配量 */ rec_per_key_all = std::min(rec_per_key_all, max(rec_per_key_t(table_rows) / 10, 1.0f)); } } rec_per_key_t rec_per_key; // 假设第一个键部分匹配1%的记录，总体记录数的1%作为估算 const rec_per_key_t rec_per_key_first = table_rows * 0.01f; if (rec_per_key_first \u0026lt; rec_per_key_all) { // 第一部分的估算小于完整键的估算，直接使用完整键的估算。 rec_per_key = rec_per_key_all; } else { if (key-\u0026gt;user_defined_key_parts \u0026gt; 1) { // See formula above：随着使用的键部分数量的增加，记录的匹配数量将相应调整 rec_per_key = rec_per_key_first - (rec_per_key_t(used_keyparts - 1) / (key-\u0026gt;user_defined_key_parts - 1)) * (rec_per_key_first - rec_per_key_all); } else { // 对于单列索引，依据索引的唯一性直接返回相应的估算值。 if (key-\u0026gt;actual_flags \u0026amp; HA_NOSAME) rec_per_key = 1.0f; // Unique index else rec_per_key = rec_per_key_first; // Non-unique index } assert(rec_per_key \u0026gt;= rec_per_key_all); } return rec_per_key; } 其中存在部分外部函数：均来自于key.h\nhas_records_per_key records_per_key 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 // 内存中的索引数据结构 class KEY { public: /** Tot length of key */ uint key_length{0}; /** dupp key and pack flags */ ulong flags{0}; /** dupp key and pack flags for actual key parts */ ulong actual_flags{0}; /** How many key_parts */ uint user_defined_key_parts{0}; /** How many key_parts including hidden parts */ uint actual_key_parts{0}; /** Key parts allocated for primary key parts extension but not used due to some reasons(no primary key, duplicated key parts) */ uint unused_key_parts{0}; /** Should normally be = actual_key_parts */ uint usable_key_parts{0}; uint block_size{0}; /// @cond Doxygen_is_confused enum ha_key_alg algorithm { HA_KEY_ALG_SE_SPECIFIC }; /// @endcond /** A flag which indicates that index algorithm for this key was explicitly specified by user. So, for example, it should be mentioned in SHOW CREATE TABLE output. */ bool is_algorithm_explicit{false}; /** Note that parser is used when the table is opened for use, and parser_name is used when the table is being created. */ /** Fulltext [pre]parser */ plugin_ref parser{nullptr}; /** Fulltext [pre]parser name */ LEX_CSTRING parser_name{nullptr, 0}; KEY_PART_INFO *key_part{nullptr}; /** Name of key */ const char *name{nullptr}; /** Array of AVG(number of records with the same field value) for 1st ... Nth key part. 0 means \u0026#39;not known\u0026#39;. For internally created temporary tables, this member can be nullptr. */ ulong *rec_per_key{nullptr}; /** @retval true if this is a functional index (at least one of the key parts is a functional key part). @retval false if this isn\u0026#39;t a functional index. */ bool is_functional_index() const; // Can\u0026#39;t use in-class initialization as long as we memset-initialize // the struct LEX_CSTRING engine_attribute{nullptr, 0}; LEX_CSTRING secondary_engine_attribute{nullptr, 0}; private: /** Estimate for how much of the index data that is currently available in a memory buffer. Valid range is [0..1]. This will be initialized to a IN_MEMORY_ESTIMATE_UNKNOWN. If it still has this value when used, it means that the storage engine has not supplied a value. */ double m_in_memory_estimate{0.0}; /** 这里就是每一个索引匹配的records数量数据结构，通过指针存了一个float数组 Array of AVG(number of records with the same field value) for 1st ... Nth key part. For internally created temporary tables, this member can be nullptr. This is the same information as stored in the above rec_per_key array but using float values instead of integer values. If the storage engine has supplied values in this array, these will be used. Otherwise the value in rec_per_key will be used. @todo In the next release the rec_per_key array above should be removed and only this should be used. */ rec_per_key_t *rec_per_key_float{nullptr}; public: /** True if this index is visible to the query optimizer. The optimizer may only use visible indexes. */ bool is_visible{false}; TABLE *table{nullptr}; LEX_CSTRING comment{nullptr, 0}; /** Check if records per key estimate is available for given key part. @param key_part_no key part number, must be in [0, KEY::actual_key_parts) @return true if records per key estimate is available, false otherwise */ bool has_records_per_key(uint key_part_no) const { assert(key_part_no \u0026lt; actual_key_parts); return ((rec_per_key_float \u0026amp;\u0026amp; rec_per_key_float[key_part_no] != REC_PER_KEY_UNKNOWN) || (rec_per_key \u0026amp;\u0026amp; rec_per_key[key_part_no] != 0)); } /** Retrieve an estimate for the average number of records per distinct value, when looking only at the first key_part_no+1 columns. If no record per key estimate is available for this key part, REC_PER_KEY_UNKNOWN is returned. @param key_part_no key part number, must be in [0, KEY::actual_key_parts) @return Number of records having the same key value @retval REC_PER_KEY_UNKNOWN no records per key estimate available @retval != REC_PER_KEY_UNKNOWN record per key estimate */ rec_per_key_t records_per_key(uint key_part_no) const { assert(key_part_no \u0026lt; actual_key_parts); /* If the storage engine has provided rec per key estimates as float then use this. If not, use the integer version. */ if (rec_per_key_float[key_part_no] != REC_PER_KEY_UNKNOWN) return rec_per_key_float[key_part_no]; return (rec_per_key[key_part_no] != 0) ? static_cast\u0026lt;rec_per_key_t\u0026gt;(rec_per_key[key_part_no]) : REC_PER_KEY_UNKNOWN; } } 这里代码量较少，可以比较直观的理解mysql优化器统计索引效率的流程。\n存储引擎（索引） innoDB 事务支持 mvcc 行锁 redolog \u0026amp; undolog .ibd文件存索引+数据 InnoDB的文件结构可以划分为多个段（segment）、区（extent）、页（page）等层级。每个索引都存储在特定的段中，而每个段又由多个区组成，每个区包含多个页。在InnoDB中，页是磁盘和内存之间交换数据的最小单位，通常是16KB大小。 Feature Support B-tree indexes Yes Clustered indexes Yes Compressed data Yes Data caches Yes Foreign key support Yes Full-text search indexes Yes Geospatial data type support Yes Geospatial indexing support Yes Hash indexes No Index caches Yes Locking granularity Row MVCC Yes Storage limits 64TB T-tree indexes No Transactions Yes Update statistics for data dictionary Yes 架构 MyISAM 表锁 读多写少 .MYI文件存储索引信息，.MYD文件存储数据（查索引后需要回表） Feature Support B-tree indexes Yes Clustered indexes No Compressed data Yes (Compressed MyISAM tables are supported only when using the compressed row format. Tables using the compressed row format with MyISAM are read only.) Data caches No Foreign key support No Full-text search indexes Yes Geospatial data type support Yes Geospatial indexing support Yes Hash indexes No Index caches Yes Locking granularity Table MVCC No Storage limits 256TB T-tree indexes No Transactions No Update statistics for data dictionary Yes MEMORY 内存 hash Feature Support B-tree indexes Yes Clustered indexes No Compressed data No Data caches No Foreign key support No Full-text search indexes No Geospatial data type support No Geospatial indexing support No Hash indexes Yes Index caches No Locking granularity Table MVCC No Storage limits RAM T-tree indexes No Transactions No Update statistics for data dictionary Yes 其他存储引擎（略） CSV ARCHIVE MERGE 参考：\nhttps://dev.mysql.com/doc/refman/8.4/en/manual-info.html\nhttps://www.cnblogs.com/kerrycode/p/11821042.html\nhttps://github.com/mysql/mysql-server/tree/8.4/sql\n","date":"2024-09-18T00:58:29+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BDmysql-%E6%A6%82%E8%A7%88/","title":"高性能MySql-概览"},{"content":"","date":"2024-09-15T00:58:54+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BDmysql-%E7%B4%A2%E5%BC%95/","title":"高性能MySql-索引"},{"content":"","date":"2024-09-15T00:58:40+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E9%AB%98%E6%80%A7%E8%83%BDmysql-%E9%80%9A%E4%BF%A1/","title":"高性能MySql-通信"},{"content":"","date":"2024-09-15T01:23:56+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E6%9D%83%E9%99%90%E8%AE%BE%E8%AE%A1-%E9%89%B4%E6%9D%83%E6%8E%88%E6%9D%83/","title":"权限设计-鉴权授权"},{"content":"Spring框架简介 陈年手写老图介绍：\n","date":"2024-10-11T01:10:50+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6-%E6%A6%82%E8%A7%88-spring/","title":"开发框架-概览-spring"},{"content":"","date":"2024-09-15T01:12:40+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6-orm-spring/","title":"开发框架-orm-spring"},{"content":"","date":"2024-09-15T01:11:15+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6-aop-spring/","title":"开发框架-aop-spring"},{"content":"","date":"2024-09-15T01:11:09+08:00","permalink":"https://wencynyu.github.io/zh-cn/p/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6-ioc-spring/","title":"开发框架-ioc-spring"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt;\r\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt;\r\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\rDiff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] One line code block 1 \u0026lt;p\u0026gt;A paragraph\u0026lt;/p\u0026gt; List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-09-07T00:00:00Z","permalink":"https://wencynyu.github.io/zh-cn/p/markdown%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/","title":"Markdown基本语法"},{"content":"For more details, check out the documentation.\nBilibili video Tencent video YouTube video Generic video file Your browser doesn't support HTML5 video. Here is a link to the video instead. Gist GitLab Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― A famous person, The book they wrote Photo by Codioful on Unsplash\n","date":"2023-08-25T00:00:00Z","image":"https://wencynyu.github.io/zh-cn/p/%E5%A4%96%E9%93%BE%E4%BD%BF%E7%94%A8/cover_hu17063188895770243625.jpg","permalink":"https://wencynyu.github.io/zh-cn/p/%E5%A4%96%E9%93%BE%E4%BD%BF%E7%94%A8/","title":"外链使用"},{"content":"Stack has built-in support for math typesetting using KaTeX.\nIt\u0026rsquo;s not enabled by default side-wide, but you can enable it for individual posts by adding math: true to the front matter. Or you can enable it side-wide by adding math = true to the params.article section in config.toml.\nInline math This is an inline mathematical expression: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\n1 $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$ Block math $$\r\\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$ 1 2 3 $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$ $$\rf(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)\\,e^{2 \\pi i \\xi x}\\,d\\xi\r$$ 1 2 3 $$ f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)\\,e^{2 \\pi i \\xi x}\\,d\\xi $$ ","date":"2023-08-24T00:00:00Z","permalink":"https://wencynyu.github.io/zh-cn/p/%E6%95%B0%E5%AD%A6%E6%94%AF%E6%8C%81-latex/","title":"数学支持-latex"},{"content":"Hugo theme Stack supports the creation of interactive image galleries using Markdown. It\u0026rsquo;s powered by PhotoSwipe and its syntax was inspired by Typlog.\nTo use this feature, the image must be in the same directory as the Markdown file, as it uses Hugo\u0026rsquo;s page bundle feature to read the dimensions of the image. External images are not supported.\nSyntax 1 ![Image 1](1.jpg) ![Image 2](2.jpg) Result Photo by mymind and Luke Chesser on Unsplash\n","date":"2023-08-26T00:00:00Z","image":"https://wencynyu.github.io/zh-cn/p/%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD-%E5%B1%95%E7%A4%BA/2_hu15576070775610481867.jpg","permalink":"https://wencynyu.github.io/zh-cn/p/%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD-%E5%B1%95%E7%A4%BA/","title":"图片加载 \u0026 展示"}]